{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CouchbaseStorage for CrewAI\n",
    "\n",
    "This notebook demonstrates how to use Couchbase as a vector store for CrewAI's memory system. The implementation provides:\n",
    "- Vector similarity search for semantic document retrieval\n",
    "- Document storage with metadata and embeddings\n",
    "- Comprehensive error handling\n",
    "- Integration with CrewAI agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "1. A running Couchbase cluster (local or Capella)\n",
    "2. OpenAI API key for generating embeddings\n",
    "3. Vector search index configured in Couchbase\n",
    "\n",
    "Set up your environment variables in a .env file:\n",
    "```\n",
    "OPENAI_API_KEY=your_key_here\n",
    "CB_USERNAME=your_username\n",
    "CB_PASSWORD=your_password\n",
    "CB_HOST=your_host\n",
    "CB_BUCKET_NAME=your_bucket\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet 'crewai[tools]' langchain-couchbase langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Import required libraries and configure logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.options import ClusterOptions\n",
    "from crewai.memory.storage.rag_storage import RAGStorage\n",
    "from dotenv import load_dotenv\n",
    "from langchain_couchbase.vectorstores import CouchbaseVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from crewai import Agent, Crew, Process, Task\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Disable all logging except our own\n",
    "for name in logging.root.manager.loggerDict:\n",
    "    if name != __name__:\n",
    "        logging.getLogger(name).setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CouchbaseStorage Class\n",
    "\n",
    "The CouchbaseStorage class extends CrewAI's RAGStorage to provide vector search capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouchbaseStorage(RAGStorage):\n",
    "    \"\"\"Extends Storage to handle embeddings for memory entries using Couchbase.\"\"\"\n",
    "\n",
    "    def __init__(self, type, allow_reset=True, embedder_config=None, crew=None):\n",
    "        try:\n",
    "            super().__init__(type, allow_reset, embedder_config, crew)\n",
    "            self._initialize_app()\n",
    "            logger.info(f\"CouchbaseStorage initialized for type: {type}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize CouchbaseStorage: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        query: str,\n",
    "        limit: int = 3,\n",
    "        filter: Optional[dict] = None,\n",
    "        score_threshold: float = 0,\n",
    "    ) -> List[Any]:\n",
    "        \"\"\"Search memory entries using vector similarity.\"\"\"\n",
    "        try:\n",
    "            results = self.vector_store.similarity_search_with_score(\n",
    "                query,\n",
    "                k=limit,\n",
    "                filter=filter,\n",
    "                score_threshold=score_threshold\n",
    "            )\n",
    "            \n",
    "            return [{\n",
    "                \"id\": str(i),\n",
    "                \"metadata\": doc.metadata,\n",
    "                \"context\": doc.page_content,\n",
    "                \"score\": score\n",
    "            } for i, (doc, score) in enumerate(results)]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Search failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset the memory storage.\"\"\"\n",
    "        if self.allow_reset:\n",
    "            try:\n",
    "                # Create primary index if it doesn't exist\n",
    "                self.cluster.query(\n",
    "                    f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{self.scope_name}`.`{self.collection_name}`\"\n",
    "                ).execute()\n",
    "                \n",
    "                # Delete all documents\n",
    "                self.cluster.query(\n",
    "                    f\"DELETE FROM `{self.bucket_name}`.`{self.scope_name}`.`{self.collection_name}`\"\n",
    "                ).execute()\n",
    "                logger.info(f\"Successfully reset collection: {self.collection_name}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Reset failed: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "    def _initialize_app(self):\n",
    "        \"\"\"Initialize Couchbase client and vector store.\"\"\"\n",
    "        try:\n",
    "            # Check for required environment variables\n",
    "            if not os.getenv('OPENAI_API_KEY'):\n",
    "                raise ValueError(\"OPENAI_API_KEY environment variable is required\")\n",
    "\n",
    "            # Initialize OpenAI embeddings\n",
    "            self.embeddings = OpenAIEmbeddings(\n",
    "                openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "                model=\"text-embedding-ada-002\"\n",
    "            )\n",
    "\n",
    "            # Connect to Couchbase\n",
    "            auth = PasswordAuthenticator(\n",
    "                os.getenv('CB_USERNAME', 'Administrator'),\n",
    "                os.getenv('CB_PASSWORD', 'password')\n",
    "            )\n",
    "            self.cluster = Cluster(\n",
    "                os.getenv('CB_HOST', 'couchbase://localhost'),\n",
    "                ClusterOptions(auth)\n",
    "            )\n",
    "            \n",
    "            # Set up bucket, scope, and collection names\n",
    "            self.bucket_name = os.getenv('CB_BUCKET_NAME', 'vector-search-testing')\n",
    "            self.scope_name = os.getenv('SCOPE_NAME', 'shared')\n",
    "            self.collection_name = self.type  # Use the type parameter as collection name\n",
    "            self.index_name = os.getenv('INDEX_NAME', 'vector_search_crew')\n",
    "\n",
    "            # Create primary index if it doesn't exist\n",
    "            self.cluster.query(\n",
    "                f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{self.scope_name}`.`{self.collection_name}`\"\n",
    "            ).execute()\n",
    "\n",
    "            # Initialize vector store\n",
    "            self.vector_store = CouchbaseVectorStore(\n",
    "                cluster=self.cluster,\n",
    "                bucket_name=self.bucket_name,\n",
    "                scope_name=self.scope_name,\n",
    "                collection_name=self.collection_name,\n",
    "                embedding=self.embeddings,\n",
    "                index_name=self.index_name,\n",
    "            )\n",
    "            logger.info(\"Storage initialized successfully\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Initialization failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def save(self, value: Any, metadata: Dict[str, Any]) -> None:\n",
    "        \"\"\"Save a memory entry with metadata.\"\"\"\n",
    "        try:\n",
    "            # Add text to vector store\n",
    "            self.vector_store.add_texts(\n",
    "                texts=[value],\n",
    "                metadatas=[metadata or {}],\n",
    "                ids=[f\"{self.type}_{metadata.get('id', len(self.search('', limit=1)) + 1)}\"]\n",
    "            )\n",
    "            logger.info(f\"Successfully saved entry with metadata: {metadata}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Save failed: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Vector Search\n",
    "\n",
    "Let's test the vector search functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 16:38:18 [INFO] Storage initialized successfully\n",
      "2025-01-15 16:38:26 [INFO] Storage initialized successfully\n",
      "2025-01-15 16:38:26 [INFO] CouchbaseStorage initialized for type: crew_stm_demo\n",
      "2025-01-15 16:38:28 [INFO] Successfully reset collection: crew_stm_demo\n",
      "2025-01-15 16:38:31 [INFO] Successfully saved entry with metadata: {'category': 'technology', 'type': 'concept'}\n",
      "2025-01-15 16:38:34 [INFO] Successfully saved entry with metadata: {'category': 'database', 'type': 'implementation'}\n",
      "2025-01-15 16:38:37 [INFO] Successfully saved entry with metadata: {'category': 'search', 'type': 'technique'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query: 'Tell me about vector search'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result:\n",
      "Context: A Google Street View image of a man loading a large white plastic bag into the boot of his car has helped unravel a murder case in a northern Spanish town, police say. The Google app allows users to see images of streets around the world - filmed by cars mounted with cameras. It captured the exact moment the body of the victim was allegedly being removed. Two people were arrested last month, accused of being responsible for the disappearance and murder of a man in October last year. His dismembered remains were found in a cemetery last week.\n",
      "\n",
      "This was the first time in 15 years that the Google car had been to the town of Tajueco, in the northern province of Soria. Officials say another photo sequence shows the blurred silhouette of someone transporting a large white bundle in a wheelbarrow. However, police said the images were not \"decisive\" in solving the case. The male victim, said by El Pais newspaper to be a 33-year-old Cuban national, was reported missing in October 2023 after a relative received text messages from the victim's phone which he found suspicious. The relative told police they said the victim had met a woman, was leaving Spain and would be getting rid of his phone. On 12 November this year, police arrested a woman said to be the missing man's partner and a man said to be her ex-partner. Earlier this month, a severely decomposed torso, thought to be the victim's, was dug up in a nearby cemetery. The accused have been remanded in custody and the investigation continues.\n",
      "Metadata: {}\n",
      "Score: 0.742242693901062\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result:\n",
      "Context: The logo of Google is seen outside Google Bay View facilities in Mountain View, California, US in August 2024\n",
      "\n",
      "Alphabet's Google proposed new limits to revenue-sharing agreements with companies including Apple which make Google's search engine the default on their devices and browsers. The suggestions stem from the US search giant's ongoing antitrust battle over its online search business. In August, US District Judge Amit Mehta ruled that Google illegally crushed its competition in search - a decision the company vowed to appeal. In a legal filing submitted Friday, Google said it should be allowed to continue entering into those contracts with other companies while widening the options it offers.\n",
      "\n",
      "These options include allowing different default search engines to be assigned to different platforms and browsing modes. Google's suggested remedies also call for the ability for partners to change their default search provider at least every 12 months. The proposals stand in stark contrast to the sweeping remedies suggested last month by the US Department of Justice (DOJ), which recommended that Judge Mehta force the firm to stop entering into revenue-sharing contracts. DOJ lawyers also demanded that Google sell Chrome, the world's most popular web browser. Google's search engine accounts for about 90% of all online searches globally, according to web traffic analysis platform Statcounter, external. In a statement, Google called DOJ's remedies \"overbroad\" and said even its own counterproposals, which were filed in response to a court-mandated deadline, would come at a cost to their partners. Judge Mehta is expected to issue a decision in the remedies phase of the landmark case by August, after a trial.\n",
      "Metadata: {}\n",
      "Score: 0.7384507656097412\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize storage\n",
    "storage = CouchbaseStorage(\"crew_stm_demo\")\n",
    "\n",
    "# Clear existing data\n",
    "storage.reset()\n",
    "\n",
    "# Test saving entries\n",
    "test_entries = [\n",
    "    (\"Vector search uses mathematical vectors to find similar items by converting data into high-dimensional vector space\", \n",
    "     {\"category\": \"technology\", \"type\": \"concept\"}),\n",
    "    (\"Couchbase vector search enables semantic similarity matching by storing and comparing vector embeddings\", \n",
    "     {\"category\": \"database\", \"type\": \"implementation\"}),\n",
    "    (\"Vector embeddings represent text, images, and other data as numerical vectors for efficient similarity search\", \n",
    "     {\"category\": \"search\", \"type\": \"technique\"})\n",
    "]\n",
    "\n",
    "for text, metadata in test_entries:\n",
    "    storage.save(text, metadata)\n",
    "\n",
    "# Test searching\n",
    "query = \"Tell me about vector search\"\n",
    "results = storage.search(query, limit=2)\n",
    "\n",
    "print(f\"Search results for query: '{query}'\")\n",
    "print(\"-\"*80)\n",
    "for result in results:\n",
    "    print(\"\\nResult:\")\n",
    "    print(f\"Context: {result['context']}\")\n",
    "    print(f\"Metadata: {result['metadata']}\")\n",
    "    print(f\"Score: {result['score']}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrewAI Integration\n",
    "\n",
    "Now let's see how to use CouchbaseStorage with CrewAI agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crew Result:\n",
      "--------------------------------------------------------------------------------\n",
      "Vector search is a prominent technique in the field of information retrieval. It operates on the principle of multi-dimensional vectors to identify the most relevant data. Conceptually, each data point is located in a multi-dimensional space, and their \"distance\" from each other is used to establish their similarity.\n",
      "\n",
      "Vector search finds extensive use across numerous applications. It's primarily used in recommendation systems to propose products or content that align with users' past interactions. For instance, Netflix employs vector search to suggest shows to its viewers based on their previous viewing patterns. In the domain of natural language processing (NLP), vector search is used to comprehend semantic similarities between different words or phrases. Google utilizes vector search in its search engine to provide the most pertinent search results.\n",
      "\n",
      "There are a variety of technologies that enable vector search. Milvus, an open-source vector database, is one such technology. It is capable of managing large-scale vector data and performing high-concurrency vector similarity search, making it suitable for AI applications like image recognition, voice search, and recommendation systems.\n",
      "\n",
      "Elasticsearch is another technology that facilitates vector search. As a search and analytics engine, Elasticsearch can perform full-text search, structured search, and analytics, and handle large data volumes in near real-time. It uses a vector scoring function, enabling it to conduct vector similarity searches.\n",
      "\n",
      "Facebook's AI research team has developed a library, FAISS (Facebook AI Similarity Search), specifically for efficient similarity search and clustering of dense vectors. Capable of supporting billions of vectors, FAISS is commonly used for tasks like image, video, and audio retrieval.\n",
      "\n",
      "To summarize, vector search is a potent method for information retrieval based on data similarity. It is widely implemented across various applications and is supported by numerous technologies, including Milvus, Elasticsearch, and FAISS.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize language model\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Create agents\n",
    "researcher = Agent(\n",
    "    role='Research Expert',\n",
    "    goal='Find relevant information',\n",
    "    backstory='Expert at finding and analyzing information',\n",
    "    llm=llm,\n",
    "    memory=True,\n",
    "    memory_storage=storage\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "    role='Technical Writer',\n",
    "    goal='Create clear documentation',\n",
    "    backstory='Expert at technical writing and documentation',\n",
    "    llm=llm,\n",
    "    memory=True,\n",
    "    memory_storage=storage\n",
    ")\n",
    "\n",
    "# Create tasks\n",
    "research_task = Task(\n",
    "    description='Research vector search capabilities',\n",
    "    agent=researcher,\n",
    "    expected_output=\"Detailed findings about vector search technology and implementations\"\n",
    ")\n",
    "\n",
    "writing_task = Task(\n",
    "    description='Document the findings',\n",
    "    agent=writer,\n",
    "    expected_output=\"Clear and comprehensive documentation of the research findings\",\n",
    "    context=[research_task]\n",
    ")\n",
    "\n",
    "# Create and run crew\n",
    "crew = Crew(\n",
    "    agents=[researcher, writer],\n",
    "    tasks=[research_task, writing_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "result = crew.kickoff()\n",
    "print(\"\\nCrew Result:\")\n",
    "print(\"-\"*80)\n",
    "print(result)\n",
    "print(\"-\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
