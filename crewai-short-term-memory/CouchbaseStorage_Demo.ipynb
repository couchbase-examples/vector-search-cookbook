{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CouchbaseStorage for CrewAI\n",
    "\n",
    "This notebook demonstrates how to use Couchbase as a vector store for CrewAI's memory system. The implementation provides:\n",
    "- Vector similarity search for semantic document retrieval\n",
    "- Document storage with metadata and embeddings\n",
    "- Comprehensive error handling with specific Couchbase exceptions\n",
    "- Proper logging with detailed operation tracking\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "1. A running Couchbase cluster (local or Capella)\n",
    "2. OpenAI API key for generating embeddings\n",
    "3. Vector search index configured in Couchbase\n",
    "\n",
    "Set up your environment variables in a .env file:\n",
    "```\n",
    "OPENAI_API_KEY=your_key_here\n",
    "CB_USERNAME=your_username\n",
    "CB_PASSWORD=your_password\n",
    "CB_HOST=your_host\n",
    "CB_BUCKET_NAME=your_bucket\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'crewai[tools]' langchain-couchbase langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "The CouchbaseStorage class extends CrewAI's RAGStorage to provide:\n",
    "\n",
    "1. **Vector Search**: Uses Couchbase's vector search capabilities for semantic similarity\n",
    "2. **Error Handling**: Specific handling for Couchbase operations\n",
    "3. **Automatic Setup**: Creates necessary indexes and collections\n",
    "4. **Logging**: Detailed operation tracking for debugging\n",
    "\n",
    "Here's the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.exceptions import (CouchbaseException,\n",
    "                                  DocumentNotFoundException,\n",
    "                                  QueryIndexNotFoundException,\n",
    "                                  TimeoutException)\n",
    "from couchbase.management.search import SearchIndex\n",
    "from couchbase.options import ClusterOptions\n",
    "from dotenv import load_dotenv\n",
    "from langchain_couchbase.vectorstores import CouchbaseVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from crewai.memory.storage.rag_storage import RAGStorage\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CouchbaseStorage(RAGStorage):\n",
    "    \"\"\"Extends Storage to handle embeddings for memory entries using Couchbase.\"\"\"\n",
    "\n",
    "    def __init__(self, type, allow_reset=True, embedder_config=None, crew=None):\n",
    "        try:\n",
    "            super().__init__(type, allow_reset, embedder_config, crew)\n",
    "            self._initialize_app()\n",
    "            logger.info(f\"CouchbaseStorage initialized for type: {type}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize CouchbaseStorage: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        query: str,\n",
    "        limit: int = 3,\n",
    "        filter: Optional[dict] = None,\n",
    "        score_threshold: float = 0,\n",
    "    ) -> List[Any]:\n",
    "        \"\"\"Search memory entries using vector similarity.\"\"\"\n",
    "        try:\n",
    "            results = self.vector_store.similarity_search_with_score(\n",
    "                query,\n",
    "                k=limit,\n",
    "                filter=filter,\n",
    "                score_threshold=score_threshold\n",
    "            )\n",
    "            \n",
    "            return [{\n",
    "                \"id\": str(i),\n",
    "                \"metadata\": doc.metadata,\n",
    "                \"context\": doc.page_content,\n",
    "                \"score\": score\n",
    "            } for i, (doc, score) in enumerate(results)]\n",
    "        except TimeoutException as e:\n",
    "            logger.error(f\"Search operation timed out: {str(e)}\")\n",
    "            raise\n",
    "        except CouchbaseException as e:\n",
    "            logger.error(f\"Couchbase error during search: {str(e)}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error during search: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset the memory storage.\"\"\"\n",
    "        if self.allow_reset:\n",
    "            try:\n",
    "                # Delete all documents in the collection using N1QL\n",
    "                self.cluster.query(\n",
    "                    f\"DELETE FROM `{self.bucket_name}`.`{self.scope_name}`.`{self.collection_name}`\"\n",
    "                ).execute()\n",
    "                logger.info(f\"Successfully reset collection: {self.collection_name}\")\n",
    "            except QueryIndexNotFoundException:\n",
    "                logger.error(\"Primary index not found. Attempting to create...\")\n",
    "                try:\n",
    "                    self.cluster.query(\n",
    "                        f\"CREATE PRIMARY INDEX ON `{self.bucket_name}`.`{self.scope_name}`.`{self.collection_name}`\"\n",
    "                    ).execute()\n",
    "                    # Retry delete after creating index\n",
    "                    self.cluster.query(\n",
    "                        f\"DELETE FROM `{self.bucket_name}`.`{self.scope_name}`.`{self.collection_name}`\"\n",
    "                    ).execute()\n",
    "                    logger.info(\"Primary index created and collection reset successfully\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to create primary index: {str(e)}\")\n",
    "                    raise\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to reset collection: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "    def _initialize_app(self):\n",
    "        \"\"\"Initialize Couchbase client and vector store.\"\"\"\n",
    "        try:\n",
    "            # Check for required environment variables\n",
    "            if not os.getenv('OPENAI_API_KEY'):\n",
    "                raise ValueError(\"OPENAI_API_KEY environment variable is required\")\n",
    "\n",
    "            # Initialize OpenAI embeddings\n",
    "            self.embeddings = OpenAIEmbeddings(\n",
    "                openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "                model=\"text-embedding-ada-002\"\n",
    "            )\n",
    "            logger.info(\"OpenAI embeddings initialized\")\n",
    "\n",
    "            # Connect to Couchbase\n",
    "            auth = PasswordAuthenticator(\n",
    "                os.getenv('CB_USERNAME', 'Administrator'),\n",
    "                os.getenv('CB_PASSWORD', 'password')\n",
    "            )\n",
    "            self.cluster = Cluster(\n",
    "                os.getenv('CB_HOST', 'couchbase://localhost'),\n",
    "                ClusterOptions(auth)\n",
    "            )\n",
    "            logger.info(\"Connected to Couchbase cluster\")\n",
    "            \n",
    "            # Set up bucket, scope, and collection names\n",
    "            self.bucket_name = os.getenv('CB_BUCKET_NAME', 'vector-search-testing')\n",
    "            self.scope_name = os.getenv('SCOPE_NAME', 'shared')\n",
    "            self.collection_name = self.type  # Use the type parameter as collection name\n",
    "            self.index_name = os.getenv('INDEX_NAME', 'vector_search_crew')\n",
    "\n",
    "            # Create primary index if it doesn't exist\n",
    "            try:\n",
    "                self.cluster.query(\n",
    "                    f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{self.bucket_name}`.`{self.scope_name}`.`{self.collection_name}`\"\n",
    "                ).execute()\n",
    "                logger.info(f\"Primary index ensured for collection: {self.collection_name}\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not create primary index: {str(e)}\")\n",
    "\n",
    "            # Initialize vector store\n",
    "            self.vector_store = CouchbaseVectorStore(\n",
    "                cluster=self.cluster,\n",
    "                bucket_name=self.bucket_name,\n",
    "                scope_name=self.scope_name,\n",
    "                collection_name=self.collection_name,\n",
    "                embedding=self.embeddings,\n",
    "                index_name=self.index_name,\n",
    "            )\n",
    "            logger.info(\"Vector store initialized successfully\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            logger.error(f\"Configuration error: {str(e)}\")\n",
    "            raise\n",
    "        except CouchbaseException as e:\n",
    "            logger.error(f\"Couchbase error during initialization: {str(e)}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error during initialization: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def save(self, value: Any, metadata: Dict[str, Any]) -> None:\n",
    "        \"\"\"Save a memory entry with metadata.\"\"\"\n",
    "        try:\n",
    "            # Add text to vector store\n",
    "            self.vector_store.add_texts(\n",
    "                texts=[value],\n",
    "                metadatas=[metadata or {}],\n",
    "                ids=[f\"{self.type}_{metadata.get('id', len(self.search('', limit=1)) + 1)}\"]\n",
    "            )\n",
    "            logger.info(f\"Successfully saved entry with metadata: {metadata}\")\n",
    "        except TimeoutException as e:\n",
    "            logger.error(f\"Save operation timed out: {str(e)}\")\n",
    "            raise\n",
    "        except CouchbaseException as e:\n",
    "            logger.error(f\"Couchbase error during save: {str(e)}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error during save: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Implementation\n",
    "\n",
    "We'll test the CouchbaseStorage implementation with:\n",
    "1. Saving test documents with metadata\n",
    "2. Performing vector similarity search\n",
    "3. Handling storage reset\n",
    "\n",
    "The test demonstrates error handling and logging throughout each operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 11:52:17 [INFO] Initializing CouchbaseStorage...\n",
      "2025-01-15 11:52:17 [INFO] OpenAI embeddings initialized\n",
      "2025-01-15 11:52:18 [INFO] Connected to Couchbase cluster\n",
      "2025-01-15 11:52:19 [INFO] Primary index ensured for collection: crew_stm_demo\n",
      "2025-01-15 11:52:25 [INFO] Vector store initialized successfully\n",
      "2025-01-15 11:52:25 [INFO] OpenAI embeddings initialized\n",
      "2025-01-15 11:52:26 [INFO] Connected to Couchbase cluster\n",
      "2025-01-15 11:52:27 [INFO] Primary index ensured for collection: crew_stm_demo\n",
      "2025-01-15 11:52:33 [INFO] Vector store initialized successfully\n",
      "2025-01-15 11:52:33 [INFO] CouchbaseStorage initialized for type: crew_stm_demo\n",
      "2025-01-15 11:52:33 [INFO] Clearing existing data...\n",
      "2025-01-15 11:52:34 [INFO] Successfully reset collection: crew_stm_demo\n",
      "2025-01-15 11:52:34 [INFO] \n",
      "Saving test entries...\n",
      "2025-01-15 11:52:34 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-15 11:52:36 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-15 11:52:37 [INFO] Successfully saved entry with metadata: {'category': 'technology'}\n",
      "2025-01-15 11:52:37 [INFO] Saved entry with metadata: {'category': 'technology'}\n",
      "2025-01-15 11:52:37 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-15 11:52:39 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-15 11:52:39 [INFO] Successfully saved entry with metadata: {'category': 'database'}\n",
      "2025-01-15 11:52:39 [INFO] Saved entry with metadata: {'category': 'database'}\n",
      "2025-01-15 11:52:40 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-15 11:52:42 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-15 11:52:42 [INFO] Successfully saved entry with metadata: {'category': 'search'}\n",
      "2025-01-15 11:52:42 [INFO] Saved entry with metadata: {'category': 'search'}\n",
      "2025-01-15 11:52:42 [INFO] \n",
      "Testing search functionality...\n",
      "2025-01-15 11:52:42 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-15 11:52:44 [INFO] \n",
      "Search results for query: 'Tell me about vector search'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result:\n",
      "Context: A Google Street View image of a man loading a large white plastic bag into the boot of his car has helped unravel a murder case in a northern Spanish town, police say. The Google app allows users to see images of streets around the world - filmed by cars mounted with cameras. It captured the exact moment the body of the victim was allegedly being removed. Two people were arrested last month, accused of being responsible for the disappearance and murder of a man in October last year. His dismembered remains were found in a cemetery last week.\n",
      "\n",
      "This was the first time in 15 years that the Google car had been to the town of Tajueco, in the northern province of Soria. Officials say another photo sequence shows the blurred silhouette of someone transporting a large white bundle in a wheelbarrow. However, police said the images were not \"decisive\" in solving the case. The male victim, said by El Pais newspaper to be a 33-year-old Cuban national, was reported missing in October 2023 after a relative received text messages from the victim's phone which he found suspicious. The relative told police they said the victim had met a woman, was leaving Spain and would be getting rid of his phone. On 12 November this year, police arrested a woman said to be the missing man's partner and a man said to be her ex-partner. Earlier this month, a severely decomposed torso, thought to be the victim's, was dug up in a nearby cemetery. The accused have been remanded in custody and the investigation continues.\n",
      "Metadata: {}\n",
      "Score: 0.742242693901062\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result:\n",
      "Context: The logo of Google is seen outside Google Bay View facilities in Mountain View, California, US in August 2024\n",
      "\n",
      "Alphabet's Google proposed new limits to revenue-sharing agreements with companies including Apple which make Google's search engine the default on their devices and browsers. The suggestions stem from the US search giant's ongoing antitrust battle over its online search business. In August, US District Judge Amit Mehta ruled that Google illegally crushed its competition in search - a decision the company vowed to appeal. In a legal filing submitted Friday, Google said it should be allowed to continue entering into those contracts with other companies while widening the options it offers.\n",
      "\n",
      "These options include allowing different default search engines to be assigned to different platforms and browsing modes. Google's suggested remedies also call for the ability for partners to change their default search provider at least every 12 months. The proposals stand in stark contrast to the sweeping remedies suggested last month by the US Department of Justice (DOJ), which recommended that Judge Mehta force the firm to stop entering into revenue-sharing contracts. DOJ lawyers also demanded that Google sell Chrome, the world's most popular web browser. Google's search engine accounts for about 90% of all online searches globally, according to web traffic analysis platform Statcounter, external. In a statement, Google called DOJ's remedies \"overbroad\" and said even its own counterproposals, which were filed in response to a court-mandated deadline, would come at a cost to their partners. Judge Mehta is expected to issue a decision in the remedies phase of the landmark case by August, after a trial.\n",
      "Metadata: {}\n",
      "Score: 0.7384507656097412\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    # Initialize storage\n",
    "    logger.info(\"Initializing CouchbaseStorage...\")\n",
    "    storage = CouchbaseStorage(\"crew_stm_demo\")\n",
    "    \n",
    "    # Clear existing data\n",
    "    logger.info(\"Clearing existing data...\")\n",
    "    storage.reset()\n",
    "    \n",
    "    # Test saving entries\n",
    "    logger.info(\"\\nSaving test entries...\")\n",
    "    test_entries = [\n",
    "        (\"This is a test document about AI\", {\"category\": \"technology\"}),\n",
    "        (\"Couchbase provides excellent vector search capabilities\", {\"category\": \"database\"}),\n",
    "        (\"Vector embeddings help with semantic search\", {\"category\": \"search\"})\n",
    "    ]\n",
    "    \n",
    "    for text, metadata in test_entries:\n",
    "        try:\n",
    "            storage.save(text, metadata)\n",
    "            logger.info(f\"Saved entry with metadata: {metadata}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save entry: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    # Test searching\n",
    "    logger.info(\"\\nTesting search functionality...\")\n",
    "    query = \"Tell me about vector search\"\n",
    "    try:\n",
    "        results = storage.search(query, limit=2)\n",
    "        \n",
    "        logger.info(f\"\\nSearch results for query: '{query}'\")\n",
    "        print(\"-\"*80)\n",
    "        for result in results:\n",
    "            print(\"\\nResult:\")\n",
    "            print(f\"Context: {result['context']}\")\n",
    "            print(f\"Metadata: {result['metadata']}\")\n",
    "            print(f\"Score: {result['score']}\")\n",
    "            print(\"-\"*80)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Search operation failed: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Demo failed: {str(e)}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
