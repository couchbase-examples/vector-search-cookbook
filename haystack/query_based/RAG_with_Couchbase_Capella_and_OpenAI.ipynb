{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this guide, we will walk you through building a Retrieval Augmented Generation (RAG) application with Haystack orchestrating OpenAI models and Couchbase Capella. We will use the [gpt-4o](https://platform.openai.com/docs/models/gpt-4o) model for response generation and the [text-embedding-3-large](https://platform.openai.com/docs/guides/embeddings/embedding-models) model for generating embeddings.\n",
    "\n",
    "This notebook demonstrates how to build a RAG system using:\n",
    "- The [BBC News dataset](https://huggingface.co/datasets/RealTimeData/bbc_news_alltime) containing news articles\n",
    "- Couchbase Capella Hyperscale and Composite Vector Indexes for vector search\n",
    "- Haystack framework for the RAG pipeline\n",
    "- OpenAI for embeddings and text generation\n",
    "\n",
    "We leverage Couchbase's Hyperscale and Composite Vector Indexes to enable efficient semantic search at scale. Hyperscale indexes prioritize high-throughput vector similarity across billions of vectors with a compact on-disk footprint, while Composite indexes blend scalar predicates with a vector column to narrow candidate sets before similarity search. For a deeper dive into how these indexes work, see the [overview of Capella vector indexes](https://docs.couchbase.com/cloud/vector-index/vectors-and-indexes-overview.html).\n",
    "\n",
    "Semantic search goes beyond simple keyword matching by understanding the context and meaning behind the words in a query, making it an essential tool for applications that require intelligent information retrieval. This tutorial shows how to combine OpenAI Services and Haystack with Couchbase's Hyperscale and Composite Vector Indexes to deliver a production-ready RAG workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "\n",
    "## Create and Deploy Your Operational cluster on Capella\n",
    "\n",
    "To get started with Couchbase Capella, create an account and use it to deploy an operational cluster.\n",
    "\n",
    "To know more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Couchbase Capella Configuration\n",
    "\n",
    "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met:\n",
    "\n",
    "* Have a multi-node Capella cluster running the Data, Query, Index, and Search services.\n",
    "* Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the bucket (Read and Write) used in the application.\n",
    "* [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running.\n",
    "\n",
    "### OpenAI Models Setup\n",
    "\n",
    "In order to create the RAG application, we need an embedding model to ingest the documents for Vector Search and a large language model (LLM) for generating the responses based on the context. \n",
    "\n",
    "For this implementation, we'll use OpenAI's models which provide state-of-the-art performance for both embeddings and text generation:\n",
    "\n",
    "**Embedding Model**: We'll use OpenAI's `text-embedding-3-large` model, which provides high-quality embeddings with 3,072 dimensions for semantic search capabilities.\n",
    "\n",
    "**Large Language Model**: We'll use OpenAI's `gpt-4o` model for generating responses based on the retrieved context. This model offers excellent reasoning capabilities and can handle complex queries effectively.\n",
    "\n",
    "**Prerequisites for OpenAI Integration**:\n",
    "* Create an OpenAI account at [platform.openai.com](https://platform.openai.com)\n",
    "* Generate an API key from your OpenAI dashboard\n",
    "* Ensure you have sufficient credits or a valid payment method set up\n",
    "* Set up your API key as an environment variable or input it securely in the notebook\n",
    "\n",
    "For more details about OpenAI's models and pricing, please refer to the [OpenAI documentation](https://platform.openai.com/docs/models).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Necessary Libraries\n",
    "To build our RAG system, we need a set of libraries. The libraries we install handle everything from connecting to databases to performing AI tasks. Each library has a specific role: Couchbase libraries manage database operations, Haystack handles AI model integrations and pipeline management, and we will use the OpenAI SDK for generating embeddings and calling OpenAI's language models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=2.1.4 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (2.3.3)\n",
      "Requirement already satisfied: datasets>=2.14.5 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (4.4.1)\n",
      "Collecting setuptools>=75.8.0 (from -r requirements.txt (line 3))\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: couchbase-haystack==2.* in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (2.1.0)\n",
      "Collecting transformers>=4.49.0 (from transformers[torch]>=4.49.0->-r requirements.txt (line 5))\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tensorflow>=2.18.0 (from -r requirements.txt (line 6))\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: backports-datetime-fromisoformat in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from couchbase-haystack==2.*->-r requirements.txt (line 4)) (2.0.3)\n",
      "Requirement already satisfied: couchbase==4.* in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from couchbase-haystack==2.*->-r requirements.txt (line 4)) (4.5.0)\n",
      "Requirement already satisfied: haystack-ai>=2.3.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from couchbase-haystack==2.*->-r requirements.txt (line 4)) (2.20.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from pandas>=2.1.4->-r requirements.txt (line 1)) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from pandas>=2.1.4->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from pandas>=2.1.4->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from pandas>=2.1.4->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: filelock in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from datasets>=2.14.5->-r requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from datasets>=2.14.5->-r requirements.txt (line 2)) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from datasets>=2.14.5->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from datasets>=2.14.5->-r requirements.txt (line 2)) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from datasets>=2.14.5->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from datasets>=2.14.5->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from datasets>=2.14.5->-r requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from datasets>=2.14.5->-r requirements.txt (line 2)) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.5->-r requirements.txt (line 2)) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from datasets>=2.14.5->-r requirements.txt (line 2)) (1.1.4)\n",
      "Requirement already satisfied: packaging in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from datasets>=2.14.5->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from datasets>=2.14.5->-r requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.5->-r requirements.txt (line 2)) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.14.5->-r requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.14.5->-r requirements.txt (line 2)) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.14.5->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets>=2.14.5->-r requirements.txt (line 2)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.14.5->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.5->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.5->-r requirements.txt (line 2)) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.5->-r requirements.txt (line 2)) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.5->-r requirements.txt (line 2)) (4.15.0)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets>=2.14.5->-r requirements.txt (line 2))\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.49.0->transformers[torch]>=4.49.0->-r requirements.txt (line 5))\n",
      "  Using cached regex-2025.11.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.49.0->transformers[torch]>=4.49.0->-r requirements.txt (line 5))\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.49.0->transformers[torch]>=4.49.0->-r requirements.txt (line 5))\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading protobuf-6.33.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from tensorflow>=2.18.0->-r requirements.txt (line 6)) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading wrapt-2.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading h5py-3.15.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading ml_dtypes-0.5.3-cp313-cp313-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.14.5->-r requirements.txt (line 2)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.14.5->-r requirements.txt (line 2)) (2.5.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading pillow-12.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.5->-r requirements.txt (line 2)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.5->-r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.5->-r requirements.txt (line 2)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.5->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.5->-r requirements.txt (line 2)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.5->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.5->-r requirements.txt (line 2)) (1.22.0)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: docstring-parser in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (0.17.0)\n",
      "Requirement already satisfied: filetype in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: haystack-experimental in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (0.14.2)\n",
      "Requirement already satisfied: jinja2 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: jsonschema in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (4.25.1)\n",
      "Requirement already satisfied: lazy-imports in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: more-itertools in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (10.8.0)\n",
      "Requirement already satisfied: networkx in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (3.5)\n",
      "Requirement already satisfied: openai>=1.99.2 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (2.8.0)\n",
      "Requirement already satisfied: posthog!=3.12.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (7.0.1)\n",
      "Requirement already satisfied: pydantic in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (2.12.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (9.1.2)\n",
      "Requirement already satisfied: rich in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow>=2.18.0->-r requirements.txt (line 6)) (14.2.0)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow>=2.18.0->-r requirements.txt (line 6))\n",
      "  Downloading optree-0.18.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from pydantic->haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from pydantic->haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from pydantic->haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from posthog!=3.12.0->haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (2.2.1)\n",
      "Collecting torch>=2.2 (from transformers[torch]>=4.49.0->-r requirements.txt (line 5))\n",
      "  Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch]>=4.49.0->-r requirements.txt (line 5))\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: psutil in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from accelerate>=0.26.0->transformers[torch]>=4.49.0->-r requirements.txt (line 5)) (7.1.3)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.2->transformers[torch]>=4.49.0->-r requirements.txt (line 5))\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.2->transformers[torch]>=4.49.0->-r requirements.txt (line 5))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow>=2.18.0->-r requirements.txt (line 6)) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from jsonschema->haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from jsonschema->haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from jsonschema->haystack-ai>=2.3.0->couchbase-haystack==2.*->-r requirements.txt (line 4)) (0.29.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow>=2.18.0->-r requirements.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow>=2.18.0->-r requirements.txt (line 6)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow>=2.18.0->-r requirements.txt (line 6)) (0.1.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets>=2.14.5->-r requirements.txt (line 2)) (8.3.1)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-macosx_12_0_arm64.whl (200.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.7/200.7 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp313-cp313-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp313-cp313-macosx_10_13_universal2.whl (663 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.8/663.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp313-cp313-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.1-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Using cached regex-2025.11.3-cp313-cp313-macosx_11_0_arm64.whl (288 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-2.0.1-cp313-cp313-macosx_11_0_arm64.whl (61 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp313-cp313-macosx_11_0_arm64.whl (346 kB)\n",
      "Downloading pillow-12.0.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: namex, mpmath, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, sympy, setuptools, safetensors, regex, protobuf, pillow, optree, opt_einsum, ml_dtypes, markdown, h5py, grpcio, google_pasta, gast, absl-py, torch, tensorboard, huggingface-hub, astunparse, tokenizers, keras, accelerate, transformers, tensorflow\n",
      "\u001b[2K  Attempting uninstall: huggingface-hub[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m25/33\u001b[0m [tensorboard]\n",
      "\u001b[2K    Found existing installation: huggingface_hub 1.1.4━━━━━━━━\u001b[0m \u001b[32m25/33\u001b[0m [tensorboard]\n",
      "\u001b[2K    Uninstalling huggingface_hub-1.1.4:[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m25/33\u001b[0m [tensorboard]\n",
      "\u001b[2K      Successfully uninstalled huggingface_hub-1.1.4m━━━━━━━━━\u001b[0m \u001b[32m25/33\u001b[0m [tensorboard]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/33\u001b[0m [tensorflow]3\u001b[0m [tensorflow]s]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 accelerate-1.11.0 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 huggingface-hub-0.36.0 keras-3.12.0 libclang-18.1.1 markdown-3.10 ml_dtypes-0.5.3 mpmath-1.3.0 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 pillow-12.0.0 protobuf-6.33.1 regex-2025.11.3 safetensors-0.6.2 setuptools-80.9.0 sympy-1.14.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 tokenizers-0.22.1 torch-2.9.1 transformers-4.57.1 werkzeug-3.1.3 wheel-0.45.1 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries\n",
    "The script starts by importing a series of libraries required for various tasks, including handling JSON, logging, time tracking, Couchbase connections, Haystack components for RAG pipeline, embedding generation, and dataset loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/viraj.agarwal/Tasks/Task16.5/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import base64\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.exceptions import CouchbaseException\n",
    "from couchbase.options import ClusterOptions, KnownConfigProfiles, QueryOptions\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from haystack import Pipeline, Document, GeneratedAnswer\n",
    "from haystack.components.embedders import OpenAIDocumentEmbedder, OpenAITextEmbedder\n",
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.preprocessors import DocumentCleaner\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.utils import Secret\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from couchbase_haystack import (\n",
    "    CouchbaseQueryDocumentStore, \n",
    "    CouchbaseQueryEmbeddingRetriever,\n",
    "    QueryVectorSearchType, \n",
    "    QueryVectorSearchSimilarity,\n",
    "    CouchbasePasswordAuthenticator,\n",
    "    CouchbaseClusterOptions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Sensitive Information\n",
    "In this section, we prompt the user to input essential configuration settings needed. These settings include sensitive information like database credentials, collection names, and API keys. Instead of hardcoding these details into the script, we request the user to provide them at runtime, ensuring flexibility and security.\n",
    "\n",
    "The script also validates that all required inputs are provided, raising an error if any crucial information is missing. This approach ensures that your integration is both secure and correctly configured without hardcoding sensitive information, enhancing the overall security and maintainability of your code.\n",
    "\n",
    "**OPENAI_API_KEY** is your OpenAI API key which can be obtained from your OpenAI dashboard at [platform.openai.com](https://platform.openai.com/api-keys).\n",
    "\n",
    "**INDEX_NAME** is the name of the Hyperscale or Composite Vector Index we will create for vector search operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB_CONNECTION_STRING = input(\"Couchbase Cluster URL (default: localhost): \") or \"couchbase://localhost\"\n",
    "CB_USERNAME = input(\"Couchbase Username (default: admin): \") or \"admin\"\n",
    "CB_PASSWORD = input(\"Couchbase password (default: Password@12345): \") or \"Password@12345\"\n",
    "CB_BUCKET_NAME = input(\"Couchbase Bucket: \")\n",
    "SCOPE_NAME = input(\"Couchbase Scope: \")\n",
    "COLLECTION_NAME = input(\"Couchbase Collection: \")\n",
    "INDEX_NAME = input(\"Vector Search Index: \")\n",
    "OPENAI_API_KEY = input(\"OpenAI API Key: \")\n",
    "\n",
    "# Check if the variables are correctly loaded\n",
    "if not all([CB_CONNECTION_STRING, CB_USERNAME, CB_PASSWORD, CB_BUCKET_NAME, SCOPE_NAME, COLLECTION_NAME, INDEX_NAME, OPENAI_API_KEY]):\n",
    "    raise ValueError(\"All configuration variables must be provided.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Logging\n",
    "Logging is essential for tracking the execution of our script and debugging any issues that may arise. We set up a logger that will display information about the script's progress, including timestamps and log levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to Couchbase Capella\n",
    "The next step is to establish a connection to our Couchbase Capella cluster. This connection will allow us to interact with the database, store and retrieve documents, and perform vector searches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:36:34,556 - INFO - Successfully connected to the Couchbase cluster\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize the Couchbase Cluster\n",
    "    auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
    "    options = ClusterOptions(auth)\n",
    "    options.apply_profile(KnownConfigProfiles.WanDevelopment)\n",
    "    \n",
    "    # Connect to the cluster\n",
    "    cluster = Cluster(CB_CONNECTION_STRING, options)\n",
    "    \n",
    "    # Wait for the cluster to be ready\n",
    "    cluster.wait_until_ready(timedelta(seconds=5))\n",
    "    logging.info(\"Successfully connected to the Couchbase cluster\")\n",
    "except CouchbaseException as e:\n",
    "    raise RuntimeError(f\"Failed to connect to Couchbase: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up the Bucket, Scope, and Collection\n",
    "Before we can store our data, we need to ensure that the appropriate bucket, scope, and collection exist in our Couchbase cluster. The code below checks if these components exist and creates them if they don't, providing a foundation for storing our vector embeddings and documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'b' already exists.\n",
      "Scope 's' already exists.\n",
      "Collection 'c' already exists in scope 's'.\n"
     ]
    }
   ],
   "source": [
    "from couchbase.management.buckets import CreateBucketSettings\n",
    "import json\n",
    "\n",
    "# Create bucket if it does not exist\n",
    "bucket_manager = cluster.buckets()\n",
    "try:\n",
    "    bucket_manager.get_bucket(CB_BUCKET_NAME)\n",
    "    print(f\"Bucket '{CB_BUCKET_NAME}' already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Bucket '{CB_BUCKET_NAME}' does not exist. Creating bucket...\")\n",
    "    bucket_settings = CreateBucketSettings(name=CB_BUCKET_NAME, ram_quota_mb=500)\n",
    "    bucket_manager.create_bucket(bucket_settings)\n",
    "    print(f\"Bucket '{CB_BUCKET_NAME}' created successfully.\")\n",
    "\n",
    "# Create scope and collection if they do not exist\n",
    "collection_manager = cluster.bucket(CB_BUCKET_NAME).collections()\n",
    "scopes = collection_manager.get_all_scopes()\n",
    "scope_exists = any(scope.name == SCOPE_NAME for scope in scopes)\n",
    "\n",
    "if scope_exists:\n",
    "    print(f\"Scope '{SCOPE_NAME}' already exists.\")\n",
    "else:\n",
    "    print(f\"Scope '{SCOPE_NAME}' does not exist. Creating scope...\")\n",
    "    collection_manager.create_scope(SCOPE_NAME)\n",
    "    print(f\"Scope '{SCOPE_NAME}' created successfully.\")\n",
    "\n",
    "collections = [collection.name for scope in scopes if scope.name == SCOPE_NAME for collection in scope.collections]\n",
    "collection_exists = COLLECTION_NAME in collections\n",
    "\n",
    "if collection_exists:\n",
    "    print(f\"Collection '{COLLECTION_NAME}' already exists in scope '{SCOPE_NAME}'.\")\n",
    "else:\n",
    "    print(f\"Collection '{COLLECTION_NAME}' does not exist in scope '{SCOPE_NAME}'. Creating collection...\")\n",
    "    collection_manager.create_collection(collection_name=COLLECTION_NAME, scope_name=SCOPE_NAME)\n",
    "    print(f\"Collection '{COLLECTION_NAME}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the BBC News Dataset\n",
    "To build a RAG engine, we need data to search through. We use the [BBC Realtime News dataset](https://huggingface.co/datasets/RealTimeData/bbc_news_alltime), a dataset with up-to-date BBC news articles grouped by month. This dataset contains articles that were created after the LLM was trained. It will showcase the use of RAG to augment the LLM. \n",
    "\n",
    "The BBC News dataset's varied content allows us to simulate real-world scenarios where users ask complex questions, enabling us to fine-tune our RAG's ability to understand and respond to various types of queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the BBC News dataset with 2687 rows\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    news_dataset = load_dataset('RealTimeData/bbc_news_alltime', '2024-12', split=\"train\")\n",
    "    print(f\"Loaded the BBC News dataset with {len(news_dataset)} rows\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading TREC dataset: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns: ['title', 'published_date', 'authors', 'description', 'section', 'content', 'link', 'top_image']\n",
      "\n",
      "First two examples:\n",
      "{'title': [\"Pakistan protest: Bushra Bibi's march for Imran Khan disappeared - BBC News\", 'Lockdown DIY linked to Walleys Quarry gases - BBC News'], 'published_date': ['2024-12-01', '2024-12-01'], 'authors': ['https://www.facebook.com/bbcnews', 'https://www.facebook.com/bbcnews'], 'description': [\"Imran Khan's third wife guided protesters to the heart of the capital - and then disappeared.\", 'An academic says an increase in plasterboard sent to landfill could be behind a spike in smells.'], 'section': ['Asia', 'Stoke & Staffordshire'], 'content': ['Bushra Bibi led a protest to free Imran Khan - what happened next is a mystery\\n\\nImran Khan\\'s wife, Bushra Bibi, encouraged protesters into the heart of Pakistan\\'s capital, Islamabad\\n\\nA charred lorry, empty tear gas shells and posters of former Pakistan Prime Minister Imran Khan - it was all that remained of a massive protest led by Khan’s wife, Bushra Bibi, that had sent the entire capital into lockdown. Just a day earlier, faith healer Bibi - wrapped in a white shawl, her face covered by a white veil - stood atop a shipping container on the edge of the city as thousands of her husband’s devoted followers waved flags and chanted slogans beneath her. It was the latest protest to flare since Khan, the 72-year-old cricketing icon-turned-politician, was jailed more than a year ago after falling foul of the country\\'s influential military which helped catapult him to power. “My children and my brothers! You have to stand with me,” Bibi cried on Tuesday afternoon, her voice cutting through the deafening roar of the crowd. “But even if you don’t,” she continued, “I will still stand firm. “This is not just about my husband. It is about this country and its leader.” It was, noted some watchers of Pakistani politics, her political debut. But as the sun rose on Wednesday morning, there was no sign of Bibi, nor the thousands of protesters who had marched through the country to the heart of the capital, demanding the release of their jailed leader. While other PMs have fallen out with Pakistan\\'s military in the past, Khan\\'s refusal to stay quiet behind bars is presenting an extraordinary challenge - escalating the standoff and leaving the country deeply divided. Exactly what happened to the so-called “final march”, and Bibi, when the city went dark is still unclear. All eyewitnesses like Samia* can say for certain is that the lights went out suddenly, plunging D Chowk, the square where they had gathered, into blackness.\\n\\nWithin a day of arriving, the protesters had scattered - leaving behind Bibi\\'s burnt-out vehicle\\n\\nAs loud screams and clouds of tear gas blanketed the square, Samia describes holding her husband on the pavement, bloodied from a gun shot to his shoulder. \"Everyone was running for their lives,\" she later told BBC Urdu from a hospital in Islamabad, adding it was \"like doomsday or a war\". \"His blood was on my hands and the screams were unending.” But how did the tide turn so suddenly and decisively? Just hours earlier, protesters finally reached D Chowk late afternoon on Tuesday. They had overcome days of tear gas shelling and a maze of barricaded roads to get to the city centre. Many of them were supporters and workers of the Pakistan Tehreek-e-Insaf (PTI), the party led by Khan. He had called for the march from his jail cell, where he has been for more than a year on charges he says are politically motivated. Now Bibi - his third wife, a woman who had been largely shrouded in mystery and out of public view since their unexpected wedding in 2018 - was leading the charge. “We won’t go back until we have Khan with us,” she declared as the march reached D Chowk, deep in the heart of Islamabad’s government district.\\n\\nThousands had marched for days to reach Islamabad, demanding former Prime Minister Imran Khan be released from jail\\n\\nInsiders say even the choice of destination - a place where her husband had once led a successful sit in - was Bibi’s, made in the face of other party leader’s opposition, and appeals from the government to choose another gathering point. Her being at the forefront may have come as a surprise. Bibi, only recently released from prison herself, is often described as private and apolitical. Little is known about her early life, apart from the fact she was a spiritual guide long before she met Khan. Her teachings, rooted in Sufi traditions, attracted many followers - including Khan himself. Was she making her move into politics - or was her sudden appearance in the thick of it a tactical move to keep Imran Khan’s party afloat while he remains behind bars? For critics, it was a move that clashed with Imran Khan’s oft-stated opposition to dynastic politics. There wasn’t long to mull the possibilities. After the lights went out, witnesses say that police started firing fresh rounds of tear gas at around 21:30 local time (16:30 GMT). The crackdown was in full swing just over an hour later. At some point, amid the chaos, Bushra Bibi left. Videos on social media appeared to show her switching cars and leaving the scene. The BBC couldn’t verify the footage. By the time the dust settled, her container had already been set on fire by unknown individuals. By 01:00 authorities said all the protesters had fled.\\n\\nSecurity was tight in the city, and as night fell, lights were switched off - leaving many in the dark as to what exactly happened next\\n\\nEyewitnesses have described scenes of chaos, with tear gas fired and police rounding up protesters. One, Amin Khan, said from behind an oxygen mask that he joined the march knowing that, \"either I will bring back Imran Khan or I will be shot\". The authorities have have denied firing at the protesters. They also said some of the protesters were carrying firearms. The BBC has seen hospital records recording patients with gunshot injuries. However, government spokesperson Attaullah Tarar told the BBC that hospitals had denied receiving or treating gunshot wound victims. He added that \"all security personnel deployed on the ground have been forbidden\" from having live ammunition during protests. But one doctor told BBC Urdu that he had never done so many surgeries for gunshot wounds in a single night. \"Some of the injured came in such critical condition that we had to start surgery right away instead of waiting for anaesthesia,\" he said. While there has been no official toll released, the BBC has confirmed with local hospitals that at least five people have died. Police say at least 500 protesters were arrested that night and are being held in police stations. The PTI claims some people are missing. And one person in particular hasn’t been seen in days: Bushra Bibi.\\n\\nThe next morning, the protesters were gone - leaving behind just wrecked cars and smashed glass\\n\\nOthers defended her. “It wasn’t her fault,” insisted another. “She was forced to leave by the party leaders.” Political commentators have been more scathing. “Her exit damaged her political career before it even started,” said Mehmal Sarfraz, a journalist and analyst. But was that even what she wanted? Khan has previously dismissed any thought his wife might have her own political ambitions - “she only conveys my messages,” he said in a statement attributed to him on his X account.\\n\\nImran Khan and Bushra Bibi, pictured here arriving at court in May 2023, married in 2018\\n\\nSpeaking to BBC Urdu, analyst Imtiaz Gul calls her participation “an extraordinary step in extraordinary circumstances\". Gul believes Bushra Bibi’s role today is only about “keeping the party and its workers active during Imran Khan’s absence”. It is a feeling echoed by some PTI members, who believe she is “stepping in only because Khan trusts her deeply”. Insiders, though, had often whispered that she was pulling the strings behind the scenes - advising her husband on political appointments and guiding high-stakes decisions during his tenure. A more direct intervention came for the first time earlier this month, when she urged a meeting of PTI leaders to back Khan’s call for a rally. Pakistan’s defence minister Khawaja Asif accused her of “opportunism”, claiming she sees “a future for herself as a political leader”. But Asma Faiz, an associate professor of political science at Lahore University of Management Sciences, suspects the PTI’s leadership may have simply underestimated Bibi. “It was assumed that there was an understanding that she is a non-political person, hence she will not be a threat,” she told the AFP news agency. “However, the events of the last few days have shown a different side of Bushra Bibi.” But it probably doesn’t matter what analysts and politicians think. Many PTI supporters still see her as their connection to Imran Khan. It was clear her presence was enough to electrify the base. “She is the one who truly wants to get him out,” says Asim Ali, a resident of Islamabad. “I trust her. Absolutely!”', 'Walleys Quarry was ordered not to accept any new waste as of Friday\\n\\nA chemist and former senior lecturer in environmental sustainability has said powerful odours from a controversial landfill site may be linked to people doing more DIY during the Covid-19 pandemic. Complaints about Walleys Quarry in Silverdale, Staffordshire – which was ordered to close as of Friday – increased significantly during and after coronavirus lockdowns. Issuing the closure notice, the Environment Agency described management of the site as poor, adding it had exhausted all other enforcement tactics at premises where gases had been noxious and periodically above emission level guidelines - which some campaigners linked to ill health locally. Dr Sharon George, who used to teach at Keele University, said she had been to the site with students and found it to be clean and well-managed, and suggested an increase in plasterboard heading to landfills in 2020 could be behind a spike in stenches.\\n\\n“One of the materials that is particularly bad for producing odours and awful emissions is plasterboard,\" she said. “That’s one of the theories behind why Walleys Quarry got worse at that time.” She said the landfill was in a low-lying area, and that some of the gases that came from the site were quite heavy. “They react with water in the atmosphere, so some of the gases you smell can be quite awful and not very good for our health. “It’s why, on some days when it’s colder and muggy and a bit misty, you can smell it more.” Dr George added: “With any landfill, you’re putting things into the ground – and when you put things into the ground, if they can they will start to rot. When they start to rot they’re going to give off gases.” She believed Walleys Quarry’s proximity to people’s homes was another major factor in the amount of complaints that arose from its operation. “If you’ve got a gas that people can smell, they’re going to report it much more than perhaps a pollutant that might go unnoticed.”\\n\\nRebecca Currie said she did not think the site would ever be closed\\n\\nLocal resident and campaigner Rebecca Currie said the closure notice served to Walleys Quarry was \"absolutely amazing\". Her son Matthew has had breathing difficulties after being born prematurely with chronic lung disease, and Ms Currie says the site has made his symptoms worse. “I never thought this day was going to happen,” she explained. “We fought and fought for years.” She told BBC Midlands Today: “Our community have suffered. We\\'ve got kids who are really poorly, people have moved homes.”\\n\\nComplaints about Walleys Quarry to Newcastle-under-Lyme Borough Council exceeded 700 in November, the highest amount since 2021 according to council leader Simon Tagg. The Environment Agency (EA), which is responsible for regulating landfill sites, said it had concluded further operation at the site could result in \"significant long-term pollution\". A spokesperson for Walley\\'s Quarry Ltd said the firm rejected the EA\\'s accusations of poor management, and would be challenging the closure notice. Dr George said she believed the EA was likely to be erring on the side of caution and public safety, adding safety standards were strict. She said a lack of landfill space in the country overall was one of the broader issues that needed addressing. “As people, we just keep using stuff and then have nowhere to put it, and then when we end up putting it in places like Walleys Quarry that is next to houses, I think that’s where the problems are.”\\n\\nTell us which stories we should cover in Staffordshire'], 'link': ['http://www.bbc.co.uk/news/articles/cvg02lvj1e7o', 'http://www.bbc.co.uk/news/articles/c5yg1v16nkpo'], 'top_image': ['https://ichef.bbci.co.uk/ace/standard/3840/cpsprodpb/9975/live/b22229e0-ad5a-11ef-83bc-1153ed943d1c.jpg', 'https://ichef.bbci.co.uk/ace/standard/3840/cpsprodpb/0896/live/55209f80-adb2-11ef-8f6c-f1a86bb055ec.jpg']}\n"
     ]
    }
   ],
   "source": [
    "# Print the first two examples from the dataset\n",
    "print(\"Dataset columns:\", news_dataset.column_names)\n",
    "print(\"\\nFirst two examples:\")\n",
    "print(news_dataset[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for RAG\n",
    "\n",
    "We need to extract the context passages from the dataset to use as our knowledge base for the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1749 unique articles in our database.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "news_articles = news_dataset\n",
    "unique_articles = {}\n",
    "\n",
    "for article in news_articles:\n",
    "    content = article.get(\"content\")\n",
    "    if content:\n",
    "        content_hash = hashlib.md5(content.encode()).hexdigest()  # Generate hash of content\n",
    "        if content_hash not in unique_articles:\n",
    "            unique_articles[content_hash] = article  # Store full article\n",
    "\n",
    "unique_news_articles = list(unique_articles.values())  # Convert back to list\n",
    "\n",
    "print(f\"We have {len(unique_news_articles)} unique articles in our database.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Embeddings using OpenAI\n",
    "Embeddings are numerical representations of text that capture semantic meaning. Unlike keyword-based search, embeddings enable semantic search to understand context and retrieve documents that are conceptually similar even without exact keyword matches. We'll use OpenAI's `text-embedding-3-large` model to create high-quality embeddings with 3,072 dimensions. This model transforms our text data into vector representations that can be efficiently searched using Haystack's OpenAI document embedder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created embedding models\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Set up the document embedder for processing documents\n",
    "    document_embedder = OpenAIDocumentEmbedder(\n",
    "        api_key=Secret.from_token(OPENAI_API_KEY),\n",
    "        model=\"text-embedding-3-large\"\n",
    "    )\n",
    "    \n",
    "    # Set up the text embedder for query processing\n",
    "    rag_embedder = OpenAITextEmbedder(\n",
    "        api_key=Secret.from_token(OPENAI_API_KEY),\n",
    "        model=\"text-embedding-3-large\"\n",
    "    )\n",
    "    \n",
    "    print(\"Successfully created embedding models\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error creating embedding models: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Embeddings Model\n",
    "We can test the text embeddings model by generating an embedding for a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:36:51,924 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding dimension: 3072\n"
     ]
    }
   ],
   "source": [
    "test_result = rag_embedder.run(text=\"this is a test sentence\")\n",
    "test_embedding = test_result[\"embedding\"]\n",
    "print(f\"Embedding dimension: {len(test_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up the Couchbase Vector Document Store\n",
    "The Couchbase document store configuration enables both Hyperscale and Composite Vector Indexes. This stores documents from the dataset while keeping embeddings ready for high-performance semantic search, and it scales to billions of vectors through Haystack's Couchbase integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created Couchbase vector document store\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Create the Couchbase vector document store\n",
    "    document_store = CouchbaseQueryDocumentStore(\n",
    "        cluster_connection_string=Secret.from_token(CB_CONNECTION_STRING),\n",
    "        authenticator=CouchbasePasswordAuthenticator(\n",
    "            username=Secret.from_token(CB_USERNAME),\n",
    "            password=Secret.from_token(CB_PASSWORD)\n",
    "        ),\n",
    "        cluster_options=CouchbaseClusterOptions(\n",
    "            profile=KnownConfigProfiles.WanDevelopment,\n",
    "        ),\n",
    "        bucket=CB_BUCKET_NAME,\n",
    "        scope=SCOPE_NAME,\n",
    "        collection=COLLECTION_NAME,\n",
    "        search_type=QueryVectorSearchType.ANN,\n",
    "        similarity=QueryVectorSearchSimilarity.L2\n",
    "    )\n",
    "    print(\"Successfully created Couchbase vector document store\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to create Couchbase vector document store: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Haystack Documents\n",
    "In this section, we'll process our news articles and create Haystack Document objects.\n",
    "Each Document is created with specific metadata that will be used for retrieval and generation.\n",
    "We'll observe examples of the document content to understand how the documents are structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document content preview:\n",
      "Content: Bushra Bibi led a protest to free Imran Khan - what happened next is a mystery\n",
      "\n",
      "Imran Khan's wife, Bushra Bibi, encouraged protesters into the heart of Pakistan's capital, Islamabad\n",
      "\n",
      "A charred lorry, ...\n",
      "Metadata: {'title': \"Pakistan protest: Bushra Bibi's march for Imran Khan disappeared - BBC News\", 'description': \"Imran Khan's third wife guided protesters to the heart of the capital - and then disappeared.\", 'published_date': '2024-12-01', 'link': 'http://www.bbc.co.uk/news/articles/cvg02lvj1e7o'}\n",
      "Created 1749 documents\n"
     ]
    }
   ],
   "source": [
    "haystack_documents = []\n",
    "# Process and store documents\n",
    "for article in unique_news_articles:  # Process all unique articles\n",
    "    try:\n",
    "        document = Document(\n",
    "            content=article[\"content\"],\n",
    "            meta={\n",
    "                \"title\": article[\"title\"],\n",
    "                \"description\": article[\"description\"],\n",
    "                \"published_date\": article[\"published_date\"],\n",
    "                \"link\": article[\"link\"],\n",
    "            }\n",
    "        )\n",
    "        haystack_documents.append(document)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create document: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Observing an example of the document content\n",
    "print(\"Document content preview:\")\n",
    "print(f\"Content: {haystack_documents[0].content[:200]}...\")\n",
    "print(f\"Metadata: {haystack_documents[0].meta}\")\n",
    "\n",
    "print(f\"Created {len(haystack_documents)} documents\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Running the Indexing Pipeline\n",
    "\n",
    "In this section, we'll create an indexing pipeline to process our documents. The pipeline will:\n",
    "\n",
    "1. Split the documents into smaller chunks using the DocumentSplitter\n",
    "2. Generate embeddings for each chunk using our document embedder\n",
    "3. Store these chunks with their embeddings in our Couchbase document store\n",
    "\n",
    "This process transforms our raw documents into a searchable knowledge base that can be queried semantically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x123acba10>\n",
       "🚅 Components\n",
       "  - cleaner: DocumentCleaner\n",
       "  - embedder: OpenAIDocumentEmbedder\n",
       "  - writer: DocumentWriter\n",
       "🛤️ Connections\n",
       "  - cleaner.documents -> embedder.documents (list[Document])\n",
       "  - embedder.documents -> writer.documents (list[Document])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Process documents: split into chunks, generate embeddings, and store in document store\n",
    "# Create indexing pipeline\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(\"cleaner\", DocumentCleaner())\n",
    "indexing_pipeline.add_component(\"embedder\", document_embedder)\n",
    "indexing_pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store))\n",
    "\n",
    "indexing_pipeline.connect(\"cleaner.documents\", \"embedder.documents\")\n",
    "indexing_pipeline.connect(\"embedder.documents\", \"writer.documents\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Indexing Pipeline\n",
    "\n",
    "Execute the pipeline for processing and indexing BCC news documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:42:29,794 - INFO - Running component cleaner\n",
      "2025-11-17 14:42:29,800 - INFO - Running component embedder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:42:31,149 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 1it [00:02,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:42:33,448 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 2it [00:04,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:42:35,608 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 3it [00:06,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:42:36,509 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 4it [00:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:42:37,301 - INFO - Running component writer\n",
      "Indexed 100 document chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the indexing pipeline\n",
    "if haystack_documents:\n",
    "    result = indexing_pipeline.run({\"cleaner\": {\"documents\": haystack_documents[:100]}})\n",
    "    print(f\"Indexed {result['writer']['documents_written']} document chunks\")\n",
    "else:\n",
    "    print(\"No documents created. Skipping indexing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenAI's Large Language Model (LLM)\n",
    "Large language models are AI systems that are trained to understand and generate human language. We'll be using OpenAI's `gpt-4o` model to process user queries and generate meaningful responses based on the retrieved context from our Couchbase document store. This model is a key component of our RAG system, allowing it to go beyond simple keyword matching and truly understand the intent behind a query. By integrating OpenAI's LLM, we equip our RAG system with the ability to interpret complex queries, understand the nuances of language, and provide more accurate and contextually relevant responses.\n",
    "\n",
    "The language model's ability to understand context and generate coherent responses is what makes our RAG system truly intelligent. It can not only find the right information but also present it in a way that is useful and understandable to the user.\n",
    "\n",
    "The LLM is configured using Haystack's OpenAI generator component with your OpenAI API key for seamless integration with their services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:42:40,424 - INFO - Successfully created the OpenAI generator\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Set up the LLM generator\n",
    "    generator = OpenAIGenerator(\n",
    "        api_key=Secret.from_token(OPENAI_API_KEY),\n",
    "        model=\"gpt-4o\"\n",
    "    )\n",
    "    logging.info(\"Successfully created the OpenAI generator\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error creating OpenAI generator: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the RAG Pipeline\n",
    "\n",
    "In this section, we'll create a RAG pipeline using Haystack components. This pipeline serves as the foundation for our RAG system, enabling semantic search capabilities and efficient retrieval of relevant information.\n",
    "\n",
    "The RAG pipeline provides a complete workflow that allows us to:\n",
    "1. Perform semantic searches based on user queries\n",
    "2. Retrieve the most relevant documents or chunks\n",
    "3. Generate contextually appropriate responses using our LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:42:41,774 - WARNING - PromptBuilder has 2 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n",
      "Successfully created RAG pipeline\n"
     ]
    }
   ],
   "source": [
    "# Define RAG prompt template\n",
    "prompt_template = \"\"\"\n",
    "Given these documents, answer the question.\\nDocuments:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "\n",
    "\\nQuestion: {{question}}\n",
    "\\nAnswer:\n",
    "\"\"\"\n",
    "\n",
    "# Create the RAG pipeline\n",
    "rag_pipeline = Pipeline()\n",
    "\n",
    "# Add components to the pipeline\n",
    "rag_pipeline.add_component(\n",
    "    \"query_embedder\",\n",
    "    rag_embedder,\n",
    ")\n",
    "rag_pipeline.add_component(\"retriever\", CouchbaseQueryEmbeddingRetriever(document_store=document_store))\n",
    "rag_pipeline.add_component(\"prompt_builder\", PromptBuilder(template=prompt_template))\n",
    "rag_pipeline.add_component(\"llm\",generator)\n",
    "rag_pipeline.add_component(\"answer_builder\", AnswerBuilder())\n",
    "\n",
    "# Connect RAG components\n",
    "rag_pipeline.connect(\"query_embedder\", \"retriever.query_embedding\")\n",
    "rag_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n",
    "rag_pipeline.connect(\"llm.replies\", \"answer_builder.replies\")\n",
    "rag_pipeline.connect(\"llm.meta\", \"answer_builder.meta\")\n",
    "rag_pipeline.connect(\"retriever\", \"answer_builder.documents\")\n",
    "\n",
    "print(\"Successfully created RAG pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG) with Couchbase and Haystack\n",
    "\n",
    "Let's test our RAG system by performing a semantic search on a sample query. In this example, we'll use a question about Pep Guardiola's reaction to Manchester City's recent form. The RAG system will:\n",
    "\n",
    "1. Process the natural language query\n",
    "2. Search through our document store for relevant information\n",
    "3. Retrieve the most semantically similar documents\n",
    "4. Generate a comprehensive response using the LLM\n",
    "\n",
    "This demonstrates how our system combines the power of vector search with language model capabilities to provide accurate, contextual answers based on the information in our database.\n",
    "\n",
    "**Note:** By default, without any Hyperscale or Composite Vector Index, Couchbase falls back to linear brute-force search that compares the query vector against every document in the collection. This works for small datasets but can become slow as the dataset grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:42:43,017 - INFO - Running component query_embedder\n",
      "2025-11-17 14:42:43,636 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-17 14:42:43,853 - INFO - Running component retriever\n",
      "2025-11-17 14:42:43,990 - INFO - Running component prompt_builder\n",
      "2025-11-17 14:42:43,990 - INFO - Running component llm\n",
      "2025-11-17 14:42:45,914 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-17 14:42:45,935 - INFO - Running component answer_builder\n",
      "=== Retrieved Documents ===\n",
      "Id: 3bd611696904f038e5ceff530ab97539a34e6893001e6e71d5518ecfa4a729ff Title: New Zealand v England: Brydon Carse repays faith with Christchurch haul - BBC Sport\n",
      "Id: 5cc142cd0535bcb62c2bce08e87714a2ddab9590c06e2935213c0341360953b1 Title: Ireland 22-19 Australia: 'No emotion' for Andy Farrell in winning send-off before Lions sabbatical - BBC Sport\n",
      "Id: 96601a80eaf87c11a39a5cada79bdaa50e227cb03ed36e3bb0573c6297767702 Title: Watch: CCTV shows how Daniel Khalife escaped - BBC News\n",
      "Id: 875d0e214cbc2d7d0bd475906cf50b74d042a831c7b00b301c39a5bb2d387f07 Title: Troy Deeney's Team of the Week: Saka, Kluivert, Schade, Rashford - BBC Sport\n",
      "Id: 62b98b01f3f453b4046fc92fb97cd73022afc2a6e70133c48985eecc658c3db7 Title: World Athletic Awards: Letsile Tebogo and Sifan Hassan named athletes of the year - BBC Sport\n",
      "\n",
      "=== Final Answer ===\n",
      "Question: Who will Daniel Dubois fight in Saudi Arabia on 22 February?\n",
      "Answer: The documents do not provide information on who Daniel Dubois will fight in Saudi Arabia on 22 February.\n",
      "\n",
      "Sources:\n",
      "-> New Zealand v England: Brydon Carse repays faith with Christchurch haul - BBC Sport\n",
      "-> Ireland 22-19 Australia: 'No emotion' for Andy Farrell in winning send-off before Lions sabbatical - BBC Sport\n",
      "-> Watch: CCTV shows how Daniel Khalife escaped - BBC News\n",
      "-> Troy Deeney's Team of the Week: Saka, Kluivert, Schade, Rashford - BBC Sport\n",
      "-> World Athletic Awards: Letsile Tebogo and Sifan Hassan named athletes of the year - BBC Sport\n",
      "\n",
      "Optimized Hyperscale Vector Search Results (completed in 2.92 seconds):\n"
     ]
    }
   ],
   "source": [
    "# Sample query from the dataset\n",
    "\n",
    "query = \"Who will Daniel Dubois fight in Saudi Arabia on 22 February?\"\n",
    "\n",
    "try:\n",
    "    # Perform the semantic search using the RAG pipeline\n",
    "    start_time = time.time()\n",
    "    result = rag_pipeline.run({\n",
    "        \"query_embedder\": {\"text\": query},\n",
    "        \"retriever\": {\"top_k\": 5},\n",
    "        \"prompt_builder\": {\"question\": query},\n",
    "        \"answer_builder\": {\"query\": query},\n",
    "        },\n",
    "     include_outputs_from={\"retriever\", \"query_embedder\"}\n",
    "    )\n",
    "    search_elapsed_time = time.time() - start_time\n",
    "    # Get the generated answer\n",
    "    answer: GeneratedAnswer = result[\"answer_builder\"][\"answers\"][0]\n",
    "\n",
    "    # Print retrieved documents\n",
    "    print(\"=== Retrieved Documents ===\")\n",
    "    retrieved_docs = result[\"retriever\"][\"documents\"]\n",
    "    for idx, doc in enumerate(retrieved_docs, start=1):\n",
    "        print(f\"Id: {doc.id} Title: {doc.meta['title']}\")\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\n=== Final Answer ===\")\n",
    "    print(f\"Question: {answer.query}\")\n",
    "    print(f\"Answer: {answer.data}\")\n",
    "    print(\"\\nSources:\")\n",
    "    for doc in answer.documents:\n",
    "        print(f\"-> {doc.meta['title']}\")\n",
    "    # Display search results\n",
    "    print(f\"\\nOptimized Hyperscale Vector Search Results (completed in {search_elapsed_time:.2f} seconds):\")\n",
    "    #print(result[\"generator\"][\"replies\"][0])\n",
    "\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error performing RAG search: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Hyperscale or Composite Vector Indexes\n",
    "\n",
    "While the above RAG system works effectively, you can significantly improve query performance by enabling Couchbase Capella's Hyperscale or Composite Vector Indexes.\n",
    "\n",
    "## Hyperscale Vector Indexes\n",
    "- Specifically designed for vector searches\n",
    "- Perform vector similarity and semantic searches faster than other index types\n",
    "- Scale to billions of vectors while keeping most of the structure in an optimized on-disk format\n",
    "- Maintain high accuracy even for vectors with a large number of dimensions\n",
    "- Support concurrent searches and inserts for constantly changing datasets\n",
    "\n",
    "Use this type of index when you primarily query vector values and need low-latency similarity search at scale. In general, Hyperscale Vector Indexes are the best starting point for most vector search workloads.\n",
    "\n",
    "## Composite Vector Indexes\n",
    "- Combine scalar filters with a single vector column in the same index definition\n",
    "- Designed for searches that apply one vector value alongside scalar attributes that remove large portions of the dataset before similarity scoring\n",
    "- Consume a moderate amount of memory and can index Tens of million to billion of documents\n",
    "- Excel when your queries must return a small, highly targeted result set\n",
    "\n",
    "Use Composite Vector Indexes when you want to perform searches that blend scalar predicates and vector similarity so that the scalar filters tighten the candidate set.\n",
    "\n",
    "For an in-depth comparison and tuning guidance, review the [Couchbase vector index documentation](https://docs.couchbase.com/cloud/vector-index/use-vector-indexes.html) and the [overview of Capella vector indexes](https://docs.couchbase.com/cloud/vector-index/vectors-and-indexes-overview.html).\n",
    "\n",
    "## Understanding Index Configuration (Couchbase 8.0 Feature)\n",
    "\n",
    "The `index_description` parameter controls how Couchbase optimizes vector storage and search performance through centroids and quantization:\n",
    "\n",
    "Format: `'IVF[<centroids>],{PQ|SQ}<settings>'`\n",
    "\n",
    "**Centroids (IVF - Inverted File):**\n",
    "- Controls how the dataset is subdivided for faster searches\n",
    "- More centroids = faster search, slower training  \n",
    "- Fewer centroids = slower search, faster training\n",
    "- If omitted (like `IVF,SQ8`), Couchbase auto-selects based on dataset size\n",
    "\n",
    "**Quantization Options:**\n",
    "- SQ (Scalar Quantization): `SQ4`, `SQ6`, `SQ8` (4, 6, or 8 bits per dimension)\n",
    "- PQ (Product Quantization): `PQ<subquantizers>x<bits>` (e.g., `PQ32x8`)\n",
    "- Higher values = better accuracy, larger index size\n",
    "\n",
    "**Common Examples:**\n",
    "- `IVF,SQ8` – Auto centroids, 8-bit scalar quantization (good default)\n",
    "- `IVF1000,SQ6` – 1000 centroids, 6-bit scalar quantization  \n",
    "- `IVF,PQ32x8` – Auto centroids, 32 subquantizers with 8 bits\n",
    "\n",
    "For detailed configuration options, see the [Quantization & Centroid Settings](https://docs.couchbase.com/server/current/vector-index/hyperscale-vector-index.html#algo_settings).\n",
    "\n",
    "In the code below, we demonstrate creating a Hyperscale index for optimal performance. You can adapt the same flow to create a COMPOSITE index by replacing the index type and options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperscale index may already exist or error occurred: InternalServerFailureException(<ec=5, category=couchbase.common, message=internal_server_failure (5), context=QueryErrorContext({'last_dispatched_to': '[::1]:8093', 'last_dispatched_from': '[::1]:60492', 'retry_attempts': 0, 'client_context_id': '7f04d5-2e9e-1547-3acb-5e7f339070b0e4', 'method': 'POST', 'path': '/query/service', 'http_status': 500, 'http_body': '{\\n\"requestID\": \"849bb82b-ba3b-4bf3-89e9-02c8505242de\",\\n\"clientContextID\": \"7f04d5-2e9e-1547-3acb-5e7f339070b0e4\",\\n\"signature\": null,\\n\"results\": [\\n],\\n\"errors\": [{\"code\":5000,\"msg\":\"GSI CreateIndex() - cause: Index sample_index_hyperscale fails to build for reason: ErrTraining: InvalidTrainListSize: The number of documents: 100 in keyspace: b:s:c are less than the minimum number of documents: 1024 required for training 1024 centroids\\\\n\",\"reason\":{\"_level\":\"exception\",\"caller\":\"secondary_index:713\",\"cause\":{\"error\":\"Index sample_index_hyperscale fails to build for reason: ErrTraining: InvalidTrainListSize: The number of documents: 100 in keyspace: b:s:c are less than the minimum number of documents: 1024 required for training 1024 centroids\",\"source\":\"CreateIndex()\"},\"code\":4350,\"key\":\"indexing.error\",\"message\":\"GSI error\"}}],\\n\"status\": \"fatal\"\\n}\\n', 'first_error_code': 5000, 'first_error_message': 'GSI CreateIndex() - cause: Index sample_index_hyperscale fails to build for reason: ErrTraining: InvalidTrainListSize: The number of documents: 100 in keyspace: b:s:c are less than the minimum number of documents: 1024 required for training 1024 centroids\\n', 'statement': '\\n        CREATE INDEX sample_index_hyperscale\\n        ON c (embedding VECTOR)\\n        USING GSI WITH {\"dimension\": 3072, \"description\": \"IVF1024,PQ32x8\", \"similarity\": \"L2\"}\\n        ', 'parameters': '{\"client_context_id\":\"7f04d5-2e9e-1547-3acb-5e7f339070b0e4\",\"metrics\":false,\"query_context\":\"`b`.`s`\",\"statement\":\"\\\\n        CREATE INDEX sample_index_hyperscale\\\\n        ON c (embedding VECTOR)\\\\n        USING GSI WITH {\\\\\"dimension\\\\\": 3072, \\\\\"description\\\\\": \\\\\"IVF1024,PQ32x8\\\\\", \\\\\"similarity\\\\\": \\\\\"L2\\\\\"}\\\\n        \",\"timeout\":\"299500ms\"}', 'context_type': 'QueryErrorContext'}), C Source=/Users/couchbase/jenkins/workspace/python/sdk/python-scripted-build-pipeline/py-client/src/n1ql.cxx:279>)\n"
     ]
    }
   ],
   "source": [
    "# Create a Hyperscale Vector Index for optimized vector search\n",
    "try:\n",
    "    hyperscale_index_name = f\"{INDEX_NAME}_hyperscale\"\n",
    "\n",
    "    # Use the cluster connection to create the Hyperscale index\n",
    "    scope = cluster.bucket(CB_BUCKET_NAME).scope(SCOPE_NAME)\n",
    "    \n",
    "    options = {\n",
    "        \"dimension\": 3072,  # text-embedding-3-large dimension\n",
    "        \"description\": \"IVF1024,PQ32x8\",\n",
    "        \"similarity\": \"L2\",\n",
    "    }\n",
    "    \n",
    "    scope.query(\n",
    "        f\"\"\"\n",
    "        CREATE INDEX {hyperscale_index_name}\n",
    "        ON {COLLECTION_NAME} (embedding VECTOR)\n",
    "        USING GSI WITH {json.dumps(options)}\n",
    "        \"\"\",\n",
    "    QueryOptions(\n",
    "        timeout=timedelta(seconds=300)\n",
    "    )).execute()\n",
    "    print(f\"Successfully created Hyperscale index: {hyperscale_index_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Hyperscale index may already exist or error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Optimized Hyperscale Vector Search\n",
    "\n",
    "The example below runs the same RAG query, but now uses the Hyperscale index created above. You'll notice improved performance as the index efficiently retrieves data. If you create a Composite index, the workflow is identical — Haystack automatically routes queries through the scalar filters before performing the vector similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:44:55,645 - INFO - Running component query_embedder\n",
      "2025-11-17 14:44:56,291 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-17 14:44:56,508 - INFO - Running component retriever\n",
      "2025-11-17 14:44:56,597 - INFO - Running component prompt_builder\n",
      "2025-11-17 14:44:56,598 - INFO - Running component llm\n",
      "2025-11-17 14:44:59,603 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-17 14:44:59,610 - INFO - Running component answer_builder\n",
      "=== Retrieved Documents ===\n",
      "Id: 0aa95f5a2c515683b16ab26312eb2734ca3a7fb72d00992f323b0f72a0e365a6 Title: Gleision mine deaths: Inquest won't be held until 2026 - BBC News\n",
      "Id: 8acf5742f95609c38bdf5941f61c337a1934570faaf21cd478daea2c635ddff6 Title: Bob Bryar dead: Former My Chemical Romance drummer dies aged 44  - BBC News\n",
      "Id: af754e31be9bfeca0436b023ecb75d1668fc035c36c81a87ded707729b790653 Title: Terry Griffiths: Former world snooker champion dies aged 77 - BBC Sport\n",
      "Id: b7434182a5461e6c5e92fa676cd071cd22a1a109d98563f3a5899894605737bd Title: Diddy on Trial - Enter the Diddy-Verse - BBC Sounds\n",
      "\n",
      "=== Final Answer ===\n",
      "Question: What is latest news on the death of Charles Breslin?\n",
      "Answer: The latest news on the death of Charles Breslin is that, after a protracted battle, families were informed in 2022 that a full inquest into the deaths of the four miners, including Charles Breslin, would be held. However, a pre-inquest hearing in Swansea’s Guildhall announced that the full inquest would not occur until \"the early part of 2026\" due to \"significant complexity\" surrounding the documents needed. The inquest involves a large volume of material, with the Coal Authority estimating 75,000 pages of written documents. Families are eagerly awaiting answers about the disaster at the Gleision colliery in which Charles Breslin and three others died, hopeful that the inquest will provide clarity and relief. The coroner has promised a thorough investigation to determine the source of the water and whether responsible parties were aware of the risks involved.\n",
      "\n",
      "Sources:\n",
      "-> Gleision mine deaths: Inquest won't be held until 2026 - BBC News\n",
      "-> Bob Bryar dead: Former My Chemical Romance drummer dies aged 44  - BBC News\n",
      "-> Terry Griffiths: Former world snooker champion dies aged 77 - BBC Sport\n",
      "-> Diddy on Trial - Enter the Diddy-Verse - BBC Sounds\n",
      "\n",
      "Optimized Hyperscale Vector Search Results (completed in 3.97 seconds):\n"
     ]
    }
   ],
   "source": [
    "# Test the optimized Hyperscale vector search\n",
    "query = \"What is latest news on the death of Charles Breslin?\"\n",
    "\n",
    "try:\n",
    "    # The RAG pipeline will automatically use the optimized Hyperscale index\n",
    "    # Perform the semantic search with Hyperscale optimization\n",
    "    start_time = time.time()\n",
    "    result = rag_pipeline.run({\n",
    "        \"query_embedder\": {\"text\": query},\n",
    "        \"retriever\": {\"top_k\": 4},\n",
    "        \"prompt_builder\": {\"question\": query},\n",
    "        \"answer_builder\": {\"query\": query},\n",
    "        },\n",
    "     include_outputs_from={\"retriever\", \"query_embedder\"}\n",
    "    )\n",
    "    search_elapsed_time = time.time() - start_time\n",
    "    # Get the generated answer\n",
    "    answer: GeneratedAnswer = result[\"answer_builder\"][\"answers\"][0]\n",
    "\n",
    "    # Print retrieved documents\n",
    "    print(\"=== Retrieved Documents ===\")\n",
    "    retrieved_docs = result[\"retriever\"][\"documents\"]\n",
    "    for idx, doc in enumerate(retrieved_docs, start=0):\n",
    "        print(f\"Id: {doc.id} Title: {doc.meta['title']}\")\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\n=== Final Answer ===\")\n",
    "    print(f\"Question: {answer.query}\")\n",
    "    print(f\"Answer: {answer.data}\")\n",
    "    print(\"\\nSources:\")\n",
    "    for doc in answer.documents:\n",
    "        print(f\"-> {doc.meta['title']}\")\n",
    "    # Display search results\n",
    "    print(f\"\\nOptimized Hyperscale Vector Search Results (completed in {search_elapsed_time:.2f} seconds):\")\n",
    "    #print(result[\"generator\"][\"replies\"][0])\n",
    "\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error performing optimized semantic search: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this tutorial, we've built a Retrieval Augmented Generation (RAG) system using Haystack with OpenAI models and Couchbase Capella's Hyperscale and Composite Vector Indexes. Using the BBC News dataset, we demonstrated how modern vector indexes make it possible to answer up-to-date questions that extend beyond an LLM's original training data.\n",
    "\n",
    "The key components of our RAG system include:\n",
    "\n",
    "1. **Couchbase Capella Hyperscale & Composite Vector Indexes** for high-performance storage and retrieval of document embeddings\n",
    "2. **Haystack** as the framework for building modular RAG pipelines with flexible component connections\n",
    "3. **OpenAI Services** for generating embeddings (`text-embedding-3-large`) and LLM responses (`gpt-4o`)\n",
    "\n",
    "This approach grounds LLM responses in specific, current information from our knowledge base while taking advantage of Couchbase's advanced vector index options for performance and scale. Haystack's modular pipeline model keeps the solution extensible as you layer in additional data sources or services.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
