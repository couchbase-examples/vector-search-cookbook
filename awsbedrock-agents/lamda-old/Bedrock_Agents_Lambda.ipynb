{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Bedrock Agents with Couchbase Vector Search - Lambda Approach\n",
    "\n",
    "This notebook demonstrates the Lambda approach for implementing AWS Bedrock agents with Couchbase Vector Search. In this approach, the agent invokes AWS Lambda functions to execute operations.\n",
    "\n",
    "We'll implement a multi-agent architecture with specialized agents for different tasks:\n",
    "- **Researcher Agent**: Searches for relevant documents in the vector store\n",
    "- **Writer Agent**: Formats and presents the research findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Approaches\n",
    "\n",
    "This notebook demonstrates the Lambda Approach for AWS Bedrock Agents. For comparison, you might also want to check out the Custom Control Approach, which handles agent tools directly in your application code instead of using AWS Lambda functions.\n",
    "\n",
    "The Custom Control approach offers simpler setup and more direct control, but may not scale as well. You can find that implementation here: [Custom Control Approach Notebook](../custom-control-approach/Bedrock_Agents_Custom_Control.ipynb)\n",
    "\n",
    "Note: If the link above doesn't work in your Jupyter environment, you can navigate to the file manually in the `awsbedrock-agents/custom-control-approach/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Lambda approach delegates the execution of an agent's defined functions (tools) to separate AWS Lambda functions. When the agent decides to use a tool, Bedrock directly invokes the corresponding Lambda function specified in the action group configuration, passing the required parameters. The Lambda function executes the logic and returns the result to the agent, which then continues processing within the same invocation.\n",
    "\n",
    "## Key Steps & Concepts\n",
    "\n",
    "1.  **Define Agent:**\n",
    "    *   Define instructions (prompt) for the agent.\n",
    "    *   Define the function schema (tools the agent can use, e.g., `researcher_functions_lambda`, `writer_functions_lambda` in the example). The schema defines the interface the agent expects.\n",
    "\n",
    "2.  **Implement Lambda Handlers:**\n",
    "    *   Create separate AWS Lambda functions to implement the logic for each tool defined in the schema (e.g., one Lambda for `search_documents`, another for `format_content`).\n",
    "    *   These Lambda functions receive an event payload containing the API path, parameters, and other details of the agent's request.\n",
    "    *   The Lambda code needs to parse this event, execute the required action (e.g., query the vector store, format text), and return a specific JSON response structure that Bedrock expects.\n",
    "    *   The example includes a `deploy` script in `awsbedrock-agents/lambda_functions` to package and deploy these handlers.\n",
    "    *   *Environment Configuration:* The Lambdas need access to necessary resources and configuration (e.g., Couchbase connection details, Bedrock embeddings client). The example writes a `.env` file before deployment to potentially pass this information, though the exact mechanism within the Lambda deployment/runtime isn't fully shown.\n",
    "\n",
    "3.  **Create Agent in Bedrock:**\n",
    "    *   Use `bedrock_agent_client.create_agent` similar to the Custom Control approach.\n",
    "\n",
    "4.  **Create Action Group (Lambda):**\n",
    "    *   Use `bedrock_agent_client.create_agent_action_group`.\n",
    "    *   Crucially, set the `actionGroupExecutor` to `{\"lambda\": \"arn:aws:lambda:<region>:<account_id>:function:<lambda_function_name>\"}`. This points Bedrock to the specific Lambda function ARN responsible for executing the actions in this group.\n",
    "    *   Provide the `functionSchema` defined earlier.\n",
    "\n",
    "5.  **Prepare Agent:**\n",
    "    *   Use `bedrock_agent_client.prepare_agent`.\n",
    "\n",
    "6.  **Create Agent Alias:**\n",
    "    *   Use `bedrock_agent_client.create_agent_alias`.\n",
    "\n",
    "7.  **Invoke Agent:**\n",
    "    *   Use `bedrock_runtime_client.invoke_agent`.\n",
    "    *   Bedrock handles the invocation of the configured Lambda function when the agent decides to use a tool.\n",
    "    *   The application code simply receives the final response from the agent after the tool execution (if any) is complete. It doesn't need to handle `returnControl` events for function execution.\n",
    "    *   *Debugging Note:* The example's `invoke_agent` function includes extensive debugging prints and attempts to manually re-execute the logic *if* the agent's final response `result` is empty but a `returnControl` event *was* observed. This suggests potential issues or complexities in correctly receiving the final result after Lambda execution in the streaming response, leading to this fallback/debugging logic being added in the script.\n",
    "\n",
    "## Pros\n",
    "\n",
    "*   **Decoupling:** Tool execution logic is separate from the main application, potentially managed by different teams or deployment cycles.\n",
    "*   **Scalability:** Leverages the inherent scalability and serverless nature of AWS Lambda for tool execution.\n",
    "*   **Managed Execution:** AWS manages the invocation and execution environment for the Lambda functions.\n",
    "*   **Simpler Application Code:** The application invoking the agent doesn't need to implement the tool logic or handle the `returnControl` event for execution.\n",
    "\n",
    "## Cons\n",
    "\n",
    "*   **Deployment Complexity:** Requires setting up, configuring, and deploying separate Lambda functions, including managing their dependencies and permissions.\n",
    "*   **State Management:** Passing state or context between the main application and the Lambda functions can be more complex (e.g., requires passing connection details, potentially initializing clients within the Lambda).\n",
    "*   **Cold Starts:** Lambda cold starts can introduce latency into the agent's response time.\n",
    "*   **Debugging:** Debugging issues that span the Bedrock Agent service and the Lambda execution can be more challenging.\n",
    "*   **Cost:** Incurs separate Lambda execution costs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Necessary Libraries\n",
    "As a prerequisite, we need to install the necessary libraries. We can do this using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet langchain-couchbase==0.3.0 langchain-aws==0.2.22 couchbase==4.3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import subprocess\n",
    "from datetime import timedelta\n",
    "\n",
    "import boto3\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.exceptions import (InternalServerFailureException,\n",
    "                                  QueryIndexAlreadyExistsException,\n",
    "                                  ServiceUnavailableException)\n",
    "from couchbase.management.buckets import CreateBucketSettings\n",
    "from couchbase.management.search import SearchIndex\n",
    "from couchbase.options import ClusterOptions\n",
    "from dotenv import load_dotenv\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_couchbase.vectorstores import CouchbaseSearchVectorStore\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Environment Variables\n",
    "\n",
    "Load environment variables from the .env file. Make sure to create a .env file with the necessary credentials before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required environment variables are set\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Couchbase Configuration\n",
    "CB_HOST = os.getenv(\"CB_HOST\", \"couchbase://localhost\")\n",
    "CB_USERNAME = os.getenv(\"CB_USERNAME\", \"Administrator\")\n",
    "CB_PASSWORD = os.getenv(\"CB_PASSWORD\", \"password\")\n",
    "CB_BUCKET_NAME = os.getenv(\"CB_BUCKET_NAME\", \"vector-search-testing\")\n",
    "SCOPE_NAME = os.getenv(\"SCOPE_NAME\", \"shared\")\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\", \"bedrock\") \n",
    "INDEX_NAME = os.getenv(\"INDEX_NAME\", \"vector_search_bedrock\")\n",
    "\n",
    "# AWS Configuration\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_ACCOUNT_ID = os.getenv(\"AWS_ACCOUNT_ID\")\n",
    "\n",
    "# Check if required environment variables are set\n",
    "required_vars = [\"AWS_ACCESS_KEY_ID\", \"AWS_SECRET_ACCESS_KEY\", \"AWS_ACCOUNT_ID\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    print(f\"Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"Please set these variables in your .env file\")\n",
    "else:\n",
    "    print(\"All required environment variables are set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize AWS Clients\n",
    "\n",
    "Set up the AWS clients for Bedrock and other services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS clients initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize AWS session\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "# Initialize AWS clients from session\n",
    "iam_client = session.client('iam')\n",
    "bedrock_client = session.client('bedrock')\n",
    "bedrock_agent_client = session.client('bedrock-agent')\n",
    "bedrock_runtime = session.client('bedrock-runtime')\n",
    "bedrock_runtime_client = session.client('bedrock-agent-runtime')\n",
    "lambda_client = session.client('lambda')\n",
    "\n",
    "print(\"AWS clients initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Couchbase and Vector Store\n",
    "\n",
    "Now let's set up the Couchbase connection, collections, and vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_collection(cluster, bucket_name, scope_name, collection_name):\n",
    "    \"\"\"Set up Couchbase collection\"\"\"\n",
    "    try:\n",
    "        # Check if bucket exists, create if it doesn't\n",
    "        try:\n",
    "            bucket = cluster.bucket(bucket_name)\n",
    "            print(f\"Bucket '{bucket_name}' exists.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Bucket '{bucket_name}' does not exist. Creating it...\")\n",
    "            bucket_settings = CreateBucketSettings(\n",
    "                name=bucket_name,\n",
    "                bucket_type='couchbase',\n",
    "                ram_quota_mb=1024,\n",
    "                flush_enabled=True,\n",
    "                num_replicas=0\n",
    "            )\n",
    "            cluster.buckets().create_bucket(bucket_settings)\n",
    "            bucket = cluster.bucket(bucket_name)\n",
    "            print(f\"Bucket '{bucket_name}' created successfully.\")\n",
    "\n",
    "        bucket_manager = bucket.collections()\n",
    "\n",
    "        # Check if scope exists, create if it doesn't\n",
    "        scopes = bucket_manager.get_all_scopes()\n",
    "        scope_exists = any(scope.name == scope_name for scope in scopes)\n",
    "        \n",
    "        if not scope_exists and scope_name != \"_default\":\n",
    "            print(f\"Scope '{scope_name}' does not exist. Creating it...\")\n",
    "            bucket_manager.create_scope(scope_name)\n",
    "            print(f\"Scope '{scope_name}' created successfully.\")\n",
    "\n",
    "        # Check if collection exists, create if it doesn't\n",
    "        collections = bucket_manager.get_all_scopes()\n",
    "        collection_exists = any(\n",
    "            scope.name == scope_name and collection_name in [col.name for col in scope.collections]\n",
    "            for scope in collections\n",
    "        )\n",
    "\n",
    "        if not collection_exists:\n",
    "            print(f\"Collection '{collection_name}' does not exist. Creating it...\")\n",
    "            bucket_manager.create_collection(scope_name, collection_name)\n",
    "            print(f\"Collection '{collection_name}' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Collection '{collection_name}' already exists. Skipping creation.\")\n",
    "\n",
    "        # Wait for collection to be ready\n",
    "        collection = bucket.scope(scope_name).collection(collection_name)\n",
    "        time.sleep(2)  # Give the collection time to be ready for queries\n",
    "\n",
    "        # Ensure primary index exists\n",
    "        try:\n",
    "            cluster.query(f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{bucket_name}`.`{scope_name}`.`{collection_name}`\").execute()\n",
    "            print(\"Primary index present or created successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating primary index: {str(e)}\")\n",
    "\n",
    "        # Clear all documents in the collection\n",
    "        try:\n",
    "            query = f\"DELETE FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
    "            cluster.query(query).execute()\n",
    "            print(\"All documents cleared from the collection.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while clearing documents: {str(e)}. The collection might be empty.\")\n",
    "\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up collection: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_indexes(cluster):\n",
    "    \"\"\"Set up search indexes\"\"\"\n",
    "    try:\n",
    "        # Load index definition from file\n",
    "        with open('aws_index.json', 'r') as file:\n",
    "            index_definition = json.load(file)\n",
    "            print(f\"Loaded index definition from aws_index.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading index definition: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    try:\n",
    "        scope_index_manager = cluster.bucket(CB_BUCKET_NAME).scope(SCOPE_NAME).search_indexes()\n",
    "\n",
    "        # Check if index already exists\n",
    "        existing_indexes = scope_index_manager.get_all_indexes()\n",
    "        index_name = index_definition[\"name\"]\n",
    "\n",
    "        if index_name in [index.name for index in existing_indexes]:\n",
    "            print(f\"Index '{index_name}' found\")\n",
    "        else:\n",
    "            print(f\"Creating new index '{index_name}'...\")\n",
    "\n",
    "        # Create SearchIndex object from JSON definition\n",
    "        search_index = SearchIndex.from_json(index_definition)\n",
    "\n",
    "        # Upsert the index (create if not exists, update if exists)\n",
    "        scope_index_manager.upsert_index(search_index)\n",
    "        print(f\"Index '{index_name}' successfully created/updated.\")\n",
    "\n",
    "    except QueryIndexAlreadyExistsException:\n",
    "        print(f\"Index '{index_name}' already exists. Skipping creation/update.\")\n",
    "    except ServiceUnavailableException:\n",
    "        print(\"Search service is not available. Please ensure the Search service is enabled in your Couchbase cluster.\")\n",
    "    except InternalServerFailureException as e:\n",
    "        print(f\"Internal server error: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Couchbase\n",
      "Bucket 'vector-search-testing' exists.\n",
      "Collection 'bedrock' already exists. Skipping creation.\n",
      "Primary index present or created successfully.\n",
      "All documents cleared from the collection.\n",
      "Collections setup complete\n",
      "Loaded index definition from aws_index.json\n",
      "Index 'vector_search_bedrock' found\n",
      "Index 'vector_search_bedrock' already exists. Skipping creation/update.\n",
      "Search indexes setup complete\n"
     ]
    }
   ],
   "source": [
    "# Connect to Couchbase\n",
    "auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
    "options = ClusterOptions(auth)\n",
    "cluster = Cluster(CB_HOST, options)\n",
    "cluster.wait_until_ready(timedelta(seconds=5))\n",
    "print(\"Successfully connected to Couchbase\")\n",
    "\n",
    "# Set up collections\n",
    "collection = setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, COLLECTION_NAME)\n",
    "print(\"Collections setup complete\")\n",
    "\n",
    "# Set up search indexes\n",
    "setup_indexes(cluster)\n",
    "print(\"Search indexes setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created Bedrock embeddings client\n",
      "Successfully created vector store\n"
     ]
    }
   ],
   "source": [
    "# Initialize Bedrock runtime client for embeddings\n",
    "embeddings = BedrockEmbeddings(\n",
    "    client=bedrock_runtime,\n",
    "    model_id=\"amazon.titan-embed-text-v2:0\"\n",
    ")\n",
    "print(\"Successfully created Bedrock embeddings client\")\n",
    "\n",
    "# Initialize vector store\n",
    "vector_store = CouchbaseSearchVectorStore(\n",
    "    cluster=cluster,\n",
    "    bucket_name=CB_BUCKET_NAME,\n",
    "    scope_name=SCOPE_NAME,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding=embeddings,\n",
    "    index_name=INDEX_NAME\n",
    ")\n",
    "print(\"Successfully created vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents from JSON File\n",
    "\n",
    "Let's load the documents from the documents.json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 documents from documents.json\n",
      "Adding 7 documents to vector store...\n",
      "Added document 1/7 with ID: dcbdea3907d54ef0b0ca892f37b9242a\n",
      "Added document 2/7 with ID: e2b05cc1e26743f3b1d838f60065589c\n",
      "Added document 3/7 with ID: 0f3f8ee598b140059514d9e625b92777\n",
      "Added document 4/7 with ID: f39cf196ebab423c9fb8b56dc00cf730\n",
      "Added document 5/7 with ID: fdb8bb35e38741beb89bfc657578b6b8\n",
      "Added document 6/7 with ID: ccac0d68aafd4818b85250194bf89cf4\n",
      "Added document 7/7 with ID: 29b4433ea4e74b6b935545ae150c571a\n",
      "\n",
      "Processing complete: 7/7 documents added successfully\n"
     ]
    }
   ],
   "source": [
    "# Load documents from JSON file\n",
    "try:\n",
    "    with open('documents.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        documents = data.get('documents', [])\n",
    "    print(f\"Loaded {len(documents)} documents from documents.json\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading documents: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Add documents to vector store\n",
    "print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    text = doc.get('text', '')\n",
    "    metadata = doc.get('metadata', {})\n",
    "    \n",
    "    # Add document to vector store\n",
    "    metadata_dict = json.loads(metadata) if isinstance(metadata, str) else metadata or {}\n",
    "    doc_ids = vector_store.add_texts([text], [metadata_dict])\n",
    "    doc_id = doc_ids[0] if doc_ids else None    \n",
    "    print(f\"Added document {i}/{len(documents)} with ID: {doc_id}\")\n",
    "    \n",
    "    # Add small delay between requests\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"\\nProcessing complete: {len(documents)}/{len(documents)} documents added successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Approach Implementation\n",
    "\n",
    "Now let's implement the Lambda approach for Bedrock agents. This approach involves deploying Lambda functions that will be invoked by the Bedrock agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Lambda Functions\n",
    "\n",
    "First, let's deploy the Lambda functions that will be invoked by our Bedrock agents. We'll create a .env file for the Lambda functions with the Couchbase configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created .env file for Lambda functions at lambda_functions/.env\n"
     ]
    }
   ],
   "source": [
    "# Create a .env file for the Lambda functions\n",
    "lambda_env_path = 'lambda_functions/.env'\n",
    "with open(lambda_env_path, 'w') as f:\n",
    "    f.write(f\"CB_HOST={CB_HOST}\\n\")\n",
    "    f.write(f\"CB_USERNAME={CB_USERNAME}\\n\")\n",
    "    f.write(f\"CB_PASSWORD={CB_PASSWORD}\\n\")\n",
    "    f.write(f\"CB_BUCKET_NAME={CB_BUCKET_NAME}\\n\")\n",
    "    f.write(f\"SCOPE_NAME={SCOPE_NAME}\\n\")\n",
    "    f.write(f\"COLLECTION_NAME={COLLECTION_NAME}\\n\")\n",
    "    f.write(f\"INDEX_NAME={INDEX_NAME}\\n\")\n",
    "\n",
    "print(f\"Created .env file for Lambda functions at {lambda_env_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying Lambda functions...\n",
      "Using existing IAM role: bedrock_agent_lambda_role\n",
      "Deleting existing Lambda function: bedrock_agent_researcher\n",
      "Waiting for bedrock_agent_researcher to be deleted...\n",
      "Deleting existing Lambda function: bedrock_agent_writer\n",
      "Waiting for bedrock_agent_writer to be deleted...\n",
      "\n",
      "=== Deploying researcher function ===\n",
      "Installing dependencies for bedrock_agent_researcher...\n",
      "Waiting for role arn:aws:iam::598307997273:role/bedrock_agent_lambda_role to be ready...\n",
      "Zip file size: 53.12 MB\n",
      "File size (53.12 MB) exceeds 10MB. Using S3 for deployment...\n",
      "Creating S3 bucket: lambda-deployment-598307997273-1745960136 (attempt 1/3)...\n",
      "Created S3 bucket: lambda-deployment-598307997273-1745960136\n",
      "Waiting for bucket to be available...\n",
      "Uploading bedrock_agent_researcher.zip to S3 bucket lambda-deployment-598307997273-1745960136...\n",
      "Successfully uploaded bedrock_agent_researcher.zip to s3://lambda-deployment-598307997273-1745960136/lambda/bedrock_agent_researcher.zip-ffbce51f\n",
      "Creating function bedrock_agent_researcher (attempt 1/5)...\n",
      "Successfully created function bedrock_agent_researcher on attempt 1\n",
      "\n",
      "=== Deploying writer function ===\n",
      "Installing dependencies for bedrock_agent_writer...\n",
      "Waiting for role arn:aws:iam::598307997273:role/bedrock_agent_lambda_role to be ready...\n",
      "Zip file size: 53.12 MB\n",
      "File size (53.12 MB) exceeds 10MB. Using S3 for deployment...\n",
      "Creating S3 bucket: lambda-deployment-598307997273-1745960210 (attempt 1/3)...\n",
      "Created S3 bucket: lambda-deployment-598307997273-1745960210\n",
      "Waiting for bucket to be available...\n",
      "Uploading bedrock_agent_writer.zip to S3 bucket lambda-deployment-598307997273-1745960210...\n",
      "Successfully uploaded bedrock_agent_writer.zip to s3://lambda-deployment-598307997273-1745960210/lambda/bedrock_agent_writer.zip-79b49f2e\n",
      "Creating function bedrock_agent_writer (attempt 1/5)...\n",
      "Successfully created function bedrock_agent_writer on attempt 1\n",
      "\n",
      "Deployment complete!\n",
      "Lambda functions deployed successfully\n"
     ]
    }
   ],
   "source": [
    "# Deploy Lambda functions\n",
    "print(\"Deploying Lambda functions...\")\n",
    "try:\n",
    "    subprocess.run([\n",
    "        'python3', \n",
    "        'lambda_functions/deploy.py'\n",
    "    ], check=True)\n",
    "    print(\"Lambda functions deployed successfully\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error deploying Lambda functions: {str(e)}\")\n",
    "    raise RuntimeError(\"Failed to deploy Lambda functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Approach Helper Functions\n",
    "\n",
    "Let's define some helper functions for the Lambda approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_agent_status(bedrock_agent_client, agent_id, target_statuses=['Available', 'PREPARED', 'NOT_PREPARED'], max_attempts=30, delay=2):\n",
    "    \"\"\"Wait for agent to reach any of the target statuses\"\"\"\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            response = bedrock_agent_client.get_agent(agentId=agent_id)\n",
    "            current_status = response['agent']['agentStatus']\n",
    "            \n",
    "            if current_status in target_statuses:\n",
    "                print(f\"Agent {agent_id} reached status: {current_status}\")\n",
    "                return current_status\n",
    "            elif current_status == 'FAILED':\n",
    "                print(f\"Agent {agent_id} failed\")\n",
    "                return 'FAILED'\n",
    "            \n",
    "            print(f\"Agent status: {current_status}, waiting... (attempt {attempt + 1}/{max_attempts})\")\n",
    "            time.sleep(delay)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error checking agent status: {str(e)}\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    return current_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(bedrock_agent_client, name, instructions, model_id=\"amazon.nova-pro-v1:0\"):\n",
    "    \"\"\"Create a Bedrock agent with Lambda action groups\"\"\"\n",
    "    try:\n",
    "        # List existing agents\n",
    "        existing_agents = bedrock_agent_client.list_agents()\n",
    "        existing_agent = next(\n",
    "            (agent for agent in existing_agents['agentSummaries'] \n",
    "             if agent['agentName'] == name),\n",
    "            None\n",
    "        )\n",
    "        \n",
    "        # Handle existing agent\n",
    "        if existing_agent:\n",
    "            agent_id = existing_agent['agentId']\n",
    "            print(f\"Found existing agent '{name}' with ID: {agent_id}\")\n",
    "            \n",
    "            # Check agent status\n",
    "            response = bedrock_agent_client.get_agent(agentId=agent_id)\n",
    "            status = response['agent']['agentStatus']\n",
    "            \n",
    "            if status in ['NOT_PREPARED', 'FAILED']:\n",
    "                print(f\"Deleting agent '{name}' with status {status}\")\n",
    "                bedrock_agent_client.delete_agent(agentId=agent_id)\n",
    "                time.sleep(10)  # Wait after deletion\n",
    "                existing_agent = None\n",
    "        \n",
    "        # Create new agent if needed\n",
    "        if not existing_agent:\n",
    "            print(f\"Creating new agent '{name}'\")\n",
    "            agent = bedrock_agent_client.create_agent(\n",
    "                agentName=name,\n",
    "                description=f\"{name.title()} agent for document operations\",\n",
    "                instruction=instructions,\n",
    "                idleSessionTTLInSeconds=1800,\n",
    "                foundationModel=model_id\n",
    "            )\n",
    "            agent_id = agent['agent']['agentId']\n",
    "            print(f\"Created new agent '{name}' with ID: {agent_id}\")\n",
    "        else:\n",
    "            agent_id = existing_agent['agentId']\n",
    "        \n",
    "        # Wait for initial creation if needed\n",
    "        status = wait_for_agent_status(bedrock_agent_client, agent_id, target_statuses=['NOT_PREPARED', 'PREPARED', 'Available'])\n",
    "        if status not in ['NOT_PREPARED', 'PREPARED', 'Available']:\n",
    "            raise Exception(f\"Agent failed to reach valid state: {status}\")\n",
    "        \n",
    "        # Handle alias creation/retrieval\n",
    "        try:\n",
    "            aliases = bedrock_agent_client.list_agent_aliases(agentId=agent_id)\n",
    "            alias = next((a for a in aliases['agentAliasSummaries'] if a['agentAliasName'] == 'v1'), None)\n",
    "            \n",
    "            if not alias:\n",
    "                print(f\"Creating new alias for agent '{name}'\")\n",
    "                alias = bedrock_agent_client.create_agent_alias(\n",
    "                    agentId=agent_id,\n",
    "                    agentAliasName=\"v1\"\n",
    "                )\n",
    "                alias_id = alias['agentAlias']['agentAliasId']\n",
    "            else:\n",
    "                alias_id = alias['agentAliasId']\n",
    "                print(f\"Using existing alias for agent '{name}'\")\n",
    "            \n",
    "            print(f\"Successfully configured agent '{name}' with ID: {agent_id} and alias: {alias_id}\")\n",
    "            return agent_id, alias_id\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error managing alias: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating/updating agent: {str(e)}\")\n",
    "        raise RuntimeError(f\"Failed to create/update agent: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# awsbedrock-agents/lamda-approach/Bedrock_Agents_Lambda.ipynb\n",
    "\n",
    "def invoke_agent(bedrock_runtime_client, agent_id, alias_id, input_text, session_id=None, vector_store=None):\n",
    "    \"\"\"Invoke a Bedrock agent with improved debugging and error handling\"\"\"\n",
    "    if session_id is None:\n",
    "        session_id = str(uuid.uuid4())\n",
    "\n",
    "    try:\n",
    "        print(f\"--- Invoking agent {agent_id} (Alias: {alias_id}) ---\")\n",
    "        print(f\"Session ID: {session_id}\")\n",
    "        print(f\"Input Text: '{input_text[:100]}...'\\\") # Print truncated input\")\n",
    "\n",
    "        response = bedrock_runtime_client.invoke_agent(\n",
    "            agentId=agent_id,\n",
    "            agentAliasId=alias_id,\n",
    "            sessionId=session_id,\n",
    "            inputText=input_text,\n",
    "            enableTrace=True\n",
    "        )\n",
    "\n",
    "        result = \"\"\n",
    "        print(\"--- Processing Response Stream ---\")\n",
    "        event_count = 0\n",
    "        lambda_invoked = False\n",
    "        lambda_result_received = None\n",
    "\n",
    "        for event in response['completion']:\n",
    "            event_count += 1\n",
    "            print(f\"\\n[Event {event_count}] Type: {list(event.keys())}\")\n",
    "\n",
    "            # Print full event for detailed inspection - Handle potential TypeError\n",
    "            try:\n",
    "                # Attempt pretty printing first\n",
    "                print(f\"Event Content:\\n{json.dumps(event, indent=2)}\")\n",
    "            except TypeError:\n",
    "                # Fallback to standard print if JSON serialization fails (e.g., due to datetime)\n",
    "                print(f\"Event Content (raw, contains non-serializable types):\\n{event}\")\n",
    "\n",
    "\n",
    "            if 'chunk' in event:\n",
    "                chunk = event['chunk']['bytes'].decode('utf-8')\n",
    "                print(f\"  -> Received Chunk: '{chunk}'\")\n",
    "                result += chunk\n",
    "\n",
    "            if 'trace' in event:\n",
    "                print(\"  -> Received Trace event.\")\n",
    "                trace_data = event['trace']\n",
    "                # Log trace details - especially useful for Lambda interactions\n",
    "                if isinstance(trace_data, dict) and 'orchestrationTrace' in trace_data:\n",
    "                    orch_trace = trace_data['orchestrationTrace']\n",
    "                    if 'invocationInput' in orch_trace:\n",
    "                         print(f\"    -> Trace: Invocation Input found (Agent intends to call function)\")\n",
    "                         lambda_invoked = True # Mark that the agent tried to call something\n",
    "                    if 'invocationOutput' in orch_trace:\n",
    "                        invocation_output = orch_trace['invocationOutput']\n",
    "                        if 'actionGroupInvocationOutput' in invocation_output:\n",
    "                            action_output = invocation_output['actionGroupInvocationOutput']\n",
    "                            if 'responseBody' in action_output:\n",
    "                                print(\"    -> Trace: Lambda Response Body found\")\n",
    "                                response_body = action_output['responseBody']\n",
    "                                if isinstance(response_body, dict) and 'application/json' in response_body:\n",
    "                                    json_body = response_body['application/json']\n",
    "                                    if 'body' in json_body:\n",
    "                                        lambda_result_received = json_body['body']\n",
    "                                        print(f\"      -> Lambda Result Body: {lambda_result_received}\")\n",
    "                                        # In Lambda mode, Bedrock should ideally incorporate this into the final 'chunk'\n",
    "                                        # But we capture it here for debugging if the final result is empty\n",
    "                                        # Assigning here might short-circuit final LLM processing, so use cautiously\n",
    "                                        # result = lambda_result_received # <-- Potentially uncomment if chunks never arrive after lambda call\n",
    "\n",
    "            if 'returnControl' in event:\n",
    "                 # This shouldn't happen often in Lambda mode, but log if it does\n",
    "                 print(\"  -> Received returnControl event (unexpected in Lambda mode)\")\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Stream Processing Complete ({event_count} events) ---\")\n",
    "\n",
    "        if not result.strip():\n",
    "            print(\"WARN: Final 'result' is empty or whitespace.\")\n",
    "            if lambda_invoked and lambda_result_received is not None:\n",
    "                 print(\"INFO: Lambda was invoked and returned a result, but it wasn't in the final agent output.\")\n",
    "                 print(f\"INFO: Raw Lambda Result was: {lambda_result_received}\")\n",
    "                 # Decide if you want to return the raw lambda result as a fallback\n",
    "                 # return lambda_result_received\n",
    "            elif lambda_invoked:\n",
    "                 print(\"ERROR: Agent trace indicates Lambda invocation, but no result was found in the trace.\")\n",
    "            else:\n",
    "                 print(\"INFO: No Lambda invocation was detected in the trace.\")\n",
    "\n",
    "\n",
    "        print(f\"--- Returning Result --- \\n'{result}'\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"--- ERROR during agent invocation ---\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc()) # Print full exception traceback\n",
    "        raise RuntimeError(f\"Failed to invoke agent: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Instructions and Functions\n",
    "\n",
    "Now let's define the instructions and functions for our agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Researcher agent instructions\n",
    "researcher_instructions = \"\"\"\n",
    "You are a Research Assistant that helps users find relevant information in documents.\n",
    "Your capabilities include:\n",
    "1. Searching through documents using semantic similarity\n",
    "2. Providing relevant document excerpts\n",
    "3. Answering questions based on document content\n",
    "\"\"\"\n",
    "\n",
    "# Researcher agent functions\n",
    "researcher_functions = [{\n",
    "    \"name\": \"search_documents\",\n",
    "    \"description\": \"Search for relevant documents using semantic similarity\",\n",
    "    \"parameters\": {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The search query\",\n",
    "            \"required\": True\n",
    "        },\n",
    "        \"k\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"Number of results to return\",\n",
    "            \"required\": False\n",
    "        }\n",
    "    },\n",
    "    \"requireConfirmation\": \"DISABLED\"\n",
    "}]\n",
    "\n",
    "# Writer agent instructions\n",
    "writer_instructions = \"\"\"\n",
    "You are a Content Writer Assistant that helps format and present research findings.\n",
    "Your capabilities include:\n",
    "1. Formatting research findings in a user-friendly way\n",
    "2. Creating clear and engaging summaries\n",
    "3. Organizing information logically\n",
    "4. Highlighting key insights\n",
    "\"\"\"\n",
    "\n",
    "# Writer agent functions\n",
    "writer_functions = [{\n",
    "    \"name\": \"format_content\",\n",
    "    \"description\": \"Format and present research findings\",\n",
    "    \"parameters\": {\n",
    "        \"content\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The research findings to format\",\n",
    "            \"required\": True\n",
    "        },\n",
    "        \"style\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The desired presentation style (e.g., summary, detailed, bullet points)\",\n",
    "            \"required\": False\n",
    "        }\n",
    "    },\n",
    "    \"requireConfirmation\": \"DISABLED\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Lambda Approach\n",
    "\n",
    "Now let's run the Lambda approach with our agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new agent 'researcher'\n",
      "Created new agent 'researcher' with ID: BQFTVQNMLY\n",
      "Agent status: CREATING, waiting... (attempt 1/30)\n",
      "Agent BQFTVQNMLY reached status: NOT_PREPARED\n",
      "Creating new alias for agent 'researcher'\n",
      "Error managing alias: An error occurred (ValidationException) when calling the CreateAgentAlias operation: Create operation can't be performed on AgentAlias when Agent is in Not Prepared state.\n",
      "Error creating/updating agent: An error occurred (ValidationException) when calling the CreateAgentAlias operation: Create operation can't be performed on AgentAlias when Agent is in Not Prepared state.\n",
      "Failed to create researcher agent: Failed to create/update agent: An error occurred (ValidationException) when calling the CreateAgentAlias operation: Create operation can't be performed on AgentAlias when Agent is in Not Prepared state.\n",
      "Creating new agent 'writer'\n",
      "Created new agent 'writer' with ID: HFUSWMZ3MC\n",
      "Agent status: CREATING, waiting... (attempt 1/30)\n",
      "Agent HFUSWMZ3MC reached status: NOT_PREPARED\n",
      "Creating new alias for agent 'writer'\n",
      "Error managing alias: An error occurred (ValidationException) when calling the CreateAgentAlias operation: Create operation can't be performed on AgentAlias when Agent is in Not Prepared state.\n",
      "Error creating/updating agent: An error occurred (ValidationException) when calling the CreateAgentAlias operation: Create operation can't be performed on AgentAlias when Agent is in Not Prepared state.\n",
      "Failed to create writer agent: Failed to create/update agent: An error occurred (ValidationException) when calling the CreateAgentAlias operation: Create operation can't be performed on AgentAlias when Agent is in Not Prepared state.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to create any agents",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     writer_id, writer_alias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m([researcher_id, writer_id]):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to create any agents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to create any agents"
     ]
    }
   ],
   "source": [
    "# Create researcher agent\n",
    "try:\n",
    "    researcher_id, researcher_alias = create_agent(\n",
    "        bedrock_agent_client,\n",
    "        \"researcher\", \n",
    "        researcher_instructions, \n",
    "    )\n",
    "    print(f\"Researcher agent created with ID: {researcher_id} and alias: {researcher_alias}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create researcher agent: {str(e)}\")\n",
    "    researcher_id, researcher_alias = None, None\n",
    "\n",
    "# Create writer agent\n",
    "try:\n",
    "    writer_id, writer_alias = create_agent(\n",
    "        bedrock_agent_client,\n",
    "        \"writer\", \n",
    "        writer_instructions, \n",
    "    )\n",
    "    print(f\"Writer agent created with ID: {writer_id} and alias: {writer_alias}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create writer agent: {str(e)}\")\n",
    "    writer_id, writer_alias = None, None\n",
    "\n",
    "if not any([researcher_id, writer_id]):\n",
    "    raise RuntimeError(\"Failed to create any agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create action group for researcher agent with Lambda executor\n",
    "try:\n",
    "    bedrock_agent_client.create_agent_action_group(\n",
    "        agentId=researcher_id,\n",
    "        agentVersion=\"DRAFT\",\n",
    "        actionGroupExecutor={\n",
    "            \"lambda\": f\"arn:aws:lambda:{AWS_REGION}:{AWS_ACCOUNT_ID}:function:bedrock_agent_researcher\"\n",
    "        },  # This is the key for Lambda approach\n",
    "        actionGroupName=\"researcher_actions\",\n",
    "        functionSchema={\"functions\": researcher_functions},\n",
    "        description=\"Action group for researcher operations with Lambda\"\n",
    "    )\n",
    "    print(\"Created researcher Lambda action group\")\n",
    "except bedrock_agent_client.exceptions.ConflictException:\n",
    "    print(\"Researcher Lambda action group already exists\")\n",
    "    \n",
    "# Prepare researcher agent\n",
    "print(\"Preparing researcher agent...\")\n",
    "bedrock_agent_client.prepare_agent(agentId=researcher_id)\n",
    "status = wait_for_agent_status(\n",
    "    bedrock_agent_client,\n",
    "    researcher_id, \n",
    "    target_statuses=['PREPARED', 'Available']\n",
    ")\n",
    "print(f\"Researcher agent preparation completed with status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create action group for writer agent with Lambda executor\n",
    "try:\n",
    "    bedrock_agent_client.create_agent_action_group(\n",
    "        agentId=writer_id,\n",
    "        agentVersion=\"DRAFT\",\n",
    "        actionGroupExecutor={\n",
    "            \"lambda\": f\"arn:aws:lambda:{AWS_REGION}:{AWS_ACCOUNT_ID}:function:bedrock_agent_writer\"\n",
    "        },  # This is the key for Lambda approach\n",
    "        actionGroupName=\"writer_actions\",\n",
    "        functionSchema={\"functions\": writer_functions},\n",
    "        description=\"Action group for writer operations with Lambda\"\n",
    "    )\n",
    "    print(\"Created writer Lambda action group\")\n",
    "except bedrock_agent_client.exceptions.ConflictException:\n",
    "    print(\"Writer Lambda action group already exists\")\n",
    "    \n",
    "# Prepare writer agent\n",
    "print(\"Preparing writer agent...\")\n",
    "bedrock_agent_client.prepare_agent(agentId=writer_id)\n",
    "status = wait_for_agent_status(\n",
    "    bedrock_agent_client,\n",
    "    writer_id, \n",
    "    target_statuses=['PREPARED', 'Available']\n",
    ")\n",
    "print(f\"Writer agent preparation completed with status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Agents\n",
    "\n",
    "Let's test our agents by asking the researcher agent to search for information and the writer agent to format the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test researcher agent\n",
    "researcher_response = invoke_agent(\n",
    "    bedrock_runtime_client,\n",
    "    researcher_id,\n",
    "    researcher_alias,\n",
    "    'What is unique about the Cline AI assistant? Use the search_documents function to find relevant information.',\n",
    "    vector_store=vector_store\n",
    ")\n",
    "print(\"\\nResearcher Response:\\n\", researcher_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test writer agent\n",
    "writer_response = invoke_agent(\n",
    "    bedrock_runtime_client,\n",
    "    writer_id,\n",
    "    writer_alias,\n",
    "    f'Format this research finding using the format_content function: {researcher_response}',\n",
    "    vector_store=vector_store\n",
    ")\n",
    "print(\"\\nWriter Response:\\n\", writer_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the Lambda approach for implementing AWS Bedrock agents with Couchbase Vector Search. This approach allows the agent to invoke AWS Lambda functions to execute operations, providing better scalability and separation of concerns.\n",
    "\n",
    "Key components of this implementation include:\n",
    "\n",
    "1. **Vector Store Setup**: We set up a Couchbase vector store to store and search documents using semantic similarity.\n",
    "2. **Lambda Function Deployment**: We deployed Lambda functions that handle the agent's function calls.\n",
    "3. **Agent Creation**: We created two specialized agents - a researcher agent for searching documents and a writer agent for formatting results.\n",
    "4. **Lambda Integration**: We integrated the agents with Lambda functions, allowing them to execute operations in a serverless environment.\n",
    "\n",
    "This approach is particularly useful for production environments where scalability and separation of concerns are important. The Lambda functions can be deployed independently and can access other AWS services, providing more flexibility and power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
