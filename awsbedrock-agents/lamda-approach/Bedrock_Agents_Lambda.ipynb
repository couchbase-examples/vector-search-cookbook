{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Bedrock Agents with Couchbase Vector Search - Lambda Approach\n",
    "\n",
    "This notebook demonstrates the Lambda approach for implementing AWS Bedrock agents with Couchbase Vector Search. In this approach, the agent invokes AWS Lambda functions to execute operations.\n",
    "\n",
    "We'll implement a multi-agent architecture with specialized agents for different tasks:\n",
    "- **Researcher Agent**: Searches for relevant documents in the vector store\n",
    "- **Writer Agent**: Formats and presents the research findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Approaches\n",
    "\n",
    "This notebook demonstrates the Lambda Approach for AWS Bedrock Agents. For comparison, you might also want to check out the Custom Control Approach, which handles agent tools directly in your application code instead of using AWS Lambda functions.\n",
    "\n",
    "The Custom Control approach offers simpler setup and more direct control, but may not scale as well. You can find that implementation here: [Custom Control Approach Notebook](../custom-control-approach/Bedrock_Agents_Custom_Control.ipynb)\n",
    "\n",
    "Note: If the link above doesn't work in your Jupyter environment, you can navigate to the file manually in the `awsbedrock-agents/custom-control-approach/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Lambda approach delegates the execution of an agent's defined functions (tools) to separate AWS Lambda functions. When the agent decides to use a tool, Bedrock directly invokes the corresponding Lambda function specified in the action group configuration, passing the required parameters. The Lambda function executes the logic and returns the result to the agent, which then continues processing within the same invocation.\n",
    "\n",
    "## Key Steps & Concepts\n",
    "\n",
    "1.  **Define Agent:**\n",
    "    *   Define instructions (prompt) for the agent.\n",
    "    *   Define the function schema (tools the agent can use, e.g., `researcher_functions_lambda`, `writer_functions_lambda` in the example). The schema defines the interface the agent expects.\n",
    "\n",
    "2.  **Implement Lambda Handlers:**\n",
    "    *   Create separate AWS Lambda functions to implement the logic for each tool defined in the schema (e.g., one Lambda for `search_documents`, another for `format_content`).\n",
    "    *   These Lambda functions receive an event payload containing the API path, parameters, and other details of the agent's request.\n",
    "    *   The Lambda code needs to parse this event, execute the required action (e.g., query the vector store, format text), and return a specific JSON response structure that Bedrock expects.\n",
    "    *   The example includes a `deploy` script in `awsbedrock-agents/lambda_functions` to package and deploy these handlers.\n",
    "    *   *Environment Configuration:* The Lambdas need access to necessary resources and configuration (e.g., Couchbase connection details, Bedrock embeddings client). The example writes a `.env` file before deployment to potentially pass this information, though the exact mechanism within the Lambda deployment/runtime isn't fully shown.\n",
    "\n",
    "3.  **Create Agent in Bedrock:**\n",
    "    *   Use `bedrock_agent_client.create_agent` similar to the Custom Control approach.\n",
    "\n",
    "4.  **Create Action Group (Lambda):**\n",
    "    *   Use `bedrock_agent_client.create_agent_action_group`.\n",
    "    *   Crucially, set the `actionGroupExecutor` to `{\"lambda\": \"arn:aws:lambda:<region>:<account_id>:function:<lambda_function_name>\"}`. This points Bedrock to the specific Lambda function ARN responsible for executing the actions in this group.\n",
    "    *   Provide the `functionSchema` defined earlier.\n",
    "\n",
    "5.  **Prepare Agent:**\n",
    "    *   Use `bedrock_agent_client.prepare_agent`.\n",
    "\n",
    "6.  **Create Agent Alias:**\n",
    "    *   Use `bedrock_agent_client.create_agent_alias`.\n",
    "\n",
    "7.  **Invoke Agent:**\n",
    "    *   Use `bedrock_runtime_client.invoke_agent`.\n",
    "    *   Bedrock handles the invocation of the configured Lambda function when the agent decides to use a tool.\n",
    "    *   The application code simply receives the final response from the agent after the tool execution (if any) is complete. It doesn't need to handle `returnControl` events for function execution.\n",
    "    *   *Debugging Note:* The example's `invoke_agent` function includes extensive debugging prints and attempts to manually re-execute the logic *if* the agent's final response `result` is empty but a `returnControl` event *was* observed. This suggests potential issues or complexities in correctly receiving the final result after Lambda execution in the streaming response, leading to this fallback/debugging logic being added in the script.\n",
    "\n",
    "## Pros\n",
    "\n",
    "*   **Decoupling:** Tool execution logic is separate from the main application, potentially managed by different teams or deployment cycles.\n",
    "*   **Scalability:** Leverages the inherent scalability and serverless nature of AWS Lambda for tool execution.\n",
    "*   **Managed Execution:** AWS manages the invocation and execution environment for the Lambda functions.\n",
    "*   **Simpler Application Code:** The application invoking the agent doesn't need to implement the tool logic or handle the `returnControl` event for execution.\n",
    "\n",
    "## Cons\n",
    "\n",
    "*   **Deployment Complexity:** Requires setting up, configuring, and deploying separate Lambda functions, including managing their dependencies and permissions.\n",
    "*   **State Management:** Passing state or context between the main application and the Lambda functions can be more complex (e.g., requires passing connection details, potentially initializing clients within the Lambda).\n",
    "*   **Cold Starts:** Lambda cold starts can introduce latency into the agent's response time.\n",
    "*   **Debugging:** Debugging issues that span the Bedrock Agent service and the Lambda execution can be more challenging.\n",
    "*   **Cost:** Incurs separate Lambda execution costs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import subprocess\n",
    "from datetime import timedelta\n",
    "\n",
    "import boto3\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.exceptions import (InternalServerFailureException,\n",
    "                                  QueryIndexAlreadyExistsException,\n",
    "                                  ServiceUnavailableException)\n",
    "from couchbase.management.buckets import CreateBucketSettings\n",
    "from couchbase.management.search import SearchIndex\n",
    "from couchbase.options import ClusterOptions\n",
    "from dotenv import load_dotenv\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_couchbase.vectorstores import CouchbaseVectorStore\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Environment Variables\n",
    "\n",
    "Load environment variables from the .env file. Make sure to create a .env file with the necessary credentials before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required environment variables are set\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Couchbase Configuration\n",
    "CB_HOST = os.getenv(\"CB_HOST\", \"couchbase://localhost\")\n",
    "CB_USERNAME = os.getenv(\"CB_USERNAME\", \"Administrator\")\n",
    "CB_PASSWORD = os.getenv(\"CB_PASSWORD\", \"password\")\n",
    "CB_BUCKET_NAME = os.getenv(\"CB_BUCKET_NAME\", \"vector-search-testing\")\n",
    "SCOPE_NAME = os.getenv(\"SCOPE_NAME\", \"shared\")\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\", \"bedrock\") \n",
    "INDEX_NAME = os.getenv(\"INDEX_NAME\", \"vector_search_bedrock\")\n",
    "\n",
    "# AWS Configuration\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_ACCOUNT_ID = os.getenv(\"AWS_ACCOUNT_ID\")\n",
    "\n",
    "# Check if required environment variables are set\n",
    "required_vars = [\"AWS_ACCESS_KEY_ID\", \"AWS_SECRET_ACCESS_KEY\", \"AWS_ACCOUNT_ID\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    print(f\"Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"Please set these variables in your .env file\")\n",
    "else:\n",
    "    print(\"All required environment variables are set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize AWS Clients\n",
    "\n",
    "Set up the AWS clients for Bedrock and other services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS clients initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize AWS session\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "# Initialize AWS clients from session\n",
    "iam_client = session.client('iam')\n",
    "bedrock_client = session.client('bedrock')\n",
    "bedrock_agent_client = session.client('bedrock-agent')\n",
    "bedrock_runtime = session.client('bedrock-runtime')\n",
    "bedrock_runtime_client = session.client('bedrock-agent-runtime')\n",
    "lambda_client = session.client('lambda')\n",
    "\n",
    "print(\"AWS clients initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Couchbase and Vector Store\n",
    "\n",
    "Now let's set up the Couchbase connection, collections, and vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_collection(cluster, bucket_name, scope_name, collection_name):\n",
    "    \"\"\"Set up Couchbase collection\"\"\"\n",
    "    try:\n",
    "        # Check if bucket exists, create if it doesn't\n",
    "        try:\n",
    "            bucket = cluster.bucket(bucket_name)\n",
    "            print(f\"Bucket '{bucket_name}' exists.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Bucket '{bucket_name}' does not exist. Creating it...\")\n",
    "            bucket_settings = CreateBucketSettings(\n",
    "                name=bucket_name,\n",
    "                bucket_type='couchbase',\n",
    "                ram_quota_mb=1024,\n",
    "                flush_enabled=True,\n",
    "                num_replicas=0\n",
    "            )\n",
    "            cluster.buckets().create_bucket(bucket_settings)\n",
    "            bucket = cluster.bucket(bucket_name)\n",
    "            print(f\"Bucket '{bucket_name}' created successfully.\")\n",
    "\n",
    "        bucket_manager = bucket.collections()\n",
    "\n",
    "        # Check if scope exists, create if it doesn't\n",
    "        scopes = bucket_manager.get_all_scopes()\n",
    "        scope_exists = any(scope.name == scope_name for scope in scopes)\n",
    "        \n",
    "        if not scope_exists and scope_name != \"_default\":\n",
    "            print(f\"Scope '{scope_name}' does not exist. Creating it...\")\n",
    "            bucket_manager.create_scope(scope_name)\n",
    "            print(f\"Scope '{scope_name}' created successfully.\")\n",
    "\n",
    "        # Check if collection exists, create if it doesn't\n",
    "        collections = bucket_manager.get_all_scopes()\n",
    "        collection_exists = any(\n",
    "            scope.name == scope_name and collection_name in [col.name for col in scope.collections]\n",
    "            for scope in collections\n",
    "        )\n",
    "\n",
    "        if not collection_exists:\n",
    "            print(f\"Collection '{collection_name}' does not exist. Creating it...\")\n",
    "            bucket_manager.create_collection(scope_name, collection_name)\n",
    "            print(f\"Collection '{collection_name}' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Collection '{collection_name}' already exists. Skipping creation.\")\n",
    "\n",
    "        # Wait for collection to be ready\n",
    "        collection = bucket.scope(scope_name).collection(collection_name)\n",
    "        time.sleep(2)  # Give the collection time to be ready for queries\n",
    "\n",
    "        # Ensure primary index exists\n",
    "        try:\n",
    "            cluster.query(f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{bucket_name}`.`{scope_name}`.`{collection_name}`\").execute()\n",
    "            print(\"Primary index present or created successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating primary index: {str(e)}\")\n",
    "\n",
    "        # Clear all documents in the collection\n",
    "        try:\n",
    "            query = f\"DELETE FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
    "            cluster.query(query).execute()\n",
    "            print(\"All documents cleared from the collection.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while clearing documents: {str(e)}. The collection might be empty.\")\n",
    "\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up collection: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_indexes(cluster):\n",
    "    \"\"\"Set up search indexes\"\"\"\n",
    "    try:\n",
    "        # Load index definition from file\n",
    "        with open('aws_index.json', 'r') as file:\n",
    "            index_definition = json.load(file)\n",
    "            print(f\"Loaded index definition from aws_index.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading index definition: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    try:\n",
    "        scope_index_manager = cluster.bucket(CB_BUCKET_NAME).scope(SCOPE_NAME).search_indexes()\n",
    "\n",
    "        # Check if index already exists\n",
    "        existing_indexes = scope_index_manager.get_all_indexes()\n",
    "        index_name = index_definition[\"name\"]\n",
    "\n",
    "        if index_name in [index.name for index in existing_indexes]:\n",
    "            print(f\"Index '{index_name}' found\")\n",
    "        else:\n",
    "            print(f\"Creating new index '{index_name}'...\")\n",
    "\n",
    "        # Create SearchIndex object from JSON definition\n",
    "        search_index = SearchIndex.from_json(index_definition)\n",
    "\n",
    "        # Upsert the index (create if not exists, update if exists)\n",
    "        scope_index_manager.upsert_index(search_index)\n",
    "        print(f\"Index '{index_name}' successfully created/updated.\")\n",
    "\n",
    "    except QueryIndexAlreadyExistsException:\n",
    "        print(f\"Index '{index_name}' already exists. Skipping creation/update.\")\n",
    "    except ServiceUnavailableException:\n",
    "        print(\"Search service is not available. Please ensure the Search service is enabled in your Couchbase cluster.\")\n",
    "    except InternalServerFailureException as e:\n",
    "        print(f\"Internal server error: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Couchbase\n",
      "Bucket 'vector-search-testing' exists.\n",
      "Collection 'bedrock' already exists. Skipping creation.\n",
      "Primary index present or created successfully.\n",
      "All documents cleared from the collection.\n",
      "Collections setup complete\n",
      "Loaded index definition from aws_index.json\n",
      "Index 'vector_search_bedrock' found\n",
      "Index 'vector_search_bedrock' already exists. Skipping creation/update.\n",
      "Search indexes setup complete\n"
     ]
    }
   ],
   "source": [
    "# Connect to Couchbase\n",
    "auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
    "options = ClusterOptions(auth)\n",
    "cluster = Cluster(CB_HOST, options)\n",
    "cluster.wait_until_ready(timedelta(seconds=5))\n",
    "print(\"Successfully connected to Couchbase\")\n",
    "\n",
    "# Set up collections\n",
    "collection = setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, COLLECTION_NAME)\n",
    "print(\"Collections setup complete\")\n",
    "\n",
    "# Set up search indexes\n",
    "setup_indexes(cluster)\n",
    "print(\"Search indexes setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created Bedrock embeddings client\n",
      "Successfully created vector store\n"
     ]
    }
   ],
   "source": [
    "# Initialize Bedrock runtime client for embeddings\n",
    "embeddings = BedrockEmbeddings(\n",
    "    client=bedrock_runtime,\n",
    "    model_id=\"amazon.titan-embed-text-v2:0\"\n",
    ")\n",
    "print(\"Successfully created Bedrock embeddings client\")\n",
    "\n",
    "# Initialize vector store\n",
    "vector_store = CouchbaseVectorStore(\n",
    "    cluster=cluster,\n",
    "    bucket_name=CB_BUCKET_NAME,\n",
    "    scope_name=SCOPE_NAME,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding=embeddings,\n",
    "    index_name=INDEX_NAME\n",
    ")\n",
    "print(\"Successfully created vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Vector Store Operations\n",
    "\n",
    "Let's define some helper functions for working with the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_document(vector_store, text, metadata=None):\n",
    "    \"\"\"Add a document to the vector store\"\"\"\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    elif isinstance(metadata, str):\n",
    "        try:\n",
    "            metadata = json.loads(metadata)\n",
    "        except json.JSONDecodeError:\n",
    "            metadata = {}\n",
    "    return vector_store.add_texts([text], [metadata])[0]\n",
    "\n",
    "def search_documents(vector_store, query, k=4):\n",
    "    \"\"\"Search for similar documents\"\"\"\n",
    "    return vector_store.similarity_search(query, k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents from JSON File\n",
    "\n",
    "Let's load the documents from the documents.json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 documents from documents.json\n",
      "Adding 7 documents to vector store...\n",
      "Added document 1/7 with ID: efe910ac824c439aa464f0919a954d21\n",
      "Added document 2/7 with ID: 6e9929e0e98946a8adf5db612b688a0a\n",
      "Added document 3/7 with ID: 6122a2fda96d4da9b3a0b83dc18d9b20\n",
      "Added document 4/7 with ID: 2512928812d64dabb00861369cd8c87e\n",
      "Added document 5/7 with ID: 2b6d94fee77e4f8caf95e75c33d61f35\n",
      "Added document 6/7 with ID: 83a8e2f4aacf43b199683a91a7525240\n",
      "Added document 7/7 with ID: 98c788ec2938458b89d650d864427f53\n",
      "\n",
      "Processing complete: 7/7 documents added successfully\n"
     ]
    }
   ],
   "source": [
    "# Load documents from JSON file\n",
    "try:\n",
    "    with open('documents.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        documents = data.get('documents', [])\n",
    "    print(f\"Loaded {len(documents)} documents from documents.json\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading documents: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Add documents to vector store\n",
    "print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    text = doc.get('text', '')\n",
    "    metadata = doc.get('metadata', {})\n",
    "    \n",
    "    # Add document to vector store\n",
    "    doc_id = add_document(vector_store, text, json.dumps(metadata))\n",
    "    print(f\"Added document {i}/{len(documents)} with ID: {doc_id}\")\n",
    "    \n",
    "    # Add small delay between requests\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"\\nProcessing complete: {len(documents)}/{len(documents)} documents added successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Approach Implementation\n",
    "\n",
    "Now let's implement the Lambda approach for Bedrock agents. This approach involves deploying Lambda functions that will be invoked by the Bedrock agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Lambda Functions\n",
    "\n",
    "First, let's deploy the Lambda functions that will be invoked by our Bedrock agents. We'll create a .env file for the Lambda functions with the Couchbase configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created .env file for Lambda functions at lambda_functions/.env\n"
     ]
    }
   ],
   "source": [
    "# Create a .env file for the Lambda functions\n",
    "lambda_env_path = 'lambda_functions/.env'\n",
    "with open(lambda_env_path, 'w') as f:\n",
    "    f.write(f\"CB_HOST={CB_HOST}\\n\")\n",
    "    f.write(f\"CB_USERNAME={CB_USERNAME}\\n\")\n",
    "    f.write(f\"CB_PASSWORD={CB_PASSWORD}\\n\")\n",
    "    f.write(f\"CB_BUCKET_NAME={CB_BUCKET_NAME}\\n\")\n",
    "    f.write(f\"SCOPE_NAME={SCOPE_NAME}\\n\")\n",
    "    f.write(f\"COLLECTION_NAME={COLLECTION_NAME}\\n\")\n",
    "    f.write(f\"INDEX_NAME={INDEX_NAME}\\n\")\n",
    "\n",
    "print(f\"Created .env file for Lambda functions at {lambda_env_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying Lambda functions...\n",
      "Using existing IAM role: bedrock_agent_lambda_role\n",
      "Deleting existing Lambda function: bedrock_agent_researcher\n",
      "Waiting for bedrock_agent_researcher to be deleted...\n",
      "Deleting existing Lambda function: bedrock_agent_writer\n",
      "Waiting for bedrock_agent_writer to be deleted...\n",
      "\n",
      "=== Deploying researcher function ===\n",
      "Installing dependencies for bedrock_agent_researcher...\n",
      "Waiting for role arn:aws:iam::598307997273:role/bedrock_agent_lambda_role to be ready...\n",
      "Zip file size: 45.58 MB\n",
      "File size (45.58 MB) exceeds 10MB. Using S3 for deployment...\n",
      "Creating S3 bucket: lambda-deployment-598307997273-1741034442 (attempt 1/3)...\n",
      "Created S3 bucket: lambda-deployment-598307997273-1741034442\n",
      "Waiting for bucket to be available...\n",
      "Uploading bedrock_agent_researcher.zip to S3 bucket lambda-deployment-598307997273-1741034442...\n",
      "Successfully uploaded bedrock_agent_researcher.zip to s3://lambda-deployment-598307997273-1741034442/lambda/bedrock_agent_researcher.zip-983f0c1a\n",
      "Creating function bedrock_agent_researcher (attempt 1/5)...\n",
      "Successfully created function bedrock_agent_researcher on attempt 1\n",
      "\n",
      "=== Deploying writer function ===\n",
      "Installing dependencies for bedrock_agent_writer...\n",
      "Waiting for role arn:aws:iam::598307997273:role/bedrock_agent_lambda_role to be ready...\n",
      "Zip file size: 45.58 MB\n",
      "File size (45.58 MB) exceeds 10MB. Using S3 for deployment...\n",
      "Creating S3 bucket: lambda-deployment-598307997273-1741034509 (attempt 1/3)...\n",
      "Created S3 bucket: lambda-deployment-598307997273-1741034509\n",
      "Waiting for bucket to be available...\n",
      "Uploading bedrock_agent_writer.zip to S3 bucket lambda-deployment-598307997273-1741034509...\n",
      "Successfully uploaded bedrock_agent_writer.zip to s3://lambda-deployment-598307997273-1741034509/lambda/bedrock_agent_writer.zip-e2b32728\n",
      "Creating function bedrock_agent_writer (attempt 1/5)...\n",
      "Successfully created function bedrock_agent_writer on attempt 1\n",
      "\n",
      "Deployment complete!\n",
      "Lambda functions deployed successfully\n"
     ]
    }
   ],
   "source": [
    "# Deploy Lambda functions\n",
    "print(\"Deploying Lambda functions...\")\n",
    "try:\n",
    "    subprocess.run([\n",
    "        'python3', \n",
    "        'lambda_functions/deploy.py'\n",
    "    ], check=True)\n",
    "    print(\"Lambda functions deployed successfully\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error deploying Lambda functions: {str(e)}\")\n",
    "    raise RuntimeError(\"Failed to deploy Lambda functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Approach Helper Functions\n",
    "\n",
    "Let's define some helper functions for the Lambda approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_agent_status(bedrock_agent_client, agent_id, target_statuses=['Available', 'PREPARED', 'NOT_PREPARED'], max_attempts=30, delay=2):\n",
    "    \"\"\"Wait for agent to reach any of the target statuses\"\"\"\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            response = bedrock_agent_client.get_agent(agentId=agent_id)\n",
    "            current_status = response['agent']['agentStatus']\n",
    "            \n",
    "            if current_status in target_statuses:\n",
    "                print(f\"Agent {agent_id} reached status: {current_status}\")\n",
    "                return current_status\n",
    "            elif current_status == 'FAILED':\n",
    "                print(f\"Agent {agent_id} failed\")\n",
    "                return 'FAILED'\n",
    "            \n",
    "            print(f\"Agent status: {current_status}, waiting... (attempt {attempt + 1}/{max_attempts})\")\n",
    "            time.sleep(delay)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error checking agent status: {str(e)}\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    return current_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(bedrock_agent_client, name, instructions, functions, model_id=\"amazon.nova-pro-v1:0\"):\n",
    "    \"\"\"Create a Bedrock agent with Lambda action groups\"\"\"\n",
    "    try:\n",
    "        # List existing agents\n",
    "        existing_agents = bedrock_agent_client.list_agents()\n",
    "        existing_agent = next(\n",
    "            (agent for agent in existing_agents['agentSummaries'] \n",
    "             if agent['agentName'] == name),\n",
    "            None\n",
    "        )\n",
    "        \n",
    "        # Handle existing agent\n",
    "        if existing_agent:\n",
    "            agent_id = existing_agent['agentId']\n",
    "            print(f\"Found existing agent '{name}' with ID: {agent_id}\")\n",
    "            \n",
    "            # Check agent status\n",
    "            response = bedrock_agent_client.get_agent(agentId=agent_id)\n",
    "            status = response['agent']['agentStatus']\n",
    "            \n",
    "            if status in ['NOT_PREPARED', 'FAILED']:\n",
    "                print(f\"Deleting agent '{name}' with status {status}\")\n",
    "                bedrock_agent_client.delete_agent(agentId=agent_id)\n",
    "                time.sleep(10)  # Wait after deletion\n",
    "                existing_agent = None\n",
    "        \n",
    "        # Create new agent if needed\n",
    "        if not existing_agent:\n",
    "            print(f\"Creating new agent '{name}'\")\n",
    "            agent = bedrock_agent_client.create_agent(\n",
    "                agentName=name,\n",
    "                description=f\"{name.title()} agent for document operations\",\n",
    "                instruction=instructions,\n",
    "                idleSessionTTLInSeconds=1800,\n",
    "                foundationModel=model_id\n",
    "            )\n",
    "            agent_id = agent['agent']['agentId']\n",
    "            print(f\"Created new agent '{name}' with ID: {agent_id}\")\n",
    "        else:\n",
    "            agent_id = existing_agent['agentId']\n",
    "        \n",
    "        # Wait for initial creation if needed\n",
    "        status = wait_for_agent_status(bedrock_agent_client, agent_id, target_statuses=['NOT_PREPARED', 'PREPARED', 'Available'])\n",
    "        if status not in ['NOT_PREPARED', 'PREPARED', 'Available']:\n",
    "            raise Exception(f\"Agent failed to reach valid state: {status}\")\n",
    "        \n",
    "        # Handle alias creation/retrieval\n",
    "        try:\n",
    "            aliases = bedrock_agent_client.list_agent_aliases(agentId=agent_id)\n",
    "            alias = next((a for a in aliases['agentAliasSummaries'] if a['agentAliasName'] == 'v1'), None)\n",
    "            \n",
    "            if not alias:\n",
    "                print(f\"Creating new alias for agent '{name}'\")\n",
    "                alias = bedrock_agent_client.create_agent_alias(\n",
    "                    agentId=agent_id,\n",
    "                    agentAliasName=\"v1\"\n",
    "                )\n",
    "                alias_id = alias['agentAlias']['agentAliasId']\n",
    "            else:\n",
    "                alias_id = alias['agentAliasId']\n",
    "                print(f\"Using existing alias for agent '{name}'\")\n",
    "            \n",
    "            print(f\"Successfully configured agent '{name}' with ID: {agent_id} and alias: {alias_id}\")\n",
    "            return agent_id, alias_id\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error managing alias: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating/updating agent: {str(e)}\")\n",
    "        raise RuntimeError(f\"Failed to create/update agent: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_agent(bedrock_runtime_client, agent_id, alias_id, input_text, session_id=None, vector_store=None):\n",
    "    \"\"\"Invoke a Bedrock agent with improved debugging and error handling\"\"\"\n",
    "    if session_id is None:\n",
    "        session_id = str(uuid.uuid4())\n",
    "        \n",
    "    try:\n",
    "        print(f\"Invoking agent with input: {input_text}\")\n",
    "        \n",
    "        # Enable trace for debugging\n",
    "        response = bedrock_runtime_client.invoke_agent(\n",
    "            agentId=agent_id,\n",
    "            agentAliasId=alias_id,\n",
    "            sessionId=session_id,\n",
    "            inputText=input_text,\n",
    "            enableTrace=True  # Enable tracing for debugging\n",
    "        )\n",
    "        \n",
    "        result = \"\"\n",
    "        \n",
    "        # Store all trace events for later processing\n",
    "        all_traces = []\n",
    "        return_control_events = []\n",
    "        \n",
    "        # Process the streaming response\n",
    "        for event in response['completion']:\n",
    "            if 'chunk' in event:\n",
    "                chunk = event['chunk']['bytes'].decode('utf-8')\n",
    "                result += chunk\n",
    "            \n",
    "            # Handle Lambda function response in trace\n",
    "            if 'trace' in event:\n",
    "                trace_data = event['trace']\n",
    "                all_traces.append(trace_data)\n",
    "                \n",
    "                if isinstance(trace_data, dict) and 'orchestrationTrace' in trace_data:\n",
    "                    orch_trace = trace_data['orchestrationTrace']\n",
    "                    \n",
    "                    if 'invocationOutput' in orch_trace:\n",
    "                        invocation_output = orch_trace['invocationOutput']\n",
    "                        \n",
    "                        if 'actionGroupInvocationOutput' in invocation_output:\n",
    "                            action_output = invocation_output['actionGroupInvocationOutput']\n",
    "                            \n",
    "                            if 'responseBody' in action_output:\n",
    "                                response_body = action_output['responseBody']\n",
    "                                \n",
    "                                if isinstance(response_body, dict) and 'application/json' in response_body:\n",
    "                                    json_body = response_body['application/json']\n",
    "                                    \n",
    "                                    if 'body' in json_body:\n",
    "                                        lambda_result = json_body['body']\n",
    "                                        result = lambda_result\n",
    "            \n",
    "            if 'returnControl' in event:\n",
    "                return_control_events.append(event['returnControl'])\n",
    "                \n",
    "                # Handle the returnControl event\n",
    "                return_control = event['returnControl']\n",
    "                invocation_inputs = return_control.get('invocationInputs', [])\n",
    "                \n",
    "                if invocation_inputs:\n",
    "                    function_input = invocation_inputs[0].get('functionInvocationInput', {})\n",
    "                    action_group = function_input.get('actionGroup')\n",
    "                    function_name = function_input.get('function')\n",
    "                    parameters = function_input.get('parameters', [])\n",
    "                    \n",
    "                    # Convert parameters to a dictionary\n",
    "                    param_dict = {}\n",
    "                    for param in parameters:\n",
    "                        param_dict[param.get('name')] = param.get('value')\n",
    "                    \n",
    "                    print(f\"Function call: {action_group}::{function_name}\")\n",
    "                    \n",
    "                    # Handle search_documents function\n",
    "                    if action_group == 'researcher_actions' and function_name == 'search_documents':\n",
    "                        query = param_dict.get('query')\n",
    "                        k = int(param_dict.get('k', 3))\n",
    "                        \n",
    "                        print(f\"Searching for: {query}, k={k}\")\n",
    "                        \n",
    "                        if vector_store:\n",
    "                            # Perform the search\n",
    "                            docs = search_documents(vector_store, query, k)\n",
    "                            \n",
    "                            # Format results\n",
    "                            search_results = [doc.page_content for doc in docs]\n",
    "                            print(f\"Found {len(search_results)} results\")\n",
    "                            \n",
    "                            # Format the response\n",
    "                            result = f\"Search results for '{query}':\\n\\n\"\n",
    "                            for i, content in enumerate(search_results):\n",
    "                                result += f\"Result {i+1}: {content}\\n\\n\"\n",
    "                        else:\n",
    "                            print(\"Vector store not available\")\n",
    "                            result = \"Error: Vector store not available\"\n",
    "                    \n",
    "                    # Handle format_content function\n",
    "                    elif action_group == 'writer_actions' and function_name == 'format_content':\n",
    "                        content = param_dict.get('content')\n",
    "                        style = param_dict.get('style', 'user-friendly')\n",
    "                        \n",
    "                        print(f\"Formatting content in {style} style\")\n",
    "                        \n",
    "                        # Check if content is valid\n",
    "                        if content and content != '?':\n",
    "                            # Use a simple formatting approach\n",
    "                            result = f\"Formatted in {style} style: {content}\"\n",
    "                        else:\n",
    "                            result = \"No content provided to format.\"\n",
    "                    else:\n",
    "                        print(f\"Unknown function: {function_name}\")\n",
    "                        result = f\"Error: Unknown function {function_name}\"\n",
    "        \n",
    "        if not result.strip():\n",
    "            print(\"Received empty response from agent\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking agent: {str(e)}\")\n",
    "        raise RuntimeError(f\"Failed to invoke agent: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Instructions and Functions\n",
    "\n",
    "Now let's define the instructions and functions for our agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Researcher agent instructions\n",
    "researcher_instructions = \"\"\"\n",
    "You are a Research Assistant that helps users find relevant information in documents.\n",
    "Your capabilities include:\n",
    "1. Searching through documents using semantic similarity\n",
    "2. Providing relevant document excerpts\n",
    "3. Answering questions based on document content\n",
    "\"\"\"\n",
    "\n",
    "# Researcher agent functions\n",
    "researcher_functions = [{\n",
    "    \"name\": \"search_documents\",\n",
    "    \"description\": \"Search for relevant documents using semantic similarity\",\n",
    "    \"parameters\": {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The search query\",\n",
    "            \"required\": True\n",
    "        },\n",
    "        \"k\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"Number of results to return\",\n",
    "            \"required\": False\n",
    "        }\n",
    "    },\n",
    "    \"requireConfirmation\": \"DISABLED\"\n",
    "}]\n",
    "\n",
    "# Writer agent instructions\n",
    "writer_instructions = \"\"\"\n",
    "You are a Content Writer Assistant that helps format and present research findings.\n",
    "Your capabilities include:\n",
    "1. Formatting research findings in a user-friendly way\n",
    "2. Creating clear and engaging summaries\n",
    "3. Organizing information logically\n",
    "4. Highlighting key insights\n",
    "\"\"\"\n",
    "\n",
    "# Writer agent functions\n",
    "writer_functions = [{\n",
    "    \"name\": \"format_content\",\n",
    "    \"description\": \"Format and present research findings\",\n",
    "    \"parameters\": {\n",
    "        \"content\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The research findings to format\",\n",
    "            \"required\": True\n",
    "        },\n",
    "        \"style\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The desired presentation style (e.g., summary, detailed, bullet points)\",\n",
    "            \"required\": False\n",
    "        }\n",
    "    },\n",
    "    \"requireConfirmation\": \"DISABLED\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Lambda Approach\n",
    "\n",
    "Now let's run the Lambda approach with our agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing agent 'researcher' with ID: FZX7XPEHVK\n",
      "Agent FZX7XPEHVK reached status: PREPARED\n",
      "Using existing alias for agent 'researcher'\n",
      "Successfully configured agent 'researcher' with ID: FZX7XPEHVK and alias: 8A60QDPM05\n",
      "Researcher agent created with ID: FZX7XPEHVK and alias: 8A60QDPM05\n",
      "Found existing agent 'writer' with ID: J08JUS1UVN\n",
      "Agent J08JUS1UVN reached status: PREPARED\n",
      "Using existing alias for agent 'writer'\n",
      "Successfully configured agent 'writer' with ID: J08JUS1UVN and alias: YJKVWNCWRL\n",
      "Writer agent created with ID: J08JUS1UVN and alias: YJKVWNCWRL\n"
     ]
    }
   ],
   "source": [
    "# Create researcher agent\n",
    "try:\n",
    "    researcher_id, researcher_alias = create_agent(\n",
    "        bedrock_agent_client,\n",
    "        \"researcher\", \n",
    "        researcher_instructions, \n",
    "        researcher_functions\n",
    "    )\n",
    "    print(f\"Researcher agent created with ID: {researcher_id} and alias: {researcher_alias}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create researcher agent: {str(e)}\")\n",
    "    researcher_id, researcher_alias = None, None\n",
    "\n",
    "# Create writer agent\n",
    "try:\n",
    "    writer_id, writer_alias = create_agent(\n",
    "        bedrock_agent_client,\n",
    "        \"writer\", \n",
    "        writer_instructions, \n",
    "        writer_functions\n",
    "    )\n",
    "    print(f\"Writer agent created with ID: {writer_id} and alias: {writer_alias}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create writer agent: {str(e)}\")\n",
    "    writer_id, writer_alias = None, None\n",
    "\n",
    "if not any([researcher_id, writer_id]):\n",
    "    raise RuntimeError(\"Failed to create any agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researcher Lambda action group already exists\n",
      "Preparing researcher agent...\n",
      "Agent status: PREPARING, waiting... (attempt 1/30)\n",
      "Agent FZX7XPEHVK reached status: PREPARED\n",
      "Researcher agent preparation completed with status: PREPARED\n"
     ]
    }
   ],
   "source": [
    "# Create action group for researcher agent with Lambda executor\n",
    "try:\n",
    "    bedrock_agent_client.create_agent_action_group(\n",
    "        agentId=researcher_id,\n",
    "        agentVersion=\"DRAFT\",\n",
    "        actionGroupExecutor={\n",
    "            \"lambda\": f\"arn:aws:lambda:{AWS_REGION}:{AWS_ACCOUNT_ID}:function:bedrock_agent_researcher\"\n",
    "        },  # This is the key for Lambda approach\n",
    "        actionGroupName=\"researcher_actions\",\n",
    "        functionSchema={\"functions\": researcher_functions},\n",
    "        description=\"Action group for researcher operations with Lambda\"\n",
    "    )\n",
    "    print(\"Created researcher Lambda action group\")\n",
    "except bedrock_agent_client.exceptions.ConflictException:\n",
    "    print(\"Researcher Lambda action group already exists\")\n",
    "    \n",
    "# Prepare researcher agent\n",
    "print(\"Preparing researcher agent...\")\n",
    "bedrock_agent_client.prepare_agent(agentId=researcher_id)\n",
    "status = wait_for_agent_status(\n",
    "    bedrock_agent_client,\n",
    "    researcher_id, \n",
    "    target_statuses=['PREPARED', 'Available']\n",
    ")\n",
    "print(f\"Researcher agent preparation completed with status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer Lambda action group already exists\n",
      "Preparing writer agent...\n",
      "Agent status: PREPARING, waiting... (attempt 1/30)\n",
      "Agent J08JUS1UVN reached status: PREPARED\n",
      "Writer agent preparation completed with status: PREPARED\n"
     ]
    }
   ],
   "source": [
    "# Create action group for writer agent with Lambda executor\n",
    "try:\n",
    "    bedrock_agent_client.create_agent_action_group(\n",
    "        agentId=writer_id,\n",
    "        agentVersion=\"DRAFT\",\n",
    "        actionGroupExecutor={\n",
    "            \"lambda\": f\"arn:aws:lambda:{AWS_REGION}:{AWS_ACCOUNT_ID}:function:bedrock_agent_writer\"\n",
    "        },  # This is the key for Lambda approach\n",
    "        actionGroupName=\"writer_actions\",\n",
    "        functionSchema={\"functions\": writer_functions},\n",
    "        description=\"Action group for writer operations with Lambda\"\n",
    "    )\n",
    "    print(\"Created writer Lambda action group\")\n",
    "except bedrock_agent_client.exceptions.ConflictException:\n",
    "    print(\"Writer Lambda action group already exists\")\n",
    "    \n",
    "# Prepare writer agent\n",
    "print(\"Preparing writer agent...\")\n",
    "bedrock_agent_client.prepare_agent(agentId=writer_id)\n",
    "status = wait_for_agent_status(\n",
    "    bedrock_agent_client,\n",
    "    writer_id, \n",
    "    target_statuses=['PREPARED', 'Available']\n",
    ")\n",
    "print(f\"Writer agent preparation completed with status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Agents\n",
    "\n",
    "Let's test our agents by asking the researcher agent to search for information and the writer agent to format the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking agent with input: What is unique about the Cline AI assistant? Use the search_documents function to find relevant information.\n",
      "Function call: researcher_actions::search_documents\n",
      "Searching for: Cline AI assistant unique features, k=5\n",
      "Found 5 results\n",
      "\n",
      "Researcher Response:\n",
      " Search results for 'Cline AI assistant unique features':\n",
      "\n",
      "Result 1: The Cline AI assistant, developed by Saoud Rizwan, is a unique system that combines vector search capabilities with Amazon Bedrock agents. Unlike traditional chatbots, it uses a sophisticated multi-agent architecture where specialized agents handle different aspects of document processing and interaction.\n",
      "\n",
      "Result 2: One of Cline's key features is its ability to create MCP (Model Context Protocol) servers on the fly. This allows users to extend the system's capabilities by adding new tools and resources that connect to external APIs, all while maintaining a secure and non-interactive environment.\n",
      "\n",
      "Result 3: The browser automation capabilities in Cline are implemented through Puppeteer, allowing the system to interact with web interfaces in a controlled 900x600 pixel window. This enables testing of web applications, verification of changes, and even general web browsing tasks.\n",
      "\n",
      "Result 4: Cline's development workflow is unique in its use of Plan Mode and Act Mode. Plan Mode enables collaborative brainstorming and architecture discussions, while Act Mode focuses on implementation using tools like file operations, CLI commands, and browser automation.\n",
      "\n",
      "Result 5: Cline's file handling system uses two main tools: write_to_file for complete file creation or overwriting, and replace_in_file for targeted edits. The system is smart enough to handle auto-formatting and maintains file integrity through careful change management.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test researcher agent\n",
    "researcher_response = invoke_agent(\n",
    "    bedrock_runtime_client,\n",
    "    researcher_id,\n",
    "    researcher_alias,\n",
    "    'What is unique about the Cline AI assistant? Use the search_documents function to find relevant information.',\n",
    "    vector_store=vector_store\n",
    ")\n",
    "print(\"\\nResearcher Response:\\n\", researcher_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking agent with input: Format this research finding using the format_content function: Search results for 'Cline AI assistant unique features':\n",
      "\n",
      "Result 1: The Cline AI assistant, developed by Saoud Rizwan, is a unique system that combines vector search capabilities with Amazon Bedrock agents. Unlike traditional chatbots, it uses a sophisticated multi-agent architecture where specialized agents handle different aspects of document processing and interaction.\n",
      "\n",
      "Result 2: One of Cline's key features is its ability to create MCP (Model Context Protocol) servers on the fly. This allows users to extend the system's capabilities by adding new tools and resources that connect to external APIs, all while maintaining a secure and non-interactive environment.\n",
      "\n",
      "Result 3: The browser automation capabilities in Cline are implemented through Puppeteer, allowing the system to interact with web interfaces in a controlled 900x600 pixel window. This enables testing of web applications, verification of changes, and even general web browsing tasks.\n",
      "\n",
      "Result 4: Cline's development workflow is unique in its use of Plan Mode and Act Mode. Plan Mode enables collaborative brainstorming and architecture discussions, while Act Mode focuses on implementation using tools like file operations, CLI commands, and browser automation.\n",
      "\n",
      "Result 5: Cline's file handling system uses two main tools: write_to_file for complete file creation or overwriting, and replace_in_file for targeted edits. The system is smart enough to handle auto-formatting and maintains file integrity through careful change management.\n",
      "\n",
      "\n",
      "Function call: writer_actions::format_content\n",
      "Formatting content in bullet points style\n",
      "\n",
      "Writer Response:\n",
      " Formatted in bullet points style: Search results for 'Cline AI assistant unique features':\n",
      "\n",
      "Result 1: The Cline AI assistant, developed by Saoud Rizwan, is a unique system that combines vector search capabilities with Amazon Bedrock agents. Unlike traditional chatbots, it uses a sophisticated multi-agent architecture where specialized agents handle different aspects of document processing and interaction.\n",
      "\n",
      "Result 2: One of Cline's key features is its ability to create MCP (Model Context Protocol) servers on the fly. This allows users to extend the system's capabilities by adding new tools and resources that connect to external APIs, all while maintaining a secure and non-interactive environment.\n",
      "\n",
      "Result 3: The browser automation capabilities in Cline are implemented through Puppeteer, allowing the system to interact with web interfaces in a controlled 900x600 pixel window. This enables testing of web applications, verification of changes, and even general web browsing tasks.\n",
      "\n",
      "Result 4: Cline's development workflow is unique in its use of Plan Mode and Act Mode. Plan Mode enables collaborative brainstorming and architecture discussions, while Act Mode focuses on implementation using tools like file operations, CLI commands, and browser automation.\n",
      "\n",
      "Result 5: Cline's file handling system uses two main tools: write_to_file for complete file creation or overwriting, and replace_in_file for targeted edits. The system is smart enough to handle auto-formatting and maintains file integrity through careful change management.\n"
     ]
    }
   ],
   "source": [
    "# Test writer agent\n",
    "writer_response = invoke_agent(\n",
    "    bedrock_runtime_client,\n",
    "    writer_id,\n",
    "    writer_alias,\n",
    "    f'Format this research finding using the format_content function: {researcher_response}',\n",
    "    vector_store=vector_store\n",
    ")\n",
    "print(\"\\nWriter Response:\\n\", writer_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the Lambda approach for implementing AWS Bedrock agents with Couchbase Vector Search. This approach allows the agent to invoke AWS Lambda functions to execute operations, providing better scalability and separation of concerns.\n",
    "\n",
    "Key components of this implementation include:\n",
    "\n",
    "1. **Vector Store Setup**: We set up a Couchbase vector store to store and search documents using semantic similarity.\n",
    "2. **Lambda Function Deployment**: We deployed Lambda functions that handle the agent's function calls.\n",
    "3. **Agent Creation**: We created two specialized agents - a researcher agent for searching documents and a writer agent for formatting results.\n",
    "4. **Lambda Integration**: We integrated the agents with Lambda functions, allowing them to execute operations in a serverless environment.\n",
    "\n",
    "This approach is particularly useful for production environments where scalability and separation of concerns are important. The Lambda functions can be deployed independently and can access other AWS services, providing more flexibility and power."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
