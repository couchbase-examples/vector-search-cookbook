{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction placeholder text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to run this tutorial placeholder text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start placeholder text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing necessary libraries placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet datasets langchain-couchbase langchain-deepseek langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import time\n",
    "import getpass\n",
    "from uuid import uuid4\n",
    "\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.exceptions import CouchbaseException, InternalServerFailureException, QueryIndexAlreadyExistsException\n",
    "from couchbase.management.search import SearchIndex\n",
    "from couchbase.options import ClusterOptions\n",
    "from datasets import load_dataset\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_deepseek import ChatDeepseek\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_couchbase.cache import CouchbaseCache\n",
    "from langchain_couchbase.vectorstores import CouchbaseVectorStore\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup logging placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading sensitive information placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file if it exists\n",
    "load_dotenv()\n",
    "\n",
    "# API Keys\n",
    "DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY') or getpass.getpass('Enter your Deepseek API Key: ')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or getpass.getpass('Enter your OpenAI API Key: ')\n",
    "\n",
    "# Couchbase Settings\n",
    "CB_HOST = os.getenv('CB_HOST') or input('Enter your Couchbase host (default: couchbase://localhost): ') or 'couchbase://localhost'\n",
    "CB_USERNAME = os.getenv('CB_USERNAME') or input('Enter your Couchbase username (default: Administrator): ') or 'Administrator'\n",
    "CB_PASSWORD = os.getenv('CB_PASSWORD') or getpass.getpass('Enter your Couchbase password (default: password): ') or 'password'\n",
    "CB_BUCKET_NAME = os.getenv('CB_BUCKET_NAME') or input('Enter your Couchbase bucket name (default: vector-search-testing): ') or 'vector-search-testing'\n",
    "INDEX_NAME = os.getenv('INDEX_NAME') or input('Enter your index name (default: vector_search_deepseek): ') or 'vector_search_deepseek'\n",
    "SCOPE_NAME = os.getenv('SCOPE_NAME') or input('Enter your scope name (default: shared): ') or 'shared'\n",
    "COLLECTION_NAME = os.getenv('COLLECTION_NAME') or input('Enter your collection name (default: deepseek): ') or 'deepseek'\n",
    "CACHE_COLLECTION = os.getenv('CACHE_COLLECTION') or input('Enter your cache collection name (default: cache): ') or 'cache'\n",
    "\n",
    "# Check if required credentials are set\n",
    "for cred_name, cred_value in {\n",
    "    'DEEPSEEK_API_KEY': DEEPSEEK_API_KEY,\n",
    "    'OPENAI_API_KEY': OPENAI_API_KEY,\n",
    "    'CB_HOST': CB_HOST,\n",
    "    'CB_USERNAME': CB_USERNAME,\n",
    "    'CB_PASSWORD': CB_PASSWORD,\n",
    "    'CB_BUCKET_NAME': CB_BUCKET_NAME\n",
    "}.items():\n",
    "    if not cred_value:\n",
    "        raise ValueError(f\"{cred_name} is not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to Couchbase placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
    "    options = ClusterOptions(auth)\n",
    "    cluster = Cluster(CB_HOST, options)\n",
    "    cluster.wait_until_ready(timedelta(seconds=5))\n",
    "    logging.info(\"Successfully connected to Couchbase\")\n",
    "except Exception as e:\n",
    "    raise ConnectionError(f\"Failed to connect to Couchbase: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up collections placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_collection(cluster, bucket_name, scope_name, collection_name):\n",
    "    try:\n",
    "        bucket = cluster.bucket(bucket_name)\n",
    "        bucket_manager = bucket.collections()\n",
    "\n",
    "        # Check if collection exists, create if it doesn't\n",
    "        collections = bucket_manager.get_all_scopes()\n",
    "        collection_exists = any(\n",
    "            scope.name == scope_name and collection_name in [col.name for col in scope.collections]\n",
    "            for scope in collections\n",
    "        )\n",
    "\n",
    "        if not collection_exists:\n",
    "            logging.info(f\"Collection '{collection_name}' does not exist. Creating it...\")\n",
    "            bucket_manager.create_collection(scope_name, collection_name)\n",
    "            logging.info(f\"Collection '{collection_name}' created successfully.\")\n",
    "        else:\n",
    "            logging.info(f\"Collection '{collection_name}' already exists. Skipping creation.\")\n",
    "\n",
    "        collection = bucket.scope(scope_name).collection(collection_name)\n",
    "\n",
    "        # Ensure primary index exists\n",
    "        try:\n",
    "            cluster.query(f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{bucket_name}`.`{scope_name}`.`{collection_name}`\").execute()\n",
    "            logging.info(\"Primary index present or created successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error creating primary index: {str(e)}\")\n",
    "\n",
    "        # Clear all documents in the collection\n",
    "        try:\n",
    "            query = f\"DELETE FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
    "            cluster.query(query).execute()\n",
    "            logging.info(\"All documents cleared from the collection.\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error while clearing documents: {str(e)}. The collection might be empty.\")\n",
    "\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error setting up collection: {str(e)}\")\n",
    "\n",
    "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, COLLECTION_NAME)\n",
    "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, CACHE_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading vector search index placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('deepseek_index.json', 'r') as file:\n",
    "        index_definition = json.load(file)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading index definition: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating search indexes placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    scope_index_manager = cluster.bucket(CB_BUCKET_NAME).scope(SCOPE_NAME).search_indexes()\n",
    "\n",
    "    # Check if index already exists\n",
    "    existing_indexes = scope_index_manager.get_all_indexes()\n",
    "    index_name = index_definition[\"name\"]\n",
    "\n",
    "    if index_name in [index.name for index in existing_indexes]:\n",
    "        logging.info(f\"Index '{index_name}' found\")\n",
    "    else:\n",
    "        logging.info(f\"Creating new index '{index_name}'...\")\n",
    "\n",
    "    # Create SearchIndex object from JSON definition\n",
    "    search_index = SearchIndex.from_json(index_definition)\n",
    "\n",
    "    # Upsert the index (create if not exists, update if exists)\n",
    "    scope_index_manager.upsert_index(search_index)\n",
    "    logging.info(f\"Index '{index_name}' successfully created/updated.\")\n",
    "\n",
    "except QueryIndexAlreadyExistsException:\n",
    "    logging.info(f\"Index '{index_name}' already exists. Skipping creation/update.\")\n",
    "\n",
    "except InternalServerFailureException as e:\n",
    "    error_message = str(e)\n",
    "    logging.error(f\"InternalServerFailureException raised: {error_message}\")\n",
    "\n",
    "    try:\n",
    "        # Accessing the response_body attribute from the context\n",
    "        error_context = e.context\n",
    "        response_body = error_context.response_body\n",
    "        if response_body:\n",
    "            error_details = json.loads(response_body)\n",
    "            error_message = error_details.get('error', '')\n",
    "\n",
    "            if \"collection: 'deepseek' doesn't belong to scope: 'shared'\" in error_message:\n",
    "                raise ValueError(\"Collection 'deepseek' does not belong to scope 'shared'. Please check the collection and scope names.\")\n",
    "\n",
    "    except ValueError as ve:\n",
    "        logging.error(str(ve))\n",
    "        raise\n",
    "\n",
    "    except Exception as json_error:\n",
    "        logging.error(f\"Failed to parse the error message: {json_error}\")\n",
    "        raise RuntimeError(f\"Internal server error while creating/updating search index: {error_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating embeddings client placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    logging.info(\"Successfully created OpenAI embeddings client\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error creating OpenAI embeddings client: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up vector store placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    vector_store = CouchbaseVectorStore(\n",
    "        cluster=cluster,\n",
    "        bucket_name=CB_BUCKET_NAME,\n",
    "        scope_name=SCOPE_NAME,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        embedding=embeddings,\n",
    "        index_name=INDEX_NAME,\n",
    "    )\n",
    "    logging.info(\"Successfully created vector store\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to create vector store: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading BBC News dataset placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    news_dataset = load_dataset(\n",
    "        \"RealTimeData/bbc_news_alltime\", \"2024-12\", split=\"train\"\n",
    "    )\n",
    "    print(f\"Loaded the BBC News dataset with {len(news_dataset)} rows\")\n",
    "    logging.info(f\"Successfully loaded the BBC News dataset with {len(news_dataset)} rows.\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading the BBC News dataset: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning data placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_articles = news_dataset[\"content\"]\n",
    "unique_articles = set()\n",
    "for article in news_articles:\n",
    "    if article:\n",
    "        unique_articles.add(article)\n",
    "unique_news_articles = list(unique_articles)\n",
    "print(f\"We have {len(unique_news_articles)} unique articles in our database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving data to vector store placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in tqdm(unique_news_articles, desc=\"Ingesting articles\"):\n",
    "    try:\n",
    "        # Skip articles that exceed the model's token limit (50,000 characters)\n",
    "        if len(article) > 50000:\n",
    "            print(f\"Skipping article with length {len(article)} - exceeds 50,000 character limit\")\n",
    "            continue\n",
    "            \n",
    "        # Convert article into the format needed for add_texts\n",
    "        texts = [article]  # Single article as text\n",
    "        metadatas = [{}]  # Empty metadata dictionary for each article\n",
    "        uuids = [str(uuid4())]  # Generate UUID for the article\n",
    "        \n",
    "        # Use add_texts instead of add_documents\n",
    "        vector_store.add_texts(\n",
    "            texts=texts,\n",
    "            metadatas=metadatas,\n",
    "            ids=uuids\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save documents to vector store: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up cache placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cache = CouchbaseCache(\n",
    "        cluster=cluster,\n",
    "        bucket_name=CB_BUCKET_NAME,\n",
    "        scope_name=SCOPE_NAME,\n",
    "        collection_name=CACHE_COLLECTION,\n",
    "    )\n",
    "    logging.info(\"Successfully created cache\")\n",
    "    set_llm_cache(cache)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to create cache: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Deepseek LLM placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    llm = ChatDeepseek(\n",
    "        api_key=DEEPSEEK_API_KEY,\n",
    "        model_name=\"deepseek-chat\",\n",
    "        temperature=0\n",
    "    )\n",
    "    logging.info(\"Successfully created Deepseek LLM client\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error creating Deepseek LLM client: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing semantic search placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What were Luke Littler's key achievements and records in his recent PDC World Championship match?\"\n",
    "\n",
    "try:\n",
    "    # Perform the semantic search\n",
    "    start_time = time.time()\n",
    "    search_results = vector_store.similarity_search_with_score(query, k=10)\n",
    "    search_elapsed_time = time.time() - start_time\n",
    "\n",
    "    logging.info(f\"Semantic search completed in {search_elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Display search results\n",
    "    print(f\"\\nSemantic Search Results (completed in {search_elapsed_time:.2f} seconds):\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for doc, score in search_results:\n",
    "        print(f\"Score: {score:.4f}, Text: {doc.page_content}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "except CouchbaseException as e:\n",
    "    raise RuntimeError(f\"Error performing semantic search: {str(e)}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up RAG chain placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RAG prompt template\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that answers questions based on the provided context.\"),\n",
    "    (\"human\", \"Context: {context}\\n\\nQuestion: {question}\")\n",
    "])\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": vector_store.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "logging.info(\"Successfully created RAG chain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing RAG chain placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "rag_response = rag_chain.invoke(query)\n",
    "rag_elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"RAG Response: {rag_response}\")\n",
    "print(f\"RAG response generated in {rag_elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing caching placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    queries = [\n",
    "        \"What happened in the match between Fullham and Liverpool?\",\n",
    "        \"What were Luke Littler's key achievements and records in his recent PDC World Championship match?\",\n",
    "        \"What happened in the match between Fullham and Liverpool?\", # Repeated query\n",
    "    ]\n",
    "\n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(f\"\\nQuery {i}: {query}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        response = rag_chain.invoke(query)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Response: {response}\")\n",
    "        print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error generating RAG response: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
