{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d4222b",
   "metadata": {},
   "source": [
    "# Game of Thrones Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Downloading and extracting a dataset.\n",
    "2. Loading documents from the dataset.\n",
    "3. Splitting those documents into chunks.\n",
    "4. Embedding the chunks and storing them in Couchbase as a vector store.\n",
    "5. Performing retrieval-augmented generation (RAG) using the `dspy` library to answer a test query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f3c25",
   "metadata": {},
   "source": [
    "## Install Required Packages\n",
    "Make sure you have the following libraries installed. If anything is missing, install via `pip install <package>`.\n",
    "\n",
    "**Required Packages**:\n",
    "- langchain\n",
    "- langchain_community (for DirectoryLoader)\n",
    "- langchain_openai (for OpenAIEmbeddings)\n",
    "- couchbase (for Couchbase connections)\n",
    "- requests\n",
    "- dspy\n",
    "- openai\n",
    "\n",
    "*(Versions may matter depending on your environment. This code assumes you have compatible versions of these packages.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0c64c5",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain_community\n",
      "  Using cached langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain_openai\n",
      "  Using cached langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain_couchbase\n",
      "  Downloading langchain_couchbase-0.2.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: requests in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (2.32.3)\n",
      "Collecting dspy\n",
      "  Downloading dspy-2.6.2-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.61.1-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.37-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.12-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.33 (from langchain)\n",
      "  Using cached langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.6-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain)\n",
      "  Downloading numpy-2.2.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting couchbase<5.0.0,>=4.3.2 (from langchain_couchbase)\n",
      "  Downloading couchbase-4.3.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from dspy) (4.8.0)\n",
      "Collecting asyncer==0.0.8 (from dspy)\n",
      "  Using cached asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting backoff (from dspy)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting cachetools (from dspy)\n",
      "  Using cached cachetools-5.5.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting cloudpickle (from dspy)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting datasets (from dspy)\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting diskcache (from dspy)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: httpx in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from dspy) (0.28.1)\n",
      "Requirement already satisfied: jinja2 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from dspy) (3.1.5)\n",
      "Collecting joblib~=1.3 (from dspy)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting json-repair (from dspy)\n",
      "  Using cached json_repair-0.35.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting litellm==1.57.4 (from litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached litellm-1.57.4-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting magicattr~=0.1.6 (from dspy)\n",
      "  Using cached magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting optuna (from dspy)\n",
      "  Using cached optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pandas (from dspy)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting regex (from dspy)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tqdm (from dspy)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting ujson (from dspy)\n",
      "  Downloading ujson-5.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.3 kB)\n",
      "Collecting click (from litellm==1.57.4->litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx (from dspy)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm==1.57.4->litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from litellm==1.57.4->litellm[proxy]==1.57.4->dspy) (4.23.0)\n",
      "Collecting python-dotenv>=0.2.0 (from litellm==1.57.4->litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting tokenizers (from litellm==1.57.4->litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting PyJWT<3.0.0,>=2.8.0 (from litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting apscheduler<4.0.0,>=3.10.4 (from litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached APScheduler-3.11.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting cryptography<44.0.0,>=43.0.1 (from litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached cryptography-43.0.3-cp39-abi3-macosx_10_9_universal2.whl.metadata (5.4 kB)\n",
      "Collecting fastapi<0.116.0,>=0.115.5 (from litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting fastapi-sso<0.17.0,>=0.16.0 (from litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached fastapi_sso-0.16.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting gunicorn<23.0.0,>=22.0.0 (from litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached gunicorn-22.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.7 (from litellm[proxy]==1.57.4->dspy)\n",
      "  Downloading orjson-3.10.15-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pynacl<2.0.0,>=1.5.0 (from litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached PyNaCl-1.5.0-cp36-abi3-macosx_10_10_universal2.whl.metadata (8.7 kB)\n",
      "Collecting python-multipart<0.0.19,>=0.0.18 (from litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached python_multipart-0.0.18-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting rq (from litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached rq-2.1.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting uvicorn<0.23.0,>=0.22.0 (from litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached uvicorn-0.22.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached propcache-0.2.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from httpx->dspy) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from httpcore==1.*->httpx->dspy) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from jinja2->dspy) (3.0.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.33->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (24.2)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from datasets->dspy)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->dspy)\n",
      "  Downloading pyarrow-19.0.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->dspy)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->dspy)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->dspy)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->dspy)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets->dspy)\n",
      "  Using cached huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna->dspy)\n",
      "  Using cached alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna->dspy)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from pandas->dspy) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->dspy)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->dspy)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna->dspy)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting tzlocal>=3.0 (from apscheduler<4.0.0,>=3.10.4->litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from cryptography<44.0.0,>=43.0.1->litellm[proxy]==1.57.4->dspy) (1.17.1)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi<0.116.0,>=0.115.5->litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting oauthlib>=3.1.0 (from fastapi-sso<0.17.0,>=0.16.0->litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm==1.57.4->litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.57.4->litellm[proxy]==1.57.4->dspy) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.57.4->litellm[proxy]==1.57.4->dspy) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.57.4->litellm[proxy]==1.57.4->dspy) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->dspy) (1.17.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting redis>=3.5 (from rq->litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: pycparser in /Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages (from cffi>=1.12->cryptography<44.0.0,>=43.0.1->litellm[proxy]==1.57.4->dspy) (2.22)\n",
      "Collecting email-validator>=2.0.0 (from pydantic[email]>=1.8.0->fastapi-sso<0.17.0,>=0.16.0->litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=1.8.0->fastapi-sso<0.17.0,>=0.16.0->litellm[proxy]==1.57.4->dspy)\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Using cached langchain-0.3.17-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n",
      "Using cached langchain_openai-0.3.3-py3-none-any.whl (54 kB)\n",
      "Downloading langchain_couchbase-0.2.4-py3-none-any.whl (15 kB)\n",
      "Downloading dspy-2.6.2-py3-none-any.whl (253 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
      "Using cached litellm-1.57.4-py3-none-any.whl (6.6 MB)\n",
      "Downloading openai-1.61.1-py3-none-any.whl (463 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.12-cp312-cp312-macosx_11_0_arm64.whl (456 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.2/456.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading couchbase-4.3.5-cp312-cp312-macosx_11_0_arm64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading jiter-0.8.2-cp312-cp312-macosx_11_0_arm64.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.3/310.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached langchain_core-0.3.33-py3-none-any.whl (412 kB)\n",
      "Using cached langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.3.6-py3-none-any.whl (332 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
      "Downloading numpy-2.2.2-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading SQLAlchemy-2.0.37-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-macosx_11_0_arm64.whl (982 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m982.6/982.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
      "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached json_repair-0.35.0-py3-none-any.whl (19 kB)\n",
      "Using cached optuna-4.2.0-py3-none-any.whl (383 kB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
      "Downloading ujson-5.10.0-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached APScheduler-3.11.0-py3-none-any.whl (64 kB)\n",
      "Using cached cryptography-43.0.3-cp39-abi3-macosx_10_9_universal2.whl (6.2 MB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
      "Using cached fastapi_sso-0.16.0-py3-none-any.whl (23 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached gunicorn-22.0.0-py3-none-any.whl (84 kB)\n",
      "Using cached huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading orjson-3.10.15-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.5/249.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached propcache-0.2.1-cp312-cp312-macosx_11_0_arm64.whl (45 kB)\n",
      "Downloading pyarrow-19.0.0-cp312-cp312-macosx_12_0_arm64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Using cached PyNaCl-1.5.0-cp36-abi3-macosx_10_10_universal2.whl (349 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached python_multipart-0.0.18-py3-none-any.whl (24 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-macosx_11_0_arm64.whl (92 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-macosx_11_0_arm64.whl (633 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m633.5/633.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached rq-2.1.0-py3-none-any.whl (96 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached redis-5.2.1-py3-none-any.whl (261 kB)\n",
      "Using cached starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Using cached tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: pytz, magicattr, zstandard, zipp, xxhash, ujson, tzlocal, tzdata, tqdm, tenacity, SQLAlchemy, regex, redis, python-multipart, python-dotenv, PyJWT, pydantic-core, pyarrow, propcache, orjson, oauthlib, numpy, mypy-extensions, multidict, marshmallow, Mako, jsonpatch, json-repair, joblib, jiter, httpx-sse, gunicorn, fsspec, frozenlist, filelock, dnspython, distro, diskcache, dill, couchbase, colorlog, cloudpickle, click, cachetools, backoff, annotated-types, aiohappyeyeballs, yarl, uvicorn, typing-inspect, tiktoken, starlette, rq, requests-toolbelt, pynacl, pydantic, pandas, multiprocess, importlib-metadata, huggingface-hub, httpx, email-validator, cryptography, asyncer, apscheduler, alembic, aiosignal, tokenizers, pydantic-settings, optuna, openai, langsmith, fastapi, dataclasses-json, aiohttp, litellm, langchain-core, fastapi-sso, langchain-text-splitters, langchain_openai, langchain_couchbase, datasets, langchain, dspy, langchain_community\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.28.1\n",
      "    Uninstalling httpx-0.28.1:\n",
      "      Successfully uninstalled httpx-0.28.1\n",
      "Successfully installed Mako-1.3.9 PyJWT-2.10.1 SQLAlchemy-2.0.37 aiohappyeyeballs-2.4.4 aiohttp-3.11.12 aiosignal-1.3.2 alembic-1.14.1 annotated-types-0.7.0 apscheduler-3.11.0 asyncer-0.0.8 backoff-2.2.1 cachetools-5.5.1 click-8.1.8 cloudpickle-3.1.1 colorlog-6.9.0 couchbase-4.3.5 cryptography-43.0.3 dataclasses-json-0.6.7 datasets-3.2.0 dill-0.3.8 diskcache-5.6.3 distro-1.9.0 dnspython-2.7.0 dspy-2.6.2 email-validator-2.2.0 fastapi-0.115.8 fastapi-sso-0.16.0 filelock-3.17.0 frozenlist-1.5.0 fsspec-2024.9.0 gunicorn-22.0.0 httpx-0.27.2 httpx-sse-0.4.0 huggingface-hub-0.28.1 importlib-metadata-8.6.1 jiter-0.8.2 joblib-1.4.2 json-repair-0.35.0 jsonpatch-1.33 langchain-0.3.17 langchain-core-0.3.33 langchain-text-splitters-0.3.5 langchain_community-0.3.16 langchain_couchbase-0.2.4 langchain_openai-0.3.3 langsmith-0.3.6 litellm-1.57.4 magicattr-0.1.6 marshmallow-3.26.1 multidict-6.1.0 multiprocess-0.70.16 mypy-extensions-1.0.0 numpy-2.2.2 oauthlib-3.2.2 openai-1.61.1 optuna-4.2.0 orjson-3.10.15 pandas-2.2.3 propcache-0.2.1 pyarrow-19.0.0 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.7.1 pynacl-1.5.0 python-dotenv-1.0.1 python-multipart-0.0.18 pytz-2025.1 redis-5.2.1 regex-2024.11.6 requests-toolbelt-1.0.0 rq-2.1.0 starlette-0.45.3 tenacity-9.0.0 tiktoken-0.8.0 tokenizers-0.21.0 tqdm-4.67.1 typing-inspect-0.9.0 tzdata-2025.1 tzlocal-5.2 ujson-5.10.0 uvicorn-0.22.0 xxhash-3.5.0 yarl-1.18.3 zipp-3.21.0 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_community langchain_openai langchain_couchbase requests dspy openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e21b2f7",
   "metadata": {},
   "source": [
    "## 1. Imports and Logging Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265300af",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_couchbase import CouchbaseVectorStore\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.options import ClusterOptions, KnownConfigProfiles\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from langchain.docstore.document import Document  # Needed for creating LangChain documents\n",
    "import re\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a92fe",
   "metadata": {},
   "source": [
    "## 2. Utility Functions\n",
    "- **fetch_archive_from_http()**: Fetches and extracts a ZIP archive.\n",
    "- **clean_text()**: Cleans up unwanted whitespace, non-ASCII, and special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cecaeb7",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [],
   "source": [
    "def fetch_archive_from_http(url: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Utility function to fetch a zip archive from a URL and extract it to a local directory.\n",
    "    \"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    if output_path.is_dir():\n",
    "        logger.warning(f\"'{output_dir}' directory already exists. Skipping data download.\")\n",
    "        return\n",
    "\n",
    "    with requests.get(url, timeout=10, stream=True) as response:\n",
    "        response.raise_for_status()\n",
    "        with zipfile.ZipFile(BytesIO(response.content)) as zip_ref:\n",
    "            zip_ref.extractall(output_dir)\n",
    "    \n",
    "    logger.info(f\"Data extracted to: {output_dir}\")\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans a document's text:\n",
    "    - Removes extra spaces\n",
    "    - Replaces multiple newlines with a single one\n",
    "    - Removes non-ASCII characters\n",
    "    - Removes special characters (except basic punctuation)\n",
    "    \"\"\"\n",
    "    text = text.strip()  # Remove leading/trailing spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Normalize whitespace\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)  # Remove non-ASCII characters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9,.!?;:\\-\\s]\", \"\", text)  # Remove special characters except punctuation\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceefb06f",
   "metadata": {},
   "source": [
    "## 3. Main Workflow\n",
    "Below is the core workflow:\n",
    "1. Download and extract the dataset.\n",
    "2. Load the documents from the `data/docs` directory.\n",
    "3. Create an OpenAI Embeddings model.\n",
    "4. Set up Couchbase connection and vector store.\n",
    "5. Chunk the documents.\n",
    "6. Store the chunked documents in the Couchbase Vector Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3575891",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# 1. Download and Extract the Dataset\n",
    "# --------------------------------------------------\n",
    "docs_dir = \"data/docs\"\n",
    "fetch_archive_from_http(\n",
    "    url=\"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt6.zip\",\n",
    "    output_dir=docs_dir,\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Load Documents\n",
    "# --------------------------------------------------\n",
    "loader = DirectoryLoader(docs_dir, recursive=True)\n",
    "documents = loader.load()\n",
    "logger.info(f\"Loaded {len(documents)} documents from {docs_dir}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Initialize OpenAI Embeddings Model\n",
    "# --------------------------------------------------\n",
    "\n",
    "api_key = input(\"Enter OpenAI API Key: \")\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    api_key= api_key\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Connect to Couchbase\n",
    "# --------------------------------------------------\n",
    "cluster_options = ClusterOptions(\n",
    "    authenticator=PasswordAuthenticator('admin', 'Password'),\n",
    ")\n",
    "cluster_options.apply_profile(KnownConfigProfiles.WanDevelopment)\n",
    "\n",
    "store = CouchbaseVectorStore(\n",
    "    cluster=Cluster(\n",
    "        'couchbase://localhost',\n",
    "        cluster_options\n",
    "    ),\n",
    "    bucket_name=\"dspy_test\",\n",
    "    scope_name=\"got\",\n",
    "    collection_name=\"got_collection\",\n",
    "    embedding=embeddings_model,\n",
    "    index_name=\"vector_search\"\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Split Documents into Chunks\n",
    "# --------------------------------------------------\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,  # Max characters per chunk\n",
    "    chunk_overlap=90  # Overlap for context retention\n",
    ")\n",
    "\n",
    "chunked_documents = []\n",
    "for doc in documents:\n",
    "    chunks = splitter.split_text(clean_text(doc.page_content))  # Split text into chunks\n",
    "    for chunk in chunks:\n",
    "        chunked_documents.append(Document(page_content=chunk, metadata=doc.metadata))  # Create LangChain Documents\n",
    "\n",
    "logger.info(f\"Generated {len(chunked_documents)} chunks for storage.\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. Store Documents in Couchbase Vector Store\n",
    "# --------------------------------------------------\n",
    "# batch_size = 50  # Adjust based on your model's limits\n",
    "# for i in range(0, len(chunked_documents), batch_size):\n",
    "#     batch = chunked_documents[i:i + batch_size]\n",
    "#     store.add_documents(batch)\n",
    "#     logger.info(f\"Stored batch {i // batch_size + 1}\")\n",
    "# logger.info(\"Documents successfully added to Couchbase Vector Store.\")\n",
    "\n",
    "store.add_documents(chunked_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782c8dd",
   "metadata": {},
   "source": [
    "## 4. Retrieval and RAG with `dspy`\n",
    "\n",
    "Below, we illustrate how to retrieve documents from Couchbase using `dspy`'s `CouchbaseRM` retriever. Then we do a retrieval-augmented generation using a simple [RAG](https://arxiv.org/abs/2005.11401) pattern:\n",
    "\n",
    "1. We query the index to retrieve relevant chunks (passages).\n",
    "2. We feed these passages, plus our question, into a GPT model (or your LLM of choice) to generate a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f218ec6b",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/svenkat/Library/Application Support/hatch/env/virtual/dspy/BCP-gpLW/dspy/lib/python3.12/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dspy.retrieve.couchbase_rm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdspy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdspy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrieve\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcouchbase_rm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CouchbaseRM\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcouchbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PasswordAuthenticator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcouchbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KnownConfigProfiles, ClusterOptions\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dspy.retrieve.couchbase_rm'"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.retrieve.couchbase_rm import CouchbaseRM\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.options import KnownConfigProfiles, ClusterOptions\n",
    "\n",
    "\n",
    "# Setup Couchbase retriever\n",
    "cluster_options = ClusterOptions(\n",
    "    authenticator=PasswordAuthenticator('admin', 'Password'),\n",
    ")\n",
    "cluster_options.apply_profile(KnownConfigProfiles.WanDevelopment)\n",
    "\n",
    "movie_datasets = CouchbaseRM(\n",
    "    index_name=\"vector_search\",\n",
    "    cluster_connection_string=\"couchbase://localhost\",\n",
    "    cluster_options=cluster_options,\n",
    "    bucket=\"haystack_integration_test\",\n",
    "    scope=\"haystack_test_scope\",\n",
    "    collection=\"haystack_collection\",\n",
    "    use_kv_get_text=True,\n",
    "    embedding_model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "dspy.settings.configure(rm=movie_datasets)\n",
    "turbo = dspy.LM(model='openai/gpt-4o', api_key=api_key)\n",
    "dspy.settings.configure(lm=turbo, trace=[], temperature=0.7)\n",
    "\n",
    "search = dspy.retrieve.Retrieve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c001e189",
   "metadata": {},
   "source": [
    "### 4.1 Define a Signature for the Generated Answer\n",
    "We'll define a simple signature for the question, context, and the answer fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497bb75b",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"answer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934c0e17",
   "metadata": {},
   "source": [
    "### 4.2 Define a Retrieval-Augmented Generation (RAG) Module\n",
    "This pipeline fetches the top-\\(k\\) passages and then calls an LLM to produce the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605d47d",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    \"\"\"Retrieval-augmented generation (RAG) pipeline.\"\"\"\n",
    "    def __init__(self, num_passages=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efdae91",
   "metadata": {},
   "source": [
    "### 4.3 Run a Query and Inspect the Result\n",
    "We create an instance of our RAG pipeline, run a custom question, and then see the LLM’s final answer plus retrieved context passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb61b67",
   "metadata": {
    "executionInfo": {}
   },
   "outputs": [],
   "source": [
    "rag = RAG()\n",
    "\n",
    "# Example query\n",
    "my_question = \"Why did Jorah Mormont flee to Essos, and how did his actions shape his relationship with Daenerys Targaryen?\"\n",
    "\n",
    "pred = rag(question=my_question)\n",
    "\n",
    "# Print results\n",
    "print(f\"Question: {my_question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")\n",
    "\n",
    "turbo.inspect_history(n=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default hatch dspy)",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
