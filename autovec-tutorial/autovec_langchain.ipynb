{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44480f12-3bd0-4fe9-9493-25bd6a2712bb",
   "metadata": {},
   "source": [
    "# Couchbase Capella AI Services Auto-Vectorization Tutorial\n",
    "\n",
    "This comprehensive tutorial demonstrates how to use Couchbase Capella's new AI Services auto-vectorization feature to automatically convert your data into vector embeddings and perform semantic search using LangChain.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Table of Contents\n",
    "\n",
    "1. [Capella Account Setup](#1-create-and-deploy-your-free-tier-operational-cluster-on-capella)\n",
    "2. [Data Upload and Preparation](#2-data-upload-and-preparation)\n",
    "3. [Deploying the Model](#3-deploying-the-model)\n",
    "4. [Auto-Vectorization Process](#4-deploying-autovectorization-workflow)\n",
    "5. [LangChain Vector Search](#5-vector-search)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502eb13e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "# 1. Create and Deploy Your Free Tier Operational cluster on Capella,\n",
    " To get started with Couchbase Capella, create an account and use it to deploy a cluster. To know more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).\n",
    " ### Couchbase Capella Configuration,\n",
    " When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met.\n",
    "   * Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the travel-sample bucket (Read and Write) used in the application.\n",
    "   * [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4369c925-adbc-4c7d-9ea6-04ff020cb1a6",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Data Upload and Preparation\n",
    "\n",
    "There are various techniques which exists to insert the data in the cluster, to read about the techniques please follow the [sample-data import](https://docs.couchbase.com/cloud/clusters/data-service/import-data-documents.html#import-sample-data) guide.\n",
    "\n",
    "After data upload is comlete, follow the next steps to achieve vectorization for your required fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3afd3f-9949-4f5e-b96a-1aac1a3aea29",
   "metadata": {},
   "source": [
    "# 3. Deploying the Model\n",
    "Now, before we actually create embedding for the documents we need to deploy a model which will create the embedding for us.\n",
    "## 3.1: Selecting the model \n",
    "1. To select the model, you first need to navigate to the \"<B>AI Services</B>\" tab, then selecting \"<B>Models</B>\" and clicking on \"<B>Deploy New Model</B>\"\n",
    "   \n",
    "   <img src=\"./img/importing_model.png\" width=\"950px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "3. Enter the <B>model name</B>, and choose the model that you want to deploy. After Selecting your model, choose the <B>model infrastructure</B> and <B>region</B> where the model will be deployed.\n",
    "   \n",
    "   <img src=\"./img/deploying_model.png\" width=\"800px\" height=\"800px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "## 3.2 Access control to the model\n",
    "\n",
    "1. After deploying the model, go to the \"<B>Models</B>\" tab in the <B>AI-services</B> and click on \"<B>setup access</B>\".\n",
    "\n",
    "    <img src=\"./img/model_setup_access.png\" width=\"1100px\" height=\"400px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "3. Enter your <B>api_key_name</B>, <B>expiration time</B> and the <B>IP-address</B> from which you will be accessing the model.\n",
    "\n",
    "    <img src=\"./img/model_api_key_form.png\" width=\"1100px\" height=\"600px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "4. Download your API key\n",
    "\n",
    "   <img src=\"./img/download_api_key_details.png\" width=\"1200px\" height=\"800px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf6525-d4e6-45fb-8839-fc7c20081675",
   "metadata": {},
   "source": [
    "# 4. Deploying AutoVectorization Workflow\n",
    "\n",
    "Now, we are in the step which will help us create the embeddings/vectors. To proceed with the process of craetion of vectorization please follow the steps below:\n",
    "\n",
    "1. For deploying the autovectorization, you need to go to the <B>ai-services</B> tab, then click on the <B>workflows</B>, and then click on <B>Get started with RAG</B>.\n",
    "\n",
    "   <img src=\"./img/Create_auto_vec.png\" width=\"1000px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "   \n",
    "2. Start your workflow deployment by giving it a name, and selecting from where your data will be provided to the auto-vectorization service. There are currently 3 options, <B>pre-processed data(JSON format) from capella</B>, <B>pre-processed data(JSON format) from external sources(S3 buckets)</B> and <B>unstructured data from external sources (S3 buckets)</B>. For this tutorial we will be choosing first option which is pre-processed data from capella.\n",
    "\n",
    "   <img src=\"./img/start_workflow.png\" width=\"1000px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "3. Now, select the <B>cluster</B>, <B>bucket</B>, <B>scope</B> and <B>collection</B> from which you want to select the documents and get the data vectorized.\n",
    "\n",
    "   <img src=\"./img/vector_data_source.png\" width=\"1000px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "4. <B>Field Mapping</B> will be used to tell the AutoVectorize service that which data will be converted to embeddings.\n",
    "\n",
    "   There are two options:-\n",
    "\n",
    "   - <B>All source fields</B> - This feature will convert all your fields inside the document to a single vector field.\n",
    "   \n",
    "     <img src=\"./img/vector_all_field_mapping.png\" width=\"900px\" height=\"400px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "\n",
    "   - <B>Custom source fields</B> - This feature will convert specific fields which are chosen by the user to a single vector field, in the image below we have chosen <B>address</B>, <B>description</B> and <B>id</B> as the fields to be converted to a vector having the name as <B>vec_addr_decr_id_mapping</B>.\n",
    "  \n",
    "       <img src=\"./img/vector_custom_field_mapping.png\" width=\"900px\" height=\"400px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "  \n",
    "5. After choosing your type of mapping, you will be required to either have an index on the new vector_embedding field or you can skip the creation of vector index which is not recommended as you will be losing out the functionality of vector searching.\n",
    "\n",
    "   <img src=\"./img/vector_index.png\" width=\"1200px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "6. All the steps mentioned above.\n",
    "\n",
    "   <img src=\"./img/vector_index_page.png\" width=\"1200px\" height=\"1200px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "   \n",
    "- After this step your vector-embedding for the selected fields must be ready and you can check it out in the capella UI. Now, in the next step we will demonsterate how we can use the generated vectors to do the vector search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50204a4",
   "metadata": {},
   "source": [
    "# 5. Vector Search\n",
    "\n",
    "The following code cells implement semantic vector search against the embeddings generated by the AutoVectorization workflow. \n",
    "   \n",
    "Proceed to execute the cells in order to run the vector similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30955126-0053-4cec-9dec-e4c05a8de7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from couchbase.cluster import Cluster\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.options import ClusterOptions\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings      \n",
    "from langchain_couchbase.vectorstores import CouchbaseSearchVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be1f01",
   "metadata": {},
   "source": [
    "# Cluster Connection Setup\n",
    "   - Defines the secure connection string, user credentials, and creates a `Cluster` object.\n",
    "   - Disables TLS verification by `options = ClusterOptions(auth, tls_verify='none')` ONLY for quick local testing (not recommended in production) and applies the `wan_development` profile to tune timeouts for higher-latency networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"couchbases://cb.xyz.com\" # Replace this with Connection String\n",
    "username = \"YOUR_USERNAME\"  # Replace this with your username\n",
    "password = \"YOUR_PASSWORD\"  # Replace this with your password\n",
    "auth = PasswordAuthenticator(username, password)\n",
    "# Configure cluster options with SSL verification disabled for testing, in production you should enable it\n",
    "options = ClusterOptions(auth, tls_verify='none')\n",
    "options.apply_profile(\"wan_development\")\n",
    "cluster = Cluster(endpoint, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb8a4f",
   "metadata": {},
   "source": [
    "# Selection of Buckets / Scope / Collection / Index / Embedder\n",
    "   - Sets the bucket, scope, and collection where the documents (with vector fields) live.\n",
    "   - Specifies the Capella Search index name created (or selected) in Step 4.5.\n",
    "   - Instantiates the NVIDIA embedding model that will transform the user's natural language query into a vector at search time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b2efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"travel-sample\"\n",
    "scope_name = \"inventory\"\n",
    "collection_name = \"hotel\"\n",
    "index_name = \"hybrid_autovec_workflow_vec_addr_descr_id\"  # This is the name of the search index which was created in the step 4.5 and can also be seen in the search tab of the cluster.\n",
    "                                                          # It shall be noted that hybrid_workflow_name_index_fieldname is the naming convention for the index created by AutoVectorization workflow where\n",
    "                                                          # fieldname is the name of the field being indexed.\n",
    "embedder = NVIDIAEmbeddings(\n",
    "    model=\"nvidia/nv-embedqa-e5-v5\",                      # This is the model which will be used to create the embedding of the query.\n",
    "    api_key=\"nvapi-xyz\"                                   # This is the api key using which your model will be accessed.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda36710",
   "metadata": {},
   "source": [
    "# VectorStore Construction\n",
    "   - Creates a `CouchbaseSearchVectorStore` instance that:\n",
    "     * Knows where to read documents (`bucket/scope/collection`).\n",
    "     * Knows the embedding field (the vector produced by the AutoVectorization workflow).\n",
    "     * Uses the provided embedder to embed queries on-demand.\n",
    "   - If your AutoVectorization workflow produced a different vector field name, update `embedding_key` accordingly.\n",
    "   - If you mapped multiple fields into a single vector, you can choose any representative field for `text_key`, or modify the VectorStore wrapper to concatenate fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b85f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = CouchbaseSearchVectorStore(\n",
    "    cluster=cluster,\n",
    "    bucket_name=bucket_name,\n",
    "    scope_name=scope_name,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedder,\n",
    "    index_name=index_name,\n",
    "    text_key=\"address\",                  # your document's text field\n",
    "    embedding_key=\"vec_addr_descr_id\"    # this is the field in which your vector(embedding) is stored in the cluster.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be207963",
   "metadata": {},
   "source": [
    "# Performing a Similarity Search\n",
    "   - Defines a natural language query (e.g., \"USA\").\n",
    "   - Calls `similarity_search(k=3)` to retrieve the top 3 most semantically similar documents.\n",
    "   - Prints ranked results, extracting a `title` (if present) and the chosen `text_key` (here `address`).\n",
    "   - Change `query` to any descriptive phrase (e.g., \"beach resort\", \"airport hotel near NYC\").\n",
    "   - Adjust `k` for more or fewer results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "177fd6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Glossop â€” Address: Woodhead Road\n",
      "2. Glossop â€” Address: 28 Woodhead Road\n",
      "3. Hadrian's Wall â€” Address: Greenhead, Brampton, Cumbria, CA8 7HB\n"
     ]
    }
   ],
   "source": [
    "query = \"Woodhead Road\"\n",
    "results = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "# Printing out the top-k results\n",
    "for rank, doc in enumerate(results, start=1):\n",
    "    title = doc.metadata.get(\"title\", \"<no title>\")\n",
    "    address_text = doc.page_content\n",
    "    print(f\"{rank}. {title} â€” Address: {address_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0d863",
   "metadata": {},
   "source": [
    "## 6. Results and Interpretation\n",
    "\n",
    "As we can see 3 (or `k`) ranked results printed in the output.\n",
    "\n",
    "### What Each Part Means\n",
    "- Leading number (1,2,3): The result rank (1 = most similar to your query).\n",
    "- Title: Pulled from `doc.metadata.get(\"title\", \"<no title>\")`. If your documents don't contain a `title` field, you will see `<no title>`.\n",
    "- Address text: This is the value of the field you configured as `text_key` (in this tutorial: `address`). It represents the human-readable content we chose to display.\n",
    "\n",
    "### How The Ranking Works\n",
    "1. Your natural language query (e.g., `\"Woodhead Road\"`) is embedded using the NVIDIA model (`nvidia/nv-embedqa-e5-v5`).\n",
    "2. The vector store compares the query embedding to stored document embeddings in the field you configured (`embedding_key = \"vec_addr_descr_id\"`).\n",
    "3. Results are sorted by vector similarity. Higher similarity = nearer semantic meaning.\n",
    "\n",
    "\n",
    "> Your vector search pipeline is working if the returned documents feel meaningfully related to your natural language queryâ€”even when exact keywords do not match. Feel free to experiment with increasingly descriptive queries to observe the semantic power of the embeddings.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autovec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
