{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Persistence with Couchbase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures, differentiating it from DAG-based solutions. This tutorial focuses on showcasing persisting state of [LangGraph](https://github.com/langchain-ai/langgraph) with Couchbase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create a custom checkpointer using Couchbase\n",
    "\n",
    "When creating LangGraph agents, you can also set them up so that they persist their state. This allows you to do things like interact with an agent multiple times and have it remember previous interactions. \n",
    "\n",
    "This reference implementation shows how to use [Couchbase](https://couchbase.com) as the backend for persisting checkpoint state. Make sure that you have Couchbase running on port `8091` for going through this guide, or you may use [Couchbase Capella](https://cloud.couchbase.com) by changing connection string.\n",
    "\n",
    "NOTE: this is just a reference implementation. You can implement your own checkpointer using a different database or modify this one as long as it conforms to the `BaseCheckpointSaver` interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires Couchbase Python SDK and langgraph package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U couchbase langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular example uses OpenAI's GPT4o-mini as the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointer implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CouchbaseSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an implementation of CouchbaseSaver (for synchronous use of graph, i.e. `.invoke()`, `.stream()`). CouchbaseSaver implements four methods that are required for any checkpointer:\n",
    "\n",
    "- `.put` - Store a checkpoint with its configuration and metadata.\n",
    "- `.put_writes` - Store intermediate writes linked to a checkpoint (i.e. pending writes).\n",
    "- `.get_tuple` - Fetch a checkpoint tuple using for a given configuration (`thread_id` and `checkpoint_id`).\n",
    "- `.list` - List checkpoints that match a given configuration and filter criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from datetime import timedelta\n",
    "from typing import Any, Dict, Iterator, Optional, Sequence, Tuple\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.bucket import Bucket\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.options import ClusterOptions, QueryOptions, UpsertOptions\n",
    "\n",
    "from langgraph.checkpoint.base import (\n",
    "    BaseCheckpointSaver,\n",
    "    ChannelVersions,\n",
    "    Checkpoint,\n",
    "    CheckpointMetadata,\n",
    "    CheckpointTuple,\n",
    "    get_checkpoint_id,\n",
    ")\n",
    "\n",
    "\n",
    "class CouchbaseSaver(BaseCheckpointSaver):\n",
    "    \"\"\"A checkpoint saver that stores checkpoints in a Couchbase database.\"\"\"\n",
    "\n",
    "    cluster: Cluster\n",
    "    bucket: Bucket\n",
    "    def __init__(\n",
    "        self,\n",
    "        cluster: Cluster,\n",
    "        bucket_name: str,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.cluster = cluster\n",
    "        self.bucket = self.cluster.bucket(bucket_name)\n",
    "\n",
    "    @classmethod\n",
    "    @contextmanager\n",
    "    def from_conn_info(\n",
    "        cls, *, cb_conn_str :str, cb_username: str, cb_password: str, bucket_name: str, scope_name: str\n",
    "    ) -> Iterator[\"CouchbaseSaver\"]:\n",
    "        cluster = None\n",
    "        try:\n",
    "            # Connect to Couchbase Cluster\n",
    "            auth = PasswordAuthenticator(cb_username, cb_password)\n",
    "            options = ClusterOptions(auth)\n",
    "            cluster = Cluster(cb_conn_str, options)\n",
    "            cluster.wait_until_ready(timedelta(seconds=5))\n",
    "            \n",
    "            cls.cluster = cluster\n",
    "            cls.bucket_name = bucket_name\n",
    "            cls.scope_name = scope_name\n",
    "            \n",
    "            yield CouchbaseSaver(cluster, bucket_name)\n",
    "        finally:\n",
    "            if cluster:\n",
    "                cluster.close()\n",
    "\n",
    "    def get_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        \"\"\"Get a checkpoint tuple from the database.\n",
    "\n",
    "        This method retrieves a checkpoint tuple from the Couchbase database based on the\n",
    "        provided config. If the config contains a \"checkpoint_id\" key, the checkpoint with\n",
    "        the matching thread ID and checkpoint ID is retrieved. Otherwise, the latest checkpoint\n",
    "        for the given thread ID is retrieved.\n",
    "\n",
    "        Args:\n",
    "            config (RunnableConfig): The config to use for retrieving the checkpoint.\n",
    "\n",
    "        Returns:\n",
    "            Optional[CheckpointTuple]: The retrieved checkpoint tuple, or None if no matching checkpoint was found.\n",
    "        \"\"\"\n",
    "        \n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\", \"\")\n",
    "        checkpoint_id = get_checkpoint_id(config)\n",
    "\n",
    "        if checkpoint_id:\n",
    "            query = f'SELECT * FROM {self.bucket_name}.{self.scope_name}.`checkpoints` WHERE thread_id = $1 AND checkpoint_ns = $2 AND checkpoint_id = $3 ORDER BY checkpoint_id DESC LIMIT 1'\n",
    "            query_params = [thread_id, checkpoint_ns, checkpoint_id]\n",
    "        else:\n",
    "            query = f'SELECT * FROM {self.bucket_name}.{self.scope_name}.`checkpoints` WHERE thread_id = $1 AND checkpoint_ns = $2 ORDER BY checkpoint_id DESC LIMIT 1'\n",
    "            query_params = [thread_id, checkpoint_ns]\n",
    "\n",
    "        result = self.cluster.query(query, QueryOptions(positional_parameters=query_params))\n",
    "\n",
    "        for row in result:\n",
    "            doc = row[\"checkpoints\"]\n",
    "            config_values = {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"checkpoint_ns\": checkpoint_ns,\n",
    "                \"checkpoint_id\": doc[\"checkpoint_id\"],\n",
    "            }\n",
    "            checkpoint = self.serde.loads_typed((doc[\"type\"], doc[\"checkpoint\"].encode()))\n",
    "\n",
    "            serialized_writes_query = f'SELECT * FROM {self.bucket_name}.{self.scope_name}.`checkpoint_writes` WHERE thread_id = $1 AND checkpoint_ns = $2 AND checkpoint_id = $3'\n",
    "            serialized_writes_params = [thread_id, checkpoint_ns, doc[\"checkpoint_id\"] or \"\"]\n",
    "            serialized_writes_result = self.cluster.query(serialized_writes_query, QueryOptions(positional_parameters=serialized_writes_params))\n",
    "\n",
    "            pending_writes = []\n",
    "            for write_doc in serialized_writes_result:\n",
    "                checkpoint_writes = write_doc.get(\"checkpoint_writes\", {})\n",
    "                if \"task_id\" not in checkpoint_writes:\n",
    "                    print(\"Error: 'task_id' is not present in checkpoint_writes\")\n",
    "                else:\n",
    "                    pending_writes.append(\n",
    "                        (\n",
    "                            checkpoint_writes[\"task_id\"],\n",
    "                            checkpoint_writes[\"channel\"],\n",
    "                            self.serde.loads_typed((checkpoint_writes[\"type\"], checkpoint_writes[\"value\"])),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            return CheckpointTuple(\n",
    "                {\"configurable\": config_values},\n",
    "                checkpoint,\n",
    "                self.serde.loads(doc[\"metadata\"].encode()),\n",
    "                (\n",
    "                    {\n",
    "                        \"configurable\": {\n",
    "                            \"thread_id\": thread_id,\n",
    "                            \"checkpoint_ns\": checkpoint_ns,\n",
    "                            \"checkpoint_id\": doc[\"parent_checkpoint_id\"],\n",
    "                        }\n",
    "                    }\n",
    "                    if doc.get(\"parent_checkpoint_id\")\n",
    "                    else None\n",
    "                ),\n",
    "                pending_writes,\n",
    "            )\n",
    "\n",
    "    def list(\n",
    "            self,\n",
    "            config: Optional[RunnableConfig],\n",
    "            *,\n",
    "            filter: Optional[Dict[str, Any]] = None,\n",
    "            before: Optional[RunnableConfig] = None,\n",
    "            limit: Optional[int] = None,\n",
    "        ) -> Iterator[CheckpointTuple]:\n",
    "        \"\"\"List checkpoints from the database.\n",
    "\n",
    "        This method retrieves a list of checkpoint tuples from the Couchbase database based\n",
    "        on the provided config. The checkpoints are ordered by checkpoint ID in descending order (newest first).\n",
    "\n",
    "        Args:\n",
    "            config (RunnableConfig): The config to use for listing the checkpoints.\n",
    "            filter (Optional[Dict[str, Any]]): Additional filtering criteria for metadata. Defaults to None.\n",
    "            before (Optional[RunnableConfig]): If provided, only checkpoints before the specified checkpoint ID are returned. Defaults to None.\n",
    "            limit (Optional[int]): The maximum number of checkpoints to return. Defaults to None.\n",
    "\n",
    "        Yields:\n",
    "            Iterator[CheckpointTuple]: An iterator of checkpoint tuples.\n",
    "        \"\"\"\n",
    "\n",
    "        query = f\"SELECT * FROM {self.bucket_name}.{self.scope_name}.`checkpoints` WHERE 1=1\"\n",
    "        query_params = []\n",
    "\n",
    "        if config is not None:\n",
    "            query += \" AND thread_id = $1 AND checkpoint_ns = $2\"\n",
    "            query_params.extend([config[\"configurable\"][\"thread_id\"], config[\"configurable\"].get(\"checkpoint_ns\", \"\")])\n",
    "\n",
    "        if filter:\n",
    "            for key, value in filter.items():\n",
    "                query += f\" AND metadata.{key} = ${len(query_params) + 1}\"\n",
    "                query_params.append(value)\n",
    "\n",
    "        if before is not None:\n",
    "            query += f\" AND checkpoint_id < ${len(query_params) + 1}\"\n",
    "            query_params.append(before[\"configurable\"][\"checkpoint_id\"])\n",
    "\n",
    "        query += \" ORDER BY checkpoint_id DESC\"\n",
    "\n",
    "        if limit is not None:\n",
    "            query += f\" LIMIT {limit}\"\n",
    "\n",
    "        result = self.cluster.query(query, QueryOptions(positional_parameters=query_params))\n",
    "\n",
    "        for row in result:\n",
    "            doc = row[\"checkpoints\"]\n",
    "            checkpoint = self.serde.loads_typed((doc[\"type\"], doc[\"checkpoint\"]))\n",
    "            yield CheckpointTuple(\n",
    "                {\n",
    "                    \"configurable\": {\n",
    "                        \"thread_id\": doc[\"thread_id\"],\n",
    "                        \"checkpoint_ns\": doc[\"checkpoint_ns\"],\n",
    "                        \"checkpoint_id\": doc[\"checkpoint_id\"],\n",
    "                    }\n",
    "                },\n",
    "                checkpoint,\n",
    "                self.serde.loads(doc[\"metadata\"].encode()),\n",
    "                (\n",
    "                    {\n",
    "                        \"configurable\": {\n",
    "                            \"thread_id\": doc[\"thread_id\"],\n",
    "                            \"checkpoint_ns\": doc[\"checkpoint_ns\"],\n",
    "                            \"checkpoint_id\": doc[\"parent_checkpoint_id\"],\n",
    "                        }\n",
    "                    }\n",
    "                    if doc.get(\"parent_checkpoint_id\")\n",
    "                    else None\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def put(\n",
    "            self,\n",
    "            config: RunnableConfig,\n",
    "            checkpoint: Checkpoint,\n",
    "            metadata: CheckpointMetadata,\n",
    "            new_versions: ChannelVersions,\n",
    "        ) -> RunnableConfig:\n",
    "        \"\"\"Save a checkpoint to the database.\n",
    "\n",
    "        This method saves a checkpoint to the Couchbase database. The checkpoint is associated\n",
    "        with the provided config and its parent config (if any).\n",
    "\n",
    "        Args:\n",
    "            config (RunnableConfig): The config to associate with the checkpoint.\n",
    "            checkpoint (Checkpoint): The checkpoint to save.\n",
    "            metadata (CheckpointMetadata): Additional metadata to save with the checkpoint.\n",
    "            new_versions (ChannelVersions): New channel versions as of this write.\n",
    "\n",
    "        Returns:\n",
    "            RunnableConfig: Updated configuration after storing the checkpoint.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        checkpoint_ns = config[\"configurable\"][\"checkpoint_ns\"]\n",
    "        checkpoint_id = checkpoint[\"id\"]\n",
    "        type_, serialized_checkpoint = self.serde.dumps_typed(checkpoint)\n",
    "        if serialized_checkpoint:\n",
    "            serialized_checkpoint = serialized_checkpoint.decode()\n",
    "            \n",
    "        metadata = self.serde.dumps(metadata)\n",
    "        if metadata:\n",
    "            metadata = metadata.decode()\n",
    "        \n",
    "        doc = {\n",
    "            \"parent_checkpoint_id\": config[\"configurable\"].get(\"checkpoint_id\"),\n",
    "            \"type\": type_,\n",
    "            \"checkpoint\": serialized_checkpoint,\n",
    "            \"metadata\": metadata,\n",
    "            \"thread_id\" : thread_id,\n",
    "            \"checkpoint_ns\": checkpoint_ns,\n",
    "            \"checkpoint_id\": checkpoint_id,\n",
    "        }\n",
    "        upsert_key = f\"{thread_id}::{checkpoint_ns}::{checkpoint_id}\"\n",
    "        \n",
    "        collection = self.bucket.scope(self.scope_name).collection(\"checkpoints\")\n",
    "        collection.upsert(upsert_key, (doc), UpsertOptions(timeout=timedelta(seconds=5)))\n",
    "\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"checkpoint_ns\": checkpoint_ns,\n",
    "                \"checkpoint_id\": checkpoint_id,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def put_writes(\n",
    "            self,\n",
    "            config: RunnableConfig,\n",
    "            writes: Sequence[Tuple[str, Any]],\n",
    "            task_id: str,\n",
    "        ) -> None:\n",
    "        \"\"\"Store intermediate writes linked to a checkpoint.\n",
    "\n",
    "        This method saves intermediate writes associated with a checkpoint to the Couchbase database.\n",
    "\n",
    "        Args:\n",
    "            config (RunnableConfig): Configuration of the related checkpoint.\n",
    "            writes (Sequence[Tuple[str, Any]]): List of writes to store, each as (channel, value) pair.\n",
    "            task_id (str): Identifier for the task creating the writes.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        checkpoint_ns = config[\"configurable\"][\"checkpoint_ns\"]\n",
    "        checkpoint_id = config[\"configurable\"][\"checkpoint_id\"]\n",
    "\n",
    "        collection = self.bucket.scope(self.scope_name).collection('checkpoint_writes')\n",
    "\n",
    "        for idx, (channel, value) in enumerate(writes):\n",
    "            upsert_key = f\"{thread_id}::{checkpoint_ns}::{checkpoint_id}::{task_id}::{idx}\"\n",
    "            type_, serialized_value = self.serde.dumps_typed(value)\n",
    "            if serialized_value:\n",
    "                serialized_value = serialized_value.decode().replace(\"'\", '\"')\n",
    "            doc = {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"checkpoint_ns\": checkpoint_ns,\n",
    "                \"checkpoint_id\": checkpoint_id,\n",
    "                \"task_id\": task_id,\n",
    "                \"idx\": idx,\n",
    "                \"channel\": channel,\n",
    "                \"type\": type_,\n",
    "                \"value\": serialized_value,\n",
    "            }\n",
    "            collection.upsert(upsert_key, (doc), UpsertOptions(timeout=timedelta(seconds=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AsyncCouchbaseSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a reference implementation of AsyncCouchbaseSaver (for asynchronous use of graph, i.e. `.ainvoke()`, `.astream()`). AsyncCouchbaseSaver implements four methods that are required for any async checkpointer:\n",
    "\n",
    "- `.aput` - Store a checkpoint with its configuration and metadata.\n",
    "- `.aput_writes` - Store intermediate writes linked to a checkpoint (i.e. pending writes).\n",
    "- `.aget_tuple` - Fetch a checkpoint tuple using for a given configuration (`thread_id` and `checkpoint_id`).\n",
    "- `.alist` - List checkpoints that match a given configuration and filter criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import asynccontextmanager\n",
    "from datetime import timedelta\n",
    "from typing import Any, AsyncIterator, Dict, Optional, Sequence, Tuple\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from acouchbase.cluster import Cluster as ACluster\n",
    "from acouchbase.bucket import Bucket as ABucket\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.options import ClusterOptions, QueryOptions, UpsertOptions\n",
    "\n",
    "from langgraph.checkpoint.base import (\n",
    "    BaseCheckpointSaver,\n",
    "    ChannelVersions,\n",
    "    Checkpoint,\n",
    "    CheckpointMetadata,\n",
    "    CheckpointTuple,\n",
    "    get_checkpoint_id,\n",
    ")\n",
    "\n",
    "\n",
    "class AsyncCouchbaseSaver(BaseCheckpointSaver):\n",
    "    \"\"\"A checkpoint saver that stores checkpoints in a Couchbase database.\"\"\"\n",
    "\n",
    "    cluster: ACluster\n",
    "    bucket: ABucket\n",
    "    def __init__(\n",
    "        self,\n",
    "        cluster: ACluster,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.cluster = cluster\n",
    "        \n",
    "    @classmethod\n",
    "    @asynccontextmanager\n",
    "    async def from_conn_info(\n",
    "        cls, *, cb_conn_str :str, cb_username: str, cb_password: str, bucket_name: str, scope_name: str\n",
    "    ) -> AsyncIterator[\"AsyncCouchbaseSaver\"]:\n",
    "        cluster = None\n",
    "        try:\n",
    "            auth = PasswordAuthenticator(cb_username, cb_password)\n",
    "            options = ClusterOptions(auth)\n",
    "            cluster = await ACluster.connect(cb_conn_str, options)\n",
    "            \n",
    "            cls.cluster = cluster\n",
    "            cls.bucket_name = bucket_name\n",
    "            cls.scope_name = scope_name\n",
    "\n",
    "            saver = AsyncCouchbaseSaver(cluster)\n",
    "            cls.bucket = cluster.bucket(bucket_name)\n",
    "            await cls.bucket.on_connect()\n",
    "            \n",
    "            yield saver\n",
    "        finally:\n",
    "            if cluster:\n",
    "                await cluster.close()\n",
    "\n",
    "\n",
    "    async def aget_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        \"\"\"Get a checkpoint tuple from the database asynchronously.\n",
    "\n",
    "        This method retrieves a checkpoint tuple from the Couchbase database based on the\n",
    "        provided config. If the config contains a \"checkpoint_id\" key, the checkpoint with\n",
    "        the matching thread ID and checkpoint ID is retrieved. Otherwise, the latest checkpoint\n",
    "        for the given thread ID is retrieved.\n",
    "\n",
    "        Args:\n",
    "            config (RunnableConfig): The config to use for retrieving the checkpoint.\n",
    "\n",
    "        Returns:\n",
    "            Optional[CheckpointTuple]: The retrieved checkpoint tuple, or None if no matching checkpoint was found.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\", \"\")\n",
    "        checkpoint_id = get_checkpoint_id(config)\n",
    "\n",
    "        print(\"thread_id: \", thread_id, \"checkpoint_ns: \", checkpoint_ns, \"checkpoint_id: \", checkpoint_id)\n",
    "        if checkpoint_id:\n",
    "            query = f'SELECT * FROM {self.bucket_name}.{self.scope_name}.`checkpoints` WHERE thread_id = $1 AND checkpoint_ns = $2 AND checkpoint_id = $3 ORDER BY checkpoint_id DESC LIMIT 1'\n",
    "            query_params = [thread_id, checkpoint_ns, checkpoint_id]\n",
    "        else:\n",
    "            query = f'SELECT * FROM {self.bucket_name}.{self.scope_name}.`checkpoints` WHERE thread_id = $1 AND checkpoint_ns = $2 ORDER BY checkpoint_id DESC LIMIT 1'\n",
    "            query_params = [thread_id, checkpoint_ns]\n",
    "\n",
    "        print(query)\n",
    "        result = self.cluster.query(query, QueryOptions(positional_parameters=query_params))\n",
    "\n",
    "        async for row in result:\n",
    "            doc = row[\"checkpoints\"]\n",
    "            config_values = {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"checkpoint_ns\": checkpoint_ns,\n",
    "                \"checkpoint_id\": doc[\"checkpoint_id\"],\n",
    "            }\n",
    "            checkpoint = self.serde.loads_typed((doc[\"type\"], doc[\"checkpoint\"].encode()))\n",
    "\n",
    "            serialized_writes_query = f'SELECT * FROM {self.bucket_name}.{self.scope_name}.`checkpoint_writes` WHERE thread_id = $1 AND checkpoint_ns = $2 AND checkpoint_id = $3'\n",
    "            serialized_writes_params = [thread_id, checkpoint_ns, doc[\"checkpoint_id\"] or \"\"]\n",
    "            print(serialized_writes_query, serialized_writes_params)\n",
    "            \n",
    "            serialized_writes_result = self.cluster.query(serialized_writes_query, QueryOptions(positional_parameters=serialized_writes_params))\n",
    "\n",
    "            pending_writes = []\n",
    "            async for write_doc in serialized_writes_result:\n",
    "                print(f\"write_doc: {write_doc}\")  # Debugging statement to log the contents of write_doc\n",
    "                checkpoint_writes = write_doc.get(\"checkpoint_writes\", {})\n",
    "                if \"task_id\" not in checkpoint_writes:\n",
    "                    print(\"Error: 'task_id' is not present in checkpoint_writes\")\n",
    "                else:\n",
    "                    pending_writes.append(\n",
    "                        (\n",
    "                            checkpoint_writes[\"task_id\"],\n",
    "                            checkpoint_writes[\"channel\"],\n",
    "                            self.serde.loads_typed((checkpoint_writes[\"type\"], checkpoint_writes[\"value\"])),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            return CheckpointTuple(\n",
    "                {\"configurable\": config_values},\n",
    "                checkpoint,\n",
    "                self.serde.loads(doc[\"metadata\"].encode()),\n",
    "                (\n",
    "                    {\n",
    "                        \"configurable\": {\n",
    "                            \"thread_id\": thread_id,\n",
    "                            \"checkpoint_ns\": checkpoint_ns,\n",
    "                            \"checkpoint_id\": doc[\"parent_checkpoint_id\"],\n",
    "                        }\n",
    "                    }\n",
    "                    if doc.get(\"parent_checkpoint_id\")\n",
    "                    else None\n",
    "                ),\n",
    "                pending_writes,\n",
    "            )\n",
    "\n",
    "    async def alist(\n",
    "            self,\n",
    "            config: Optional[RunnableConfig],\n",
    "            *,\n",
    "            filter: Optional[Dict[str, Any]] = None,\n",
    "            before: Optional[RunnableConfig] = None,\n",
    "            limit: Optional[int] = None,\n",
    "        ) -> AsyncIterator[CheckpointTuple]:\n",
    "        \"\"\"List checkpoints from the database asynchronously.\n",
    "\n",
    "        This method retrieves a list of checkpoint tuples from the Couchbase database based\n",
    "        on the provided config. The checkpoints are ordered by checkpoint ID in descending order (newest first).\n",
    "\n",
    "        Args:\n",
    "            config (Optional[RunnableConfig]): The config to use for listing the checkpoints.\n",
    "            filter (Optional[Dict[str, Any]]): Additional filtering criteria for metadata. Defaults to None.\n",
    "            before (Optional[RunnableConfig]): If provided, only checkpoints before the specified checkpoint ID are returned. Defaults to None.\n",
    "            limit (Optional[int]): The maximum number of checkpoints to return. Defaults to None.\n",
    "\n",
    "        Yields:\n",
    "            AsyncIterator[CheckpointTuple]: An asynchronous iterator of checkpoint tuples.\n",
    "        \"\"\"\n",
    "\n",
    "        query = f\"SELECT * FROM {self.bucket_name}.{self.scope_name}.`checkpoints` WHERE 1=1\"\n",
    "        query_params = []\n",
    "\n",
    "        if config is not None:\n",
    "            query += \" AND thread_id = $1 AND checkpoint_ns = $2\"\n",
    "            query_params.extend([config[\"configurable\"][\"thread_id\"], config[\"configurable\"].get(\"checkpoint_ns\", \"\")])\n",
    "\n",
    "        if filter:\n",
    "            for key, value in filter.items():\n",
    "                query += f\" AND metadata.{key} = ${len(query_params) + 1}\"\n",
    "                query_params.append(value)\n",
    "\n",
    "        if before is not None:\n",
    "            query += f\" AND checkpoint_id < ${len(query_params) + 1}\"\n",
    "            query_params.append(before[\"configurable\"][\"checkpoint_id\"])\n",
    "\n",
    "        query += \" ORDER BY checkpoint_id DESC\"\n",
    "\n",
    "        if limit is not None:\n",
    "            query += f\" LIMIT {limit}\"\n",
    "\n",
    "        result = self.cluster.query(query, QueryOptions(positional_parameters=query_params))\n",
    "\n",
    "        async for row in result:\n",
    "            doc = row[\"checkpoints\"]\n",
    "            checkpoint = self.serde.loads_typed((doc[\"type\"], doc[\"checkpoint\"]))\n",
    "            yield CheckpointTuple(\n",
    "                {\n",
    "                    \"configurable\": {\n",
    "                        \"thread_id\": doc[\"thread_id\"],\n",
    "                        \"checkpoint_ns\": doc[\"checkpoint_ns\"],\n",
    "                        \"checkpoint_id\": doc[\"checkpoint_id\"],\n",
    "                    }\n",
    "                },\n",
    "                checkpoint,\n",
    "                self.serde.loads(doc[\"metadata\"].encode()),\n",
    "                (\n",
    "                    {\n",
    "                        \"configurable\": {\n",
    "                            \"thread_id\": doc[\"thread_id\"],\n",
    "                            \"checkpoint_ns\": doc[\"checkpoint_ns\"],\n",
    "                            \"checkpoint_id\": doc[\"parent_checkpoint_id\"],\n",
    "                        }\n",
    "                    }\n",
    "                    if doc.get(\"parent_checkpoint_id\")\n",
    "                    else None\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    async def aput(\n",
    "            self,\n",
    "            config: RunnableConfig,\n",
    "            checkpoint: Checkpoint,\n",
    "            metadata: CheckpointMetadata,\n",
    "            new_versions: ChannelVersions,\n",
    "        ) -> RunnableConfig:\n",
    "        \"\"\"Save a checkpoint to the database asynchronously.\n",
    "\n",
    "        This method saves a checkpoint to the Couchbase database. The checkpoint is associated\n",
    "        with the provided config and its parent config (if any).\n",
    "\n",
    "        Args:\n",
    "            config (RunnableConfig): The config to associate with the checkpoint.\n",
    "            checkpoint (Checkpoint): The checkpoint to save.\n",
    "            metadata (CheckpointMetadata): Additional metadata to save with the checkpoint.\n",
    "            new_versions (ChannelVersions): New channel versions as of this write.\n",
    "\n",
    "        Returns:\n",
    "            RunnableConfig: Updated configuration after storing the checkpoint.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        checkpoint_ns = config[\"configurable\"][\"checkpoint_ns\"]\n",
    "        checkpoint_id = checkpoint[\"id\"]\n",
    "        type_, serialized_checkpoint = self.serde.dumps_typed(checkpoint)\n",
    "        if serialized_checkpoint:\n",
    "            serialized_checkpoint = serialized_checkpoint.decode()\n",
    "            \n",
    "        metadata = self.serde.dumps(metadata)\n",
    "        if metadata:\n",
    "            metadata = metadata.decode()\n",
    "        \n",
    "        doc = {\n",
    "            \"parent_checkpoint_id\": config[\"configurable\"].get(\"checkpoint_id\"),\n",
    "            \"type\": type_,\n",
    "            \"checkpoint\": serialized_checkpoint,\n",
    "            \"metadata\": metadata,\n",
    "            \"thread_id\" : thread_id,\n",
    "            \"checkpoint_ns\": checkpoint_ns,\n",
    "            \"checkpoint_id\": checkpoint_id,\n",
    "        }\n",
    "        # print(json.dumps(doc))\n",
    "        upsert_key = f\"{thread_id}::{checkpoint_ns}::{checkpoint_id}\"\n",
    "\n",
    "        collection = self.bucket.scope(self.scope_name).collection(\"checkpoints\")\n",
    "        await collection.upsert(upsert_key, (doc), UpsertOptions(timeout=timedelta(seconds=5)))\n",
    "\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"checkpoint_ns\": checkpoint_ns,\n",
    "                \"checkpoint_id\": checkpoint_id,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    async def aput_writes(\n",
    "            self,\n",
    "            config: RunnableConfig,\n",
    "            writes: Sequence[Tuple[str, Any]],\n",
    "            task_id: str,\n",
    "        ) -> None:\n",
    "        \"\"\"Store intermediate writes linked to a checkpoint asynchronously.\n",
    "\n",
    "        This method saves intermediate writes associated with a checkpoint to the Couchbase database.\n",
    "\n",
    "        Args:\n",
    "            config (RunnableConfig): Configuration of the related checkpoint.\n",
    "            writes (Sequence[Tuple[str, Any]]): List of writes to store, each as (channel, value) pair.\n",
    "            task_id (str): Identifier for the task creating the writes.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        checkpoint_ns = config[\"configurable\"][\"checkpoint_ns\"]\n",
    "        checkpoint_id = config[\"configurable\"][\"checkpoint_id\"]\n",
    "\n",
    "        collection = self.bucket.scope(self.scope_name).collection('checkpoint_writes')\n",
    "\n",
    "        for idx, (channel, value) in enumerate(writes):\n",
    "            upsert_key = f\"{thread_id}::{checkpoint_ns}::{checkpoint_id}::{task_id}::{idx}\"\n",
    "            type_, serialized_value = self.serde.dumps_typed(value)\n",
    "            if serialized_value:\n",
    "                serialized_value = serialized_value.decode().replace(\"'\", '\"')\n",
    "            doc = {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"checkpoint_ns\": checkpoint_ns,\n",
    "                \"checkpoint_id\": checkpoint_id,\n",
    "                \"task_id\": task_id,\n",
    "                \"idx\": idx,\n",
    "                \"channel\": channel,\n",
    "                \"type\": type_,\n",
    "                \"value\": serialized_value,\n",
    "            }\n",
    "            await collection.upsert(upsert_key, (doc), UpsertOptions(timeout=timedelta(seconds=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model and tools for the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a tool `get_weather` which gives the weather information based on the city. This tool gives weather information based on the city. We are also setting up the Chat GPT model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use sync connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create a Couchbase connection. We are using local setup with bucket `test`, `langgraph` scope. We will also require `checkpoints` and `checkpoint_writes` as collections inside.\n",
    "\n",
    "Then a [ReAct Agent](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/) is created with GPT Model, weather tool and Couchbase checkpointer.\n",
    "\n",
    "LangGraph's graph is invoked with message for GPT, storing all the state in Couchbase. We use get, get_tuple and list methods to fetch the states again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CouchbaseSaver.from_conn_info(\n",
    "    cb_conn_str=\"couchbase://localhost\",\n",
    "    cb_username=\"Administrator\",\n",
    "    cb_password=\"password\",\n",
    "    bucket_name=\"test\",\n",
    "    scope_name=\"langgraph\",\n",
    ") as checkpointer:\n",
    "    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    res = graph.invoke({\"messages\": [(\"human\", \"what's the weather in sf\")]}, config)\n",
    "    \n",
    "    latest_checkpoint = checkpointer.get(config)\n",
    "    latest_checkpoint_tuple = checkpointer.get_tuple(config)\n",
    "    checkpoint_tuples = list(checkpointer.list(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v': 1,\n",
       " 'ts': '2024-09-02T15:36:56.312466+00:00',\n",
       " 'id': '1ef69412-f89c-6a04-8002-1edbcb45b47f',\n",
       " 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='b1e35f4e-28b0-4e98-aedb-9ae848e3d8a9'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0bc63960-ba12-46cf-b5dc-137f29a1238b-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}),\n",
       "   ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='7032ea51-9e50-4564-bcae-2645ecd0b55f', tool_call_id='call_WDTjM34Km4HcTubnpR3CzchQ')],\n",
       "  'tools': 'tools'},\n",
       " 'channel_versions': {'__start__': 2,\n",
       "  'messages': 4,\n",
       "  'start:agent': 3,\n",
       "  'agent': 4,\n",
       "  'branch:agent:should_continue:tools': 4,\n",
       "  'tools': 4},\n",
       " 'versions_seen': {'__input__': {},\n",
       "  '__start__': {'__start__': 1},\n",
       "  'agent': {'start:agent': 2},\n",
       "  'tools': {'branch:agent:should_continue:tools': 3}},\n",
       " 'pending_sends': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-0357-6674-8003-77dd94f370df'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:57.437545+00:00', 'id': '1ef69413-0357-6674-8003-77dd94f370df', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='b1e35f4e-28b0-4e98-aedb-9ae848e3d8a9'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0bc63960-ba12-46cf-b5dc-137f29a1238b-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}), ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='7032ea51-9e50-4564-bcae-2645ecd0b55f', tool_call_id='call_WDTjM34Km4HcTubnpR3CzchQ'), AIMessage(content='The weather in San Francisco is always sunny!', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-a462cd6b-c35b-4443-8611-d5fa9b79f3a8-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})], 'agent': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in San Francisco is always sunny!', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-a462cd6b-c35b-4443-8611-d5fa9b79f3a8-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})]}}, 'step': 3, 'parents': {}}, parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef69412-f89c-6a04-8002-1edbcb45b47f'}}, pending_writes=[])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_checkpoint_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-0357-6674-8003-77dd94f370df'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:57.437545+00:00', 'id': '1ef69413-0357-6674-8003-77dd94f370df', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='b1e35f4e-28b0-4e98-aedb-9ae848e3d8a9'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0bc63960-ba12-46cf-b5dc-137f29a1238b-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}), ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='7032ea51-9e50-4564-bcae-2645ecd0b55f', tool_call_id='call_WDTjM34Km4HcTubnpR3CzchQ'), AIMessage(content='The weather in San Francisco is always sunny!', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-a462cd6b-c35b-4443-8611-d5fa9b79f3a8-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})], 'agent': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in San Francisco is always sunny!', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-a462cd6b-c35b-4443-8611-d5fa9b79f3a8-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})]}}, 'step': 3, 'parents': {}}, parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef69412-f89c-6a04-8002-1edbcb45b47f'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef69412-f89c-6a04-8002-1edbcb45b47f'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:56.312466+00:00', 'id': '1ef69412-f89c-6a04-8002-1edbcb45b47f', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='b1e35f4e-28b0-4e98-aedb-9ae848e3d8a9'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0bc63960-ba12-46cf-b5dc-137f29a1238b-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}), ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='7032ea51-9e50-4564-bcae-2645ecd0b55f', tool_call_id='call_WDTjM34Km4HcTubnpR3CzchQ')], 'tools': 'tools'}, 'channel_versions': {'__start__': 2, 'messages': 4, 'start:agent': 3, 'agent': 4, 'branch:agent:should_continue:tools': 4, 'tools': 4}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'tools': {'messages': [ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='7032ea51-9e50-4564-bcae-2645ecd0b55f', tool_call_id='call_WDTjM34Km4HcTubnpR3CzchQ')]}}, 'step': 2, 'parents': {}}, parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef69412-f896-6208-8001-942e3147b40e'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef69412-f896-6208-8001-942e3147b40e'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:56.309804+00:00', 'id': '1ef69412-f896-6208-8001-942e3147b40e', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='b1e35f4e-28b0-4e98-aedb-9ae848e3d8a9'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0bc63960-ba12-46cf-b5dc-137f29a1238b-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71})], 'agent': 'agent', 'branch:agent:should_continue:tools': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 3, 'start:agent': 3, 'agent': 3, 'branch:agent:should_continue:tools': 3}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0bc63960-ba12-46cf-b5dc-137f29a1238b-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_WDTjM34Km4HcTubnpR3CzchQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71})]}}, 'step': 1, 'parents': {}}, parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef69412-f1ab-6394-8000-bd11376d13f6'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef69412-f1ab-6394-8000-bd11376d13f6'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:55.584442+00:00', 'id': '1ef69412-f1ab-6394-8000-bd11376d13f6', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='b1e35f4e-28b0-4e98-aedb-9ae848e3d8a9')], 'start:agent': '__start__'}, 'channel_versions': {'__start__': 2, 'messages': 2, 'start:agent': 2}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}}, parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef69412-f1a7-6e92-bfff-1ee8c38ad7cf'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef69412-f1a7-6e92-bfff-1ee8c38ad7cf'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:55.583086+00:00', 'id': '1ef69412-f1a7-6e92-bfff-1ee8c38ad7cf', 'channel_values': {'__start__': {'messages': [['human', \"what's the weather in sf\"]]}}, 'channel_versions': {'__start__': 1}, 'versions_seen': {'__input__': {}}, 'pending_sends': []}, metadata={'source': 'input', 'writes': {'__start__': {'messages': [['human', \"what's the weather in sf\"]]}}, 'step': -1, 'parents': {}}, parent_config=None, pending_writes=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use async connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the asynchronous example, Here we will create a Couchbase connection. We are using local setup with bucket `test`, `langgraph` scope. We will also require `checkpoints` and `checkpoint_writes` as collections inside.\n",
    "\n",
    "Then a [ReAct Agent](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/) is created with GPT Model, weather tool and Couchbase checkpointer.\n",
    "\n",
    "LangGraph's graph is invoked with message for GPT, storing all the state in Couchbase. We use get, get_tuple and list methods to fetch the states again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_id:  2 checkpoint_ns:   checkpoint_id:  None\n",
      "SELECT * FROM test.langgraph.`checkpoints` WHERE thread_id = $1 AND checkpoint_ns = $2 ORDER BY checkpoint_id DESC LIMIT 1\n",
      "thread_id:  2 checkpoint_ns:   checkpoint_id:  None\n",
      "SELECT * FROM test.langgraph.`checkpoints` WHERE thread_id = $1 AND checkpoint_ns = $2 ORDER BY checkpoint_id DESC LIMIT 1\n",
      "SELECT * FROM test.langgraph.`checkpoint_writes` WHERE thread_id = $1 AND checkpoint_ns = $2 AND checkpoint_id = $3 ['2', '', '1ef69413-10bb-6d4c-8003-19c466b7447a']\n",
      "thread_id:  2 checkpoint_ns:   checkpoint_id:  None\n",
      "SELECT * FROM test.langgraph.`checkpoints` WHERE thread_id = $1 AND checkpoint_ns = $2 ORDER BY checkpoint_id DESC LIMIT 1\n",
      "SELECT * FROM test.langgraph.`checkpoint_writes` WHERE thread_id = $1 AND checkpoint_ns = $2 AND checkpoint_id = $3 ['2', '', '1ef69413-10bb-6d4c-8003-19c466b7447a']\n"
     ]
    }
   ],
   "source": [
    "async with AsyncCouchbaseSaver.from_conn_info(\n",
    "    cb_conn_str=\"couchbase://localhost\",\n",
    "    cb_username=\"Administrator\",\n",
    "    cb_password=\"password\",\n",
    "    bucket_name=\"test\",\n",
    "    scope_name=\"langgraph\",\n",
    ") as checkpointer:\n",
    "    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "    config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "    res = await graph.ainvoke(\n",
    "        {\"messages\": [(\"human\", \"what's the weather in nyc\")]}, config\n",
    "    )\n",
    "\n",
    "    latest_checkpoint = await checkpointer.aget(config)\n",
    "    latest_checkpoint_tuple = await checkpointer.aget_tuple(config)\n",
    "    checkpoint_tuples = [c async for c in checkpointer.alist(config)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v': 1,\n",
       " 'ts': '2024-09-02T15:36:58.841829+00:00',\n",
       " 'id': '1ef69413-10bb-6d4c-8003-19c466b7447a',\n",
       " 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='38e11355-dfcb-4419-a866-ce57e7879aa8'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ab2d766-1e9f-47a0-a50b-5d1c84a94dd6-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}),\n",
       "   ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='a56b34e5-6915-494c-b2e3-8eafe1d66119', tool_call_id='call_uqSSzLFdE0jhG6OhbKuQfcyB'),\n",
       "   AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd0a701e-52d0-499b-847e-9b93577b4508-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})],\n",
       "  'agent': 'agent'},\n",
       " 'channel_versions': {'__start__': 2,\n",
       "  'messages': 5,\n",
       "  'start:agent': 3,\n",
       "  'agent': 5,\n",
       "  'branch:agent:should_continue:tools': 4,\n",
       "  'tools': 5},\n",
       " 'versions_seen': {'__input__': {},\n",
       "  '__start__': {'__start__': 1},\n",
       "  'agent': {'start:agent': 2, 'tools': 4},\n",
       "  'tools': {'branch:agent:should_continue:tools': 3}},\n",
       " 'pending_sends': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-10bb-6d4c-8003-19c466b7447a'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:58.841829+00:00', 'id': '1ef69413-10bb-6d4c-8003-19c466b7447a', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='38e11355-dfcb-4419-a866-ce57e7879aa8'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ab2d766-1e9f-47a0-a50b-5d1c84a94dd6-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='a56b34e5-6915-494c-b2e3-8eafe1d66119', tool_call_id='call_uqSSzLFdE0jhG6OhbKuQfcyB'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd0a701e-52d0-499b-847e-9b93577b4508-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})], 'agent': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd0a701e-52d0-499b-847e-9b93577b4508-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})]}}, 'step': 3, 'parents': {}}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-0aa2-600a-8002-2197bf6a772b'}}, pending_writes=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_checkpoint_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-10bb-6d4c-8003-19c466b7447a'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:58.841829+00:00', 'id': '1ef69413-10bb-6d4c-8003-19c466b7447a', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='38e11355-dfcb-4419-a866-ce57e7879aa8'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ab2d766-1e9f-47a0-a50b-5d1c84a94dd6-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='a56b34e5-6915-494c-b2e3-8eafe1d66119', tool_call_id='call_uqSSzLFdE0jhG6OhbKuQfcyB'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd0a701e-52d0-499b-847e-9b93577b4508-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})], 'agent': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd0a701e-52d0-499b-847e-9b93577b4508-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})]}}, 'step': 3, 'parents': {}}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-0aa2-600a-8002-2197bf6a772b'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-0aa2-600a-8002-2197bf6a772b'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:58.202103+00:00', 'id': '1ef69413-0aa2-600a-8002-2197bf6a772b', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='38e11355-dfcb-4419-a866-ce57e7879aa8'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ab2d766-1e9f-47a0-a50b-5d1c84a94dd6-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='a56b34e5-6915-494c-b2e3-8eafe1d66119', tool_call_id='call_uqSSzLFdE0jhG6OhbKuQfcyB')], 'tools': 'tools'}, 'channel_versions': {'__start__': 2, 'messages': 4, 'start:agent': 3, 'agent': 4, 'branch:agent:should_continue:tools': 4, 'tools': 4}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'tools': {'messages': [ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='a56b34e5-6915-494c-b2e3-8eafe1d66119', tool_call_id='call_uqSSzLFdE0jhG6OhbKuQfcyB')]}}, 'step': 2, 'parents': {}}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-0a99-65c2-8001-b1a9f602ce61'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-0a99-65c2-8001-b1a9f602ce61'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:58.198566+00:00', 'id': '1ef69413-0a99-65c2-8001-b1a9f602ce61', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='38e11355-dfcb-4419-a866-ce57e7879aa8'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ab2d766-1e9f-47a0-a50b-5d1c84a94dd6-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73})], 'agent': 'agent', 'branch:agent:should_continue:tools': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 3, 'start:agent': 3, 'agent': 3, 'branch:agent:should_continue:tools': 3}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}, 'agent': {'start:agent': 2}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ab2d766-1e9f-47a0-a50b-5d1c84a94dd6-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_uqSSzLFdE0jhG6OhbKuQfcyB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73})]}}, 'step': 1, 'parents': {}}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-0400-67ce-8000-53532fd907e8'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-0400-67ce-8000-53532fd907e8'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:57.506804+00:00', 'id': '1ef69413-0400-67ce-8000-53532fd907e8', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='38e11355-dfcb-4419-a866-ce57e7879aa8')], 'start:agent': '__start__'}, 'channel_versions': {'__start__': 2, 'messages': 2, 'start:agent': 2}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': 1}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}}, parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-03fd-61e6-bfff-81609956e564'}}, pending_writes=None),\n",
       " CheckpointTuple(config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1ef69413-03fd-61e6-bfff-81609956e564'}}, checkpoint={'v': 1, 'ts': '2024-09-02T15:36:57.505419+00:00', 'id': '1ef69413-03fd-61e6-bfff-81609956e564', 'channel_values': {'__start__': {'messages': [['human', \"what's the weather in nyc\"]]}}, 'channel_versions': {'__start__': 1}, 'versions_seen': {'__input__': {}}, 'pending_sends': []}, metadata={'source': 'input', 'writes': {'__start__': {'messages': [['human', \"what's the weather in nyc\"]]}}, 'step': -1, 'parents': {}}, parent_config=None, pending_writes=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
