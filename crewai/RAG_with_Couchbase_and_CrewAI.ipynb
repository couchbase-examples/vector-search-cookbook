{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this guide, we will walk you through building a powerful semantic search engine using Couchbase as the backend database and [CrewAI](https://github.com/joaomdmoura/crewAI) for agent-based RAG operations. CrewAI allows us to create specialized agents that can work together to handle different aspects of the RAG workflow, from document retrieval to response generation. This tutorial is designed to be beginner-friendly, with clear, step-by-step instructions that will equip you with the knowledge to create a fully functional semantic search system from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the Stage: Installing Necessary Libraries\n",
    "\n",
    "To build our semantic search engine, we need a robust set of tools. The libraries we install handle everything from connecting to databases to performing complex machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets langchain-couchbase langchain-openai crewai python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries\n",
    "\n",
    "The script starts by importing a series of libraries required for various tasks, including handling JSON, logging, time tracking, Couchbase connections, embedding generation, and dataset loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from uuid import uuid4\n",
    "from typing import Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.exceptions import InternalServerFailureException, QueryIndexAlreadyExistsException\n",
    "from couchbase.management.search import SearchIndex\n",
    "from couchbase.options import ClusterOptions\n",
    "from datasets import load_dataset\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_couchbase.cache import CouchbaseCache\n",
    "from langchain_couchbase.vectorstores import CouchbaseVectorStore\n",
    "from langchain.tools import Tool\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Logging\n",
    "\n",
    "Logging is configured to track the progress of the script and capture any errors or warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Settings\n",
    "\n",
    "Load configuration settings from environment variables or use default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set\")\n",
    "\n",
    "CB_HOST = os.getenv('CB_HOST', 'couchbase://localhost')\n",
    "CB_USERNAME = os.getenv('CB_USERNAME', 'Administrator')\n",
    "CB_PASSWORD = os.getenv('CB_PASSWORD', 'password')\n",
    "CB_BUCKET_NAME = os.getenv('CB_BUCKET_NAME', 'vector-search-testing')\n",
    "INDEX_NAME = os.getenv('INDEX_NAME', 'vector_search_crew')\n",
    "SCOPE_NAME = os.getenv('SCOPE_NAME', 'shared')\n",
    "COLLECTION_NAME = os.getenv('COLLECTION_NAME', 'crew')\n",
    "CACHE_COLLECTION = os.getenv('CACHE_COLLECTION', 'cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Search Tool Implementation\n",
    "\n",
    "Define a custom tool for performing vector searches with improved result formatting and error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query: str, vector_store: Any) -> str:\n",
    "    \"\"\"Perform vector search and return formatted results\"\"\"\n",
    "    try:\n",
    "        # Ensure query is a string\n",
    "        if isinstance(query, dict):\n",
    "            query = str(query.get('query', ''))\n",
    "        elif not isinstance(query, str):\n",
    "            query = str(query)\n",
    "            \n",
    "        # Get more results and with higher similarity threshold\n",
    "        docs = vector_store.similarity_search(\n",
    "            query,\n",
    "            k=8,  # Increase number of results\n",
    "            fetch_k=20  # Fetch more candidates for reranking\n",
    "        )\n",
    "        \n",
    "        # Format results with more context\n",
    "        results = []\n",
    "        for i, doc in enumerate(docs, 1):\n",
    "            # Add document number and content\n",
    "            results.append(f\"Document {i}:\")\n",
    "            results.append(\"-\" * 40)\n",
    "            results.append(doc.page_content)\n",
    "            \n",
    "            # Add metadata if available\n",
    "            if hasattr(doc, 'metadata') and doc.metadata:\n",
    "                results.append(\"\\nMetadata:\")\n",
    "                for key, value in doc.metadata.items():\n",
    "                    results.append(f\"{key}: {value}\")\n",
    "            \n",
    "            results.append(\"\\n\")  # Add spacing between documents\n",
    "            \n",
    "        return \"\\n\".join(results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Vector search failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def create_vector_search_tool(vector_store: Any) -> Tool:\n",
    "    \"\"\"Create a vector search tool\"\"\"\n",
    "    return Tool(\n",
    "        name=\"vector_search\",\n",
    "        func=lambda query: vector_search(query, vector_store),\n",
    "        description=\"\"\"Search for relevant documents using vector similarity.\n",
    "        Input should be a simple text query string.\n",
    "        Returns a list of relevant document contents with metadata.\n",
    "        Use this tool to find detailed information about topics.\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Couchbase and Vector Store\n",
    "\n",
    "Initialize Couchbase connection, setup collections, and create the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_couchbase():\n",
    "    \"\"\"Initialize Couchbase connection and setup collections\"\"\"\n",
    "    try:\n",
    "        # Connect to Couchbase\n",
    "        auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
    "        options = ClusterOptions(auth)\n",
    "        cluster = Cluster(CB_HOST, options)\n",
    "        cluster.wait_until_ready(timedelta(seconds=5))\n",
    "        logging.info(\"Successfully connected to Couchbase\")\n",
    "        \n",
    "        def setup_collection(collection_name):\n",
    "            bucket = cluster.bucket(CB_BUCKET_NAME)\n",
    "            bucket_manager = bucket.collections()\n",
    "            \n",
    "            # Check if collection exists\n",
    "            collections = bucket_manager.get_all_scopes()\n",
    "            collection_exists = any(\n",
    "                scope.name == SCOPE_NAME and collection_name in [col.name for col in scope.collections]\n",
    "                for scope in collections\n",
    "            )\n",
    "            \n",
    "            if not collection_exists:\n",
    "                bucket_manager.create_collection(SCOPE_NAME, collection_name)\n",
    "                logging.info(f\"Collection '{collection_name}' created\")\n",
    "            else:\n",
    "                logging.info(f\"Collection '{collection_name}' already exists\")\n",
    "            \n",
    "            # Create primary index\n",
    "            cluster.query(\n",
    "                f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{CB_BUCKET_NAME}`.`{SCOPE_NAME}`.`{collection_name}`\"\n",
    "            ).execute()\n",
    "            logging.info(f\"Primary index created for '{collection_name}'\")\n",
    "            \n",
    "            # Clear collection\n",
    "            cluster.query(\n",
    "                f\"DELETE FROM `{CB_BUCKET_NAME}`.`{SCOPE_NAME}`.`{collection_name}`\"\n",
    "            ).execute()\n",
    "            logging.info(f\"Collection '{collection_name}' cleared\")\n",
    "            \n",
    "            return bucket.scope(SCOPE_NAME).collection(collection_name)\n",
    "        \n",
    "        # Setup main and cache collections\n",
    "        setup_collection(COLLECTION_NAME)\n",
    "        setup_collection(CACHE_COLLECTION)\n",
    "        \n",
    "        return cluster\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to setup Couchbase: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def setup_vector_store(cluster):\n",
    "    \"\"\"Initialize vector store and embeddings\"\"\"\n",
    "    try:\n",
    "        # Load index definition\n",
    "        with open('crew_index.json', 'r') as file:\n",
    "            index_definition = json.load(file)\n",
    "        \n",
    "        # Setup vector search index\n",
    "        scope_index_manager = cluster.bucket(CB_BUCKET_NAME).scope(SCOPE_NAME).search_indexes()\n",
    "        \n",
    "        # Check if index exists\n",
    "        try:\n",
    "            existing_indexes = scope_index_manager.get_all_indexes()\n",
    "            index_exists = any(index.name == INDEX_NAME for index in existing_indexes)\n",
    "            \n",
    "            if index_exists:\n",
    "                logging.info(f\"Index '{INDEX_NAME}' already exists\")\n",
    "            else:\n",
    "                search_index = SearchIndex.from_json(index_definition)\n",
    "                scope_index_manager.upsert_index(search_index)\n",
    "                logging.info(f\"Index '{INDEX_NAME}' created\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error handling index: {str(e)}\")\n",
    "            # Continue anyway since the index might exist\n",
    "        \n",
    "        # Initialize OpenAI components\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        \n",
    "        llm = ChatOpenAI(\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        # Setup vector store\n",
    "        vector_store = CouchbaseVectorStore(\n",
    "            cluster=cluster,\n",
    "            bucket_name=CB_BUCKET_NAME,\n",
    "            scope_name=SCOPE_NAME,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            embedding=embeddings,\n",
    "            index_name=INDEX_NAME,\n",
    "        )\n",
    "        logging.info(\"Vector store initialized\")\n",
    "        \n",
    "        # Setup cache\n",
    "        cache = CouchbaseCache(\n",
    "            cluster=cluster,\n",
    "            bucket_name=CB_BUCKET_NAME,\n",
    "            scope_name=SCOPE_NAME,\n",
    "            collection_name=CACHE_COLLECTION,\n",
    "        )\n",
    "        set_llm_cache(cache)\n",
    "        logging.info(\"Cache initialized\")\n",
    "        \n",
    "        return vector_store, llm\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to setup vector store: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sample Data\n",
    "\n",
    "Load and process the TREC dataset for our vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data(vector_store):\n",
    "    \"\"\"Load sample data into vector store\"\"\"\n",
    "    try:\n",
    "        # Load TREC dataset\n",
    "        trec = load_dataset('trec', split='train[:1000]')\n",
    "        logging.info(f\"Loaded {len(trec)} samples from TREC dataset\")\n",
    "        \n",
    "        # Disable logging during data loading\n",
    "        logging.disable(logging.INFO)\n",
    "        \n",
    "        # Add documents in batches\n",
    "        batch_size = 50\n",
    "        for i in tqdm(range(0, len(trec['text']), batch_size), desc=\"Loading data\"):\n",
    "            batch = trec['text'][i:i + batch_size]\n",
    "            documents = [Document(page_content=text) for text in batch]\n",
    "            uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "            vector_store.add_documents(documents=documents, ids=uuids)\n",
    "            \n",
    "        # Re-enable logging\n",
    "        logging.disable(logging.NOTSET)\n",
    "        logging.info(\"Sample data loaded into vector store\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Re-enable logging in case of error\n",
    "        logging.disable(logging.NOTSET)\n",
    "        logging.error(f\"Failed to load sample data: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up CrewAI Agents\n",
    "\n",
    "Create specialized agents for research and writing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_agents(llm, vector_store):\n",
    "    \"\"\"Create CrewAI agents\"\"\"\n",
    "    # Create vector search tool\n",
    "    search_tool = create_vector_search_tool(vector_store)\n",
    "    \n",
    "    # Custom response template for better formatting\n",
    "    response_template = \"\"\"\n",
    "    Analysis Results:\n",
    "    ----------------\n",
    "    {{ .Response }}\n",
    "    \n",
    "    Sources Used:\n",
    "    ------------\n",
    "    {% for tool in .Tools %}\n",
    "    - {{ tool.name }}\n",
    "    {% endfor %}\n",
    "    \n",
    "    Confidence Level: {{ .Confidence }}\n",
    "    Analysis Time: {{ .ExecutionTime }}\n",
    "    \"\"\"\n",
    "    \n",
    "    researcher = Agent(\n",
    "        role='Research Expert',\n",
    "        goal='Find and analyze the most relevant documents to answer user queries accurately',\n",
    "        backstory=\"\"\"You are an expert researcher with deep knowledge in information retrieval \n",
    "        and analysis. Your expertise lies in finding, evaluating, and synthesizing information \n",
    "        from various sources. You have a keen eye for detail and can identify key insights \n",
    "        from complex documents. You always verify information across multiple sources and \n",
    "        provide comprehensive, accurate analyses.\"\"\",\n",
    "        tools=[search_tool],\n",
    "        llm=llm,\n",
    "        verbose=True,\n",
    "        memory=True,\n",
    "        allow_delegation=False,\n",
    "        response_template=response_template\n",
    "    )\n",
    "    \n",
    "    writer = Agent(\n",
    "        role='Technical Writer',\n",
    "        goal='Generate clear, accurate, and well-structured responses based on research findings',\n",
    "        backstory=\"\"\"You are a skilled technical writer with expertise in making complex \n",
    "        information accessible and engaging. You excel at organizing information logically, \n",
    "        explaining technical concepts clearly, and creating well-structured documents. You \n",
    "        ensure all information is properly cited, accurate, and presented in a user-friendly \n",
    "        manner. You have a talent for maintaining the reader's interest while conveying \n",
    "        detailed technical information.\"\"\",\n",
    "        llm=llm,\n",
    "        verbose=True,\n",
    "        memory=True,\n",
    "        allow_delegation=False,\n",
    "        response_template=response_template\n",
    "    )\n",
    "    \n",
    "    logging.info(\"Agents created\")\n",
    "    return researcher, writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Tasks\n",
    "\n",
    "Define tasks for research and writing with detailed instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tasks(query, researcher, writer):\n",
    "    \"\"\"Create CrewAI tasks\"\"\"\n",
    "    # Research task\n",
    "    research_task = Task(\n",
    "        description=f\"\"\"Research and analyze information relevant to: {query}\n",
    "        \n",
    "        Follow these steps:\n",
    "        1. Use the vector_search tool to find relevant documents\n",
    "        2. Search with multiple variations of the query to ensure comprehensive coverage\n",
    "        3. Analyze each document carefully, noting key points and supporting evidence\n",
    "        4. Cross-reference information across documents to verify accuracy\n",
    "        5. Identify any conflicting information or gaps in knowledge\n",
    "        6. Organize findings into clear, logical categories\n",
    "        \n",
    "        Focus on:\n",
    "        - Accuracy and completeness of information\n",
    "        - Relevance to the query\n",
    "        - Quality and reliability of sources\n",
    "        - Key concepts and their relationships\n",
    "        - Supporting evidence and examples\"\"\",\n",
    "        agent=researcher,\n",
    "        expected_output=\"\"\"A detailed analysis containing:\n",
    "        1. Key findings organized by topic\n",
    "        2. Supporting evidence from documents\n",
    "        3. Any conflicting information or uncertainties\n",
    "        4. Gaps in knowledge that may need further research\n",
    "        5. Relevant context and background information\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Writing task\n",
    "    writing_task = Task(\n",
    "        description=f\"\"\"Create a comprehensive and well-structured response based on the research findings.\n",
    "        \n",
    "        Follow these steps:\n",
    "        1. Review and analyze all research findings\n",
    "        2. Organize information into a logical structure\n",
    "        3. Create clear section headings and transitions\n",
    "        4. Explain complex concepts in accessible language\n",
    "        5. Include relevant examples and illustrations\n",
    "        6. Ensure proper citation of sources\n",
    "        \n",
    "        The response should be:\n",
    "        1. Clear and easy to understand\n",
    "        2. Well-organized with logical flow\n",
    "        3. Accurate and supported by research\n",
    "        4. Engaging and informative\n",
    "        5. Appropriate for the target audience\"\"\",\n",
    "        agent=writer,\n",
    "        expected_output=\"\"\"A clear, comprehensive response that:\n",
    "        1. Answers the query completely\n",
    "        2. Is well-structured and organized\n",
    "        3. Uses clear, accessible language\n",
    "        4. Includes relevant examples\n",
    "        5. Cites supporting evidence\n",
    "        6. Maintains reader engagement\"\"\",\n",
    "        context=[research_task]  # Properly set task dependency\n",
    "    )\n",
    "    \n",
    "    return [research_task, writing_task]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Search Function\n",
    "\n",
    "Implement the main search functionality that coordinates the agents and tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(result: Any) -> str:\n",
    "    \"\"\"Format the response for better readability\"\"\"\n",
    "    if not result:\n",
    "        return \"No response generated\"\n",
    "        \n",
    "    # Format the main response\n",
    "    formatted = []\n",
    "    formatted.append(\"=\" * 80)\n",
    "    formatted.append(\"RESPONSE\")\n",
    "    formatted.append(\"=\" * 80)\n",
    "    formatted.append(str(result))\n",
    "    \n",
    "    # Add task outputs if available\n",
    "    if hasattr(result, 'tasks_output'):\n",
    "        formatted.append(\"\\n\" + \"=\" * 80)\n",
    "        formatted.append(\"DETAILED TASK OUTPUTS\")\n",
    "        formatted.append(\"=\" * 80)\n",
    "        for task_output in result.tasks_output:\n",
    "            formatted.append(f\"\\nTask: {task_output.description[:100]}...\")\n",
    "            formatted.append(\"-\" * 40)\n",
    "            formatted.append(f\"Output: {task_output.raw}\")\n",
    "            formatted.append(\"-\" * 40)\n",
    "    \n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "def search(query: str, vector_store: Any, researcher: Any, writer: Any) -> Optional[str]:\n",
    "    \"\"\"Perform search and generate response\"\"\"\n",
    "    try:\n",
    "        # Create and execute crew\n",
    "        crew = Crew(\n",
    "            agents=[researcher, writer],\n",
    "            tasks=create_tasks(query, researcher, writer),\n",
    "            process=Process.sequential,  # Execute tasks in order\n",
    "            verbose=True,\n",
    "            cache=True,  # Enable caching\n",
    "            planning=True  # Enable planning capability\n",
    "        )\n",
    "        \n",
    "        result = crew.kickoff()\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Search failed: {str(e)}\")\n",
    "        logging.exception(\"Error details:\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Search System\n",
    "\n",
    "Initialize the system and run some example queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup components\n",
    "print(\"\\nInitializing search system...\")\n",
    "print(\"This may take a few minutes for initial setup.\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "cluster = setup_couchbase()\n",
    "vector_store, llm = setup_vector_store(cluster)\n",
    "load_sample_data(vector_store)\n",
    "researcher, writer = setup_agents(llm, vector_store)\n",
    "\n",
    "print(\"\\nSetup complete! You can now enter your queries.\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Example queries\n",
    "queries = [\n",
    "    \"What caused the 1929 Great Depression?\",\n",
    "    \"Why do heavier objects fall faster?\",\n",
    "    \"How does photosynthesis work?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = search(query, vector_store, researcher, writer)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nQuery completed in {elapsed_time:.2f} seconds\")\n",
    "    print(format_response(result))\n",
    "    print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
