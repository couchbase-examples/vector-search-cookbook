{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this guide, we will walk you through building a powerful semantic search engine using Couchbase as the backend database and [CrewAI](https://github.com/joaomdmoura/crewAI) for agent-based RAG operations. CrewAI allows us to create specialized agents that can work together to handle different aspects of the RAG workflow, from document retrieval to response generation. This tutorial is designed to be beginner-friendly, with clear, step-by-step instructions that will equip you with the knowledge to create a fully functional semantic search system from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the Stage: Installing Necessary Libraries\n",
    "\n",
    "To build our semantic search engine, we need a robust set of tools. The libraries we install handle everything from connecting to databases to performing complex machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets langchain-couchbase langchain-openai crewai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries\n",
    "\n",
    "The script starts by importing a series of libraries required for various tasks, including handling JSON, logging, time tracking, Couchbase connections, embedding generation, and dataset loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.exceptions import CouchbaseException, InternalServerFailureException, QueryIndexAlreadyExistsException\n",
    "from couchbase.management.search import SearchIndex\n",
    "from couchbase.options import ClusterOptions\n",
    "from datasets import load_dataset\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_couchbase.cache import CouchbaseCache\n",
    "from langchain_couchbase.vectorstores import CouchbaseVectorStore\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Logging\n",
    "\n",
    "Logging is configured to track the progress of the script and capture any errors or warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Configuration Settings\n",
    "\n",
    "In this section, we load configuration settings from environment variables or prompt the user for input. These settings include API keys, database credentials, and specific configuration names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# Load environment variables from .env file if it exists\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API Key\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or getpass.getpass('Enter your OpenAI API key: ')\n",
    "\n",
    "# Couchbase Settings\n",
    "CB_HOST = os.getenv('CB_HOST') or input('Enter your Couchbase host (default: couchbase://localhost): ') or 'couchbase://localhost'\n",
    "CB_USERNAME = os.getenv('CB_USERNAME') or input('Enter your Couchbase username (default: Administrator): ') or 'Administrator'\n",
    "CB_PASSWORD = os.getenv('CB_PASSWORD') or getpass.getpass('Enter your Couchbase password (default: password): ') or 'password'\n",
    "CB_BUCKET_NAME = os.getenv('CB_BUCKET_NAME') or input('Enter your Couchbase bucket name (default: vector-search-testing): ') or 'vector-search-testing'\n",
    "INDEX_NAME = input('Enter your index name (default: vector_search_crew): ') or 'vector_search_crew'\n",
    "SCOPE_NAME = input('Enter your scope name (default: shared): ') or 'shared'\n",
    "COLLECTION_NAME = input('Enter your collection name (default: crew): ') or 'crew'\n",
    "CACHE_COLLECTION = input('Enter your cache collection name (default: cache): ') or 'cache'\n",
    "\n",
    "# Check if OpenAI API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to the Couchbase Cluster\n",
    "\n",
    "Connecting to a Couchbase cluster is the foundation of our project. Couchbase will serve as our primary data store, handling all the storage and retrieval operations required for our semantic search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
    "    options = ClusterOptions(auth)\n",
    "    cluster = Cluster(CB_HOST, options)\n",
    "    cluster.wait_until_ready(timedelta(seconds=5))\n",
    "    logging.info(\"Successfully connected to Couchbase\")\n",
    "except Exception as e:\n",
    "    raise ConnectionError(f\"Failed to connect to Couchbase: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Collections in Couchbase\n",
    "\n",
    "In Couchbase, data is organized in buckets, which can be further divided into scopes and collections. Before we can store any data, we need to ensure that our collections exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_collection(cluster, bucket_name, scope_name, collection_name):\n",
    "    try:\n",
    "        bucket = cluster.bucket(bucket_name)\n",
    "        bucket_manager = bucket.collections()\n",
    "\n",
    "        # Check if collection exists, create if it doesn't\n",
    "        collections = bucket_manager.get_all_scopes()\n",
    "        collection_exists = any(\n",
    "            scope.name == scope_name and collection_name in [col.name for col in scope.collections]\n",
    "            for scope in collections\n",
    "        )\n",
    "\n",
    "        if not collection_exists:\n",
    "            logging.info(f\"Collection '{collection_name}' does not exist. Creating it...\")\n",
    "            bucket_manager.create_collection(scope_name, collection_name)\n",
    "            logging.info(f\"Collection '{collection_name}' created successfully.\")\n",
    "        else:\n",
    "            logging.info(f\"Collection '{collection_name}' already exists. Skipping creation.\")\n",
    "\n",
    "        collection = bucket.scope(scope_name).collection(collection_name)\n",
    "\n",
    "        # Ensure primary index exists\n",
    "        try:\n",
    "            cluster.query(f\"CREATE PRIMARY INDEX IF NOT EXISTS ON `{bucket_name}`.`{scope_name}`.`{collection_name}`\").execute()\n",
    "            logging.info(\"Primary index present or created successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error creating primary index: {str(e)}\")\n",
    "\n",
    "        # Clear all documents in the collection\n",
    "        try:\n",
    "            query = f\"DELETE FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
    "            cluster.query(query).execute()\n",
    "            logging.info(\"All documents cleared from the collection.\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error while clearing documents: {str(e)}. The collection might be empty.\")\n",
    "\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error setting up collection: {str(e)}\")\n",
    "\n",
    "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, COLLECTION_NAME)\n",
    "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, CACHE_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Couchbase Vector Search Index\n",
    "\n",
    "Semantic search requires an efficient way to retrieve relevant documents based on a user's query. This is where the Couchbase **Vector Search Index** comes into play. In this step, we load the Vector Search Index definition from a JSON file, which specifies how the index should be structured.\n",
    "\n",
    "For more information on creating a vector search index, please follow the [instructions](https://docs.couchbase.com/cloud/vector-search/create-vector-search-index-ui.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('crew_index.json', 'r') as file:\n",
    "        index_definition = json.load(file)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading index definition: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating or Updating Search Indexes\n",
    "\n",
    "With the index definition loaded, the next step is to create or update the **Vector Search Index** in Couchbase. This step is crucial because it optimizes our database for vector similarity search operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    scope_index_manager = cluster.bucket(CB_BUCKET_NAME).scope(SCOPE_NAME).search_indexes()\n",
    "\n",
    "    # Check if index already exists\n",
    "    existing_indexes = scope_index_manager.get_all_indexes()\n",
    "    index_name = index_definition[\"name\"]\n",
    "\n",
    "    if index_name in [index.name for index in existing_indexes]:\n",
    "        logging.info(f\"Index '{index_name}' found\")\n",
    "    else:\n",
    "        logging.info(f\"Creating new index '{index_name}'...\")\n",
    "\n",
    "    # Create SearchIndex object from JSON definition\n",
    "    search_index = SearchIndex.from_json(index_definition)\n",
    "\n",
    "    # Upsert the index (create if not exists, update if exists)\n",
    "    scope_index_manager.upsert_index(search_index)\n",
    "    logging.info(f\"Index '{index_name}' successfully created/updated.\")\n",
    "\n",
    "except QueryIndexAlreadyExistsException:\n",
    "    logging.info(f\"Index '{index_name}' already exists. Skipping creation/update.\")\n",
    "\n",
    "except InternalServerFailureException as e:\n",
    "    error_message = str(e)\n",
    "    logging.error(f\"InternalServerFailureException raised: {error_message}\")\n",
    "\n",
    "    try:\n",
    "        # Accessing the response_body attribute from the context\n",
    "        error_context = e.context\n",
    "        response_body = error_context.response_body\n",
    "        if response_body:\n",
    "            error_details = json.loads(response_body)\n",
    "            error_message = error_details.get('error', '')\n",
    "\n",
    "            if \"collection: 'crew' doesn't belong to scope: 'shared'\" in error_message:\n",
    "                raise ValueError(\"Collection 'crew' does not belong to scope 'shared'. Please check the collection and scope names.\")\n",
    "\n",
    "    except ValueError as ve:\n",
    "        logging.error(str(ve))\n",
    "        raise\n",
    "\n",
    "    except Exception as json_error:\n",
    "        logging.error(f\"Failed to parse the error message: {json_error}\")\n",
    "        raise RuntimeError(f\"Internal server error while creating/updating search index: {error_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the TREC Dataset\n",
    "\n",
    "To build a search engine, we need data to search through. We use the TREC dataset, a well-known benchmark in the field of information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trec = load_dataset('trec', split='train[:1000]')\n",
    "    logging.info(f\"Successfully loaded TREC dataset with {len(trec)} samples\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading TREC dataset: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up OpenAI Embeddings and LLM\n",
    "\n",
    "We'll use OpenAI's models for embeddings and language generation, which will be used by our CrewAI agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        openai_api_key=OPENAI_API_KEY,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=OPENAI_API_KEY,\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        temperature=0\n",
    "    )\n",
    "    logging.info(\"Successfully created OpenAI clients\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error creating OpenAI clients: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up the Couchbase Vector Store\n",
    "\n",
    "A vector store is where we'll keep our embeddings. Unlike the FTS index, which is used for text-based search, the vector store is specifically designed to handle embeddings and perform similarity searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    vector_store = CouchbaseVectorStore(\n",
    "        cluster=cluster,\n",
    "        bucket_name=CB_BUCKET_NAME,\n",
    "        scope_name=SCOPE_NAME,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        embedding=embeddings,\n",
    "        index_name=INDEX_NAME,\n",
    "    )\n",
    "    logging.info(\"Successfully created vector store\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to create vector store: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Data to the Vector Store\n",
    "\n",
    "With the vector store set up, the next step is to populate it with data. We save the TREC dataset to the vector store in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    batch_size = 50\n",
    "    logging.disable(sys.maxsize) # Disable logging to prevent tqdm output\n",
    "    for i in tqdm(range(0, len(trec['text']), batch_size), desc=\"Processing Batches\"):\n",
    "        batch = trec['text'][i:i + batch_size]\n",
    "        documents = [Document(page_content=text) for text in batch]\n",
    "        uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "        vector_store.add_documents(documents=documents, ids=uuids)\n",
    "    logging.disable(logging.NOTSET) # Re-enable logging\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to save documents to vector store: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up a Couchbase Cache\n",
    "\n",
    "To further optimize our system, we set up a Couchbase-based cache. A cache is a temporary storage layer that holds data that is frequently accessed, speeding up operations by reducing the need to repeatedly retrieve the same information from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cache = CouchbaseCache(\n",
    "        cluster=cluster,\n",
    "        bucket_name=CB_BUCKET_NAME,\n",
    "        scope_name=SCOPE_NAME,\n",
    "        collection_name=CACHE_COLLECTION,\n",
    "    )\n",
    "    logging.info(\"Successfully created cache\")\n",
    "    set_llm_cache(cache)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to create cache: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating CrewAI Agents\n",
    "\n",
    "Now we'll create specialized agents using CrewAI. Each agent will have a specific role in our RAG system:\n",
    "1. Research Agent - Responsible for retrieving relevant documents\n",
    "2. Writing Agent - Responsible for generating responses based on retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Agent for document retrieval\n",
    "researcher = Agent(\n",
    "    role='Research Expert',\n",
    "    goal='Find the most relevant documents to answer user queries',\n",
    "    backstory=\"\"\"You are an expert researcher with deep knowledge in information retrieval. \n",
    "    Your job is to find the most relevant documents to help answer user questions.\"\"\",\n",
    "    tools=[],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Writing Agent for response generation\n",
    "writer = Agent(\n",
    "    role='Technical Writer',\n",
    "    goal='Generate clear and accurate responses based on provided documents',\n",
    "    backstory=\"\"\"You are a skilled technical writer who excels at synthesizing information \n",
    "    from multiple sources to create clear and accurate responses.\"\"\",\n",
    "    tools=[],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "logging.info(\"Successfully created CrewAI agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating CrewAI Tasks\n",
    "\n",
    "Now we'll define the tasks that our agents will perform. These tasks form the workflow of our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tasks(query):\n",
    "    # Task for retrieving relevant documents\n",
    "    research_task = Task(\n",
    "        description=f\"Find relevant documents to answer: {query}\",\n",
    "        agent=researcher,\n",
    "        context=lambda: format_docs(vector_store.similarity_search(query))\n",
    "    )\n",
    "\n",
    "    # Task for generating response\n",
    "    writing_task = Task(\n",
    "        description=\"Generate a comprehensive response based on the retrieved documents\",\n",
    "        agent=writer,\n",
    "        context=lambda: research_task.output\n",
    "    )\n",
    "\n",
    "    return [research_task, writing_task]\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "logging.info(\"Successfully created task definitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Running the Crew\n",
    "\n",
    "Now we'll create a Crew that coordinates our agents to perform RAG operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What caused the 1929 Great Depression?\"\n",
    "\n",
    "try:\n",
    "    # Create crew with tasks\n",
    "    crew = Crew(\n",
    "        agents=[researcher, writer],\n",
    "        tasks=create_tasks(query),\n",
    "        process=Process.sequential,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Execute the crew's tasks\n",
    "    start_time = time.time()\n",
    "    result = crew.kickoff()\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"\\nCrewAI Response (completed in {elapsed_time:.2f} seconds):\")\n",
    "    print(result)\n",
    "\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error executing CrewAI tasks: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Multiple Queries\n",
    "\n",
    "Let's test our CrewAI-powered RAG system with multiple queries to see how it handles different types of questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    queries = [\n",
    "        \"Why do heavier objects travel downhill faster?\",\n",
    "        \"What caused the 1929 Great Depression?\", # Repeated query\n",
    "        \"Why do heavier objects travel downhill faster?\",  # Repeated query\n",
    "    ]\n",
    "\n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(f\"\\nQuery {i}: {query}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Create and execute crew for each query\n",
    "        crew = Crew(\n",
    "            agents=[researcher, writer],\n",
    "            tasks=create_tasks(query),\n",
    "            process=Process.sequential,\n",
    "            verbose=True\n",
    "        )\n",
    "        result = crew.kickoff()\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Response: {result}\")\n",
    "        print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error generating CrewAI responses: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
