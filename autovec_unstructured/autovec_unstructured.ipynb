{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f623039",
   "metadata": {},
   "source": [
    "# Couchbase Capella AI Services Auto-Vectorization Tutorial\n",
    "This comprehensive tutorial demonstrates how to use Couchbase Capella's new AI Services auto-vectorization feature to automatically convert your data into vector embeddings and perform semantic search using LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d47a8a",
   "metadata": {},
   "source": [
    "# 1. Create and Deploy Your Operational cluster on Capella\n",
    "To get started with Couchbase Capella, create an account and use it to deploy a cluster. To know more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).\n",
    "    \n",
    "### Couchbase Capella Configuration\n",
    "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met.\n",
    "- Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the travel-sample bucket (Read and Write) used in the application.\\n\",\n",
    "- [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08bd871-e20d-4362-b5c1-765737894c65",
   "metadata": {},
   "source": [
    "# 2. Deploying the Model\n",
    "Now, before we actually create embeddings for the documents, we need to deploy a model that will create the embeddings for us.\n",
    "## 2.1: Selecting the Model \n",
    "1. To select the model, you first need to navigate to the \"<B>AI Services</B>\" tab, then select \"<B>Models</B>\" and click on \"<B>Deploy New Model</B>\".\n",
    "   \n",
    "   <img src=\"./img/importing_model.png\" width=\"950px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "2. Enter the <B>model name</B>, and choose the model that you want to deploy. After selecting your model, choose the <B>model infrastructure</B> and <B>region</B> where the model will be deployed.\n",
    "   \n",
    "   <img src=\"./img/deploying_model.png\" width=\"800px\" height=\"800px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "## 2.2 Access Control to the Model\n",
    "\n",
    "1. After deploying the model, go to the \"<B>Models</B>\" tab in the <B>AI Services</B> and click on \"<B>Setup Access</B>\".\n",
    "\n",
    "    <img src=\"./img/model_setup_access.png\" width=\"1100px\" height=\"400px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "2. Enter your <B>API key name</B>, <B>expiration time</B> and the <B>IP address</B> from which you will be accessing the model.\n",
    "\n",
    "    <img src=\"./img/model_api_key_form.png\" width=\"1100px\" height=\"600px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "3. Download your API key\n",
    "\n",
    "   <img src=\"./img/download_api_key_details.png\" width=\"1200px\" height=\"800px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7552113",
   "metadata": {},
   "source": [
    "# 3. Data upload from S3 bucket to couchbase(with chunking and vectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b64dd-495b-4358-b732-d01856713b70",
   "metadata": {},
   "source": [
    "In order to import unstructured data from the S3 bucket, you need to create a workflow which connects to your S3 bucket and chunks your unstructured data before importing it into the collections. To do so, please follow the steps mentioned below:\n",
    "1) Let's start by creating a new workflow. which can be done by clicking on the <B>`AI Services`</B> tab, then click on <B>`Workflows`</B>, and then click on <B>`Create New Workflow`</B>.\n",
    "   \n",
    "   <img src=\"./img/workflow.png\" width=\"1000px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "   \n",
    "2) Start your workflow deployment by giving it a name and selecting where your data will be provided to the auto-vectorization service. There are currently 3 options: <B>`pre-processed data (JSON format) from Capella`</B>, <B>`pre-processed data (JSON format) from external sources (S3 buckets)`</B> and <B>`unstructured data from external sources (S3 buckets)`</B>. For this tutorial, we will choose the third option, which is unstructured data from external sources(S3 buckets). After selecting the workflow enter the workflow name and click on <B>`Start Workflow`</B>.\n",
    "   \n",
    "   <img src=\"./img/start_workflow.png\" width=\"1000px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "3) To proceed, capella needs to connect to your S3 bucket which will be the source of the data, and to do so click on the <B>`+ Add New S3 Bucket`</B>.\n",
    "\n",
    "   <img src=\"./img/addS3bucket.png\" width=\"1000px\" height=\"300px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "4) Upon clicking <B>`+ Add New S3 Bucket`</B> a new sidebar will appear asking for the credentials of your S3 bucket.\n",
    "\n",
    "   <img src=\"./img/S3credentials.png\" width=\"1000px\" height=\"800px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "   \n",
    "   - Enter <B>`Integration Name`</B>, which will be later used to select your S3 Bucket.\n",
    "   - Select the AWS Region where the bucket is deployed.\n",
    "   - Enter the name of the S3 bucket deployed in AWS.\n",
    "   - Enter the path where your unstructured-data is present.\n",
    "   - Enter your S3 bucket credentials.\n",
    "   - Click on ADD Credentials.\n",
    "5) If the steps mentioned above are followed correctly then you should see a success pop-up as shown below and then S3 bucket can be selected from the drop-down menu.\n",
    "\n",
    "   <img src=\"./img/S3bucketsuccess.png\" width=\"800px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "6) On selection of the S3 bucket, various options will be shown as described and shown below.\n",
    "\n",
    "   <img src=\"./img/configure_data_source.png\" width=\"900px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "- `Index Configuration` allows us to create a search index on the generated embeddings of the imported data. If it's skipped then the functionality of vector searching will not be enabled and you need to create index later on.\n",
    "- `Destination Cluster` helps choose the cluster, bucket, scope and collection in which the data needs to be imported.\n",
    "- `Estimated Cost` dialogue box in blue color(on the right) will show you the cost of operation per document.\n",
    "- Click on `Next`.\n",
    "  \n",
    "7) <B>`Configure Data Preprocessing`</B> allows to perform various operation on the data being imported from the S3 buckets and are descibed below.\n",
    "   \n",
    "   <img src=\"./img/data_processing.png\" width=\"600px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "- <B>`Page Range selection`</B> allow to select a custom page range when working with PDFs. (Optional)\n",
    "- <B>`Layout Exclusions`</B> allow to skip various unnecessary objects in your unstructured data. (Optional)\n",
    "- <B>`Object Character Recognition (OCR)`</B> allow to detect text from images/pdfs. (Optional)\n",
    "- <B>`Chunking Strategy`</B> is a important step and for importing data and creating embeddings(vectors) in capella, the step will be further described below.\n",
    "    - `Strategy` dropdown menu helps to select the strategy that will be used to chunk the data present in S3 bucket and might be useful depending upon the data present in the S3 bucket.\n",
    "    - `Max Token in Chunk` decides the number of tokens that will be present in a chunk.\n",
    "    - `Chunk Overlap` decided the number of tokens that will overlap, this helps in creating contexts between chunks.\n",
    "- Click `Next` after the options above specified are modified according to the requirement.\n",
    "\n",
    "8) Select the model which will be used to create the embeddings. There are two options to create the embeddings, `capella based` and `external model`.\n",
    "\n",
    "   <img src=\"./img/Select_embedding_model.png\" width=\"600px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "   \n",
    "   - For this tutorial, capella based embedding model is used as can be seen in the image below. API credentials can be uploade using the file downloaded in `step 2.2` or it can be entered manually as well.\n",
    "   - Choices between private and insecure networking is available to choose.\n",
    "   - A click on `Next` will land you at the final page of the workflow.\n",
    "          \n",
    "9) <B>`Workflow Summary`</B> will display all the necessary details of the workflow including `Data Source`, `Model Service`, `Unstructured Data Service` and `Billing Overview` as shown in image below.\n",
    "\n",
    "   <img src=\"./img/workflow_summary.png\" width=\"800px\" height=\"500px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "10) <B>`Hurray! Workflow Deployed`</B> Now in the `workflow` tabs we can see out workflow deployed and can check the status of our workflow. The status of the workflow run will be shown over here.\n",
    "\n",
    "       <img src=\"./img/workflow_deployed.png\" width=\"950px\" height=\"350px\" style=\"padding: 5px; border-radius: 10px 20px 30px 40px; border: 2px solid #555;\">\n",
    "\n",
    "\n",
    "    After this step, your vector embeddings for the selected fields should be ready, and you can check them out in the Capella UI. In the next step, we will demonstrate how we can use the generated vectors to perform vector search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7321a7",
   "metadata": {},
   "source": [
    "# 5. Vector Search\n",
    "\n",
    "The following code cells implement semantic vector search against the embeddings generated by the AutoVectorization workflow. \n",
    "   \n",
    "Proceed to execute the cells in order to run the vector similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef050e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from couchbase.cluster import Cluster\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.options import ClusterOptions\n",
    "from datetime import timedelta\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings      \n",
    "from langchain_couchbase.vectorstores import CouchbaseSearchVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8428f2-f923-42df-bf7d-beacf5b38f16",
   "metadata": {},
   "source": [
    "# Cluster Connection Setup\n",
    "   - Defines the secure connection string, user credentials, and creates a `Cluster` object.\n",
    "   - Disables TLS verification by `options = ClusterOptions(auth, tls_verify='none')` ONLY for quick local testing (not recommended in production) and applies the `wan_development` profile to tune timeouts for higher-latency networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44ea528-1ec1-41ce-90db-bdd0d87b5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"couchbases://cb.ddm6ubdjrosbwo5y.sandbox.nonprod-project-avengers.com\"  # Replace this with Connection String\n",
    "username = \"testing\"  # Replace this with your username\n",
    "password = \"Testing@1\"  # Replace this with your password\n",
    "auth = PasswordAuthenticator(username, password)\n",
    "# Configure cluster options with SSL verification disabled for testing; in production you should enable it\n",
    "options = ClusterOptions(auth, tls_verify='none')\n",
    "options.apply_profile(\"wan_development\")\n",
    "cluster = Cluster(endpoint, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0874f89",
   "metadata": {},
   "source": [
    "# Selection of Buckets / Scope / Collection / Index / Embedder\n",
    "   - Sets the bucket, scope, and collection where the documents (with vector fields) live.\n",
    "   - Specifies the Capella Search index name created (or selected) in Step 4.5.\n",
    "   - Instantiates the NVIDIA embedding model that will transform the user's natural language query into a vector at search time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d77404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"Unstructured_data_bucket\"\n",
    "scope_name = \"_default\"\n",
    "collection_name = \"_default\"\n",
    "index_name = \"testing_search_index_unstructured\"  # This is the name of the search index that was created in step 4.5 and can also be seen in the search tab of the cluster.\n",
    "                                                          # It should be noted that hybrid_workflow_name_index_fieldname is the naming convention for the index created by AutoVectorization workflow where\n",
    "                                                          # fieldname is the name of the field being indexed.\n",
    "embedder = NVIDIAEmbeddings(\n",
    "    model=\"nvidia/nv-embedqa-e5-v5\",                      # This is the model that will be used to create the embedding of the query.\n",
    "    api_key=\"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\"                                   # This is the API key that will be used to access your model.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9ac43",
   "metadata": {},
   "source": [
    "# VectorStore Construction\n",
    "   - Creates a `CouchbaseSearchVectorStore` instance that:\n",
    "     * Knows where to read documents (`bucket/scope/collection`).\n",
    "     * Knows the embedding field (the vector produced by the AutoVectorization workflow).\n",
    "     * Uses the provided embedder to embed queries on-demand.\n",
    "   - If your AutoVectorization workflow produced a different vector field name, update `embedding_key` accordingly.\n",
    "   - If you mapped multiple fields into a single vector, you can choose any representative field for `text_key`, or modify the VectorStore wrapper to concatenate fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8efd0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = CouchbaseSearchVectorStore(\n",
    "    cluster=cluster,\n",
    "    bucket_name=bucket_name,\n",
    "    scope_name=scope_name,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedder,\n",
    "    index_name=index_name,\n",
    "    text_key=\"text-embedding\",                  # Your document's text field\n",
    "    embedding_key=\"text-embedding\"    # This is the field in which your vector (embedding) is stored in the cluster.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17adeeed",
   "metadata": {},
   "source": [
    "# Performing a Similarity Search\n",
    "   - Defines a natural language query (e.g., \"USA\").\n",
    "   - Calls `similarity_search(k=3)` to retrieve the top 3 most semantically similar documents.\n",
    "   - Prints ranked results, extracting a `title` (if present) and the chosen `text_key` (here `address`).\n",
    "   - Change `query` to any descriptive phrase (e.g., \"beach resort\", \"airport hotel near NYC\").\n",
    "   - Adjust `k` for more or fewer results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb87c6e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Search failed with error: Search results do not contain the fields from the document. Please check if the Search index contains the required fields:text-embedding",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vector-search-cookbook/autovec_unstructured/mvenv/lib/python3.13/site-packages/langchain_couchbase/vectorstores/search_vector_store.py:466\u001b[39m, in \u001b[36mCouchbaseSearchVectorStore.similarity_search_with_score_by_vector\u001b[39m\u001b[34m(self, embedding, k, search_options, filter, **kwargs)\u001b[39m\n\u001b[32m    465\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    467\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mSearch results do not contain the fields from the document. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    468\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mPlease check if the Search index contains the required fields:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    469\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._text_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    470\u001b[39m             )\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mValueError\u001b[39m: Search results do not contain the fields from the document. Please check if the Search index contains the required fields:text-embedding",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mCouchbase setup\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m results = \u001b[43mvector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Print out the top-k results\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rank, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results, start=\u001b[32m1\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vector-search-cookbook/autovec_unstructured/mvenv/lib/python3.13/site-packages/langchain_couchbase/vectorstores/search_vector_store.py:344\u001b[39m, in \u001b[36mCouchbaseSearchVectorStore.similarity_search\u001b[39m\u001b[34m(self, query, k, search_options, filter, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return documents most similar to embedding vector with their scores.\u001b[39;00m\n\u001b[32m    296\u001b[39m \n\u001b[32m    297\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    341\u001b[39m \n\u001b[32m    342\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m    343\u001b[39m query_embedding = \u001b[38;5;28mself\u001b[39m.embeddings.embed_query(query)\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m docs_with_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score_by_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_with_scores]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vector-search-cookbook/autovec_unstructured/mvenv/lib/python3.13/site-packages/langchain_couchbase/vectorstores/search_vector_store.py:472\u001b[39m, in \u001b[36mCouchbaseSearchVectorStore.similarity_search_with_score_by_vector\u001b[39m\u001b[34m(self, embedding, k, search_options, filter, **kwargs)\u001b[39m\n\u001b[32m    466\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    467\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mSearch results do not contain the fields from the document. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    468\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mPlease check if the Search index contains the required fields:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    469\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._text_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    470\u001b[39m             )\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSearch failed with error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m docs_with_score\n",
      "\u001b[31mValueError\u001b[39m: Search failed with error: Search results do not contain the fields from the document. Please check if the Search index contains the required fields:text-embedding"
     ]
    }
   ],
   "source": [
    "query = \"Couchbase setup\"\n",
    "results = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "# Print out the top-k results\n",
    "for rank, doc in enumerate(results, start=1):\n",
    "    title = doc.metadata.get(\"title\", \"<no title>\")\n",
    "    address_text = doc.page_content\n",
    "    print(f\"{rank}. {title} — Address: {address_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab91ee",
   "metadata": {},
   "source": [
    "## 6. Results and Interpretation\n",
    "\n",
    "As we can see, 3 (or `k`) ranked results are printed in the output.\n",
    "\n",
    "### What Each Part Means\n",
    "- Leading number (1, 2, 3): The result rank (1 = most similar to your query).\n",
    "- Title: Pulled from `doc.metadata.get(\"title\", \"<no title>\")`. If your documents don't contain a `title` field, you will see `<no title>`.\n",
    "- Address text: This is the value of the field you configured as `text_key` (in this tutorial: `address`). It represents the human-readable content we chose to display.\n",
    "\n",
    "### How the Ranking Works\n",
    "1. Your natural language query (e.g., `\"Woodhead Road\"`) is embedded using the NVIDIA model (`nvidia/nv-embedqa-e5-v5`).\n",
    "2. The vector store compares the query embedding to stored document embeddings in the field you configured (`embedding_key = \"vec_addr_descr_id\"`).\n",
    "3. Results are sorted by vector similarity. Higher similarity = closer semantic meaning.\n",
    "\n",
    "\n",
    "> Your vector search pipeline is working if the returned documents feel meaningfully related to your natural language query—even when exact keywords do not match. Feel free to experiment with increasingly descriptive queries to observe the semantic power of the embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
