{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6880599d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this guide, we will walk you through building a powerful semantic search engine using Couchbase as the backend database, [Mistral AI](https://mistral.ai/) as the AI-powered embedding Model. Semantic search goes beyond simple keyword matching by understanding the context and meaning behind the words in a query, making it an essential tool for applications that require intelligent information retrieval. This tutorial is designed to be beginner-friendly, with clear, step-by-step instructions that will equip you with the knowledge to create a fully functional semantic search system from scratch. Alternatively, if you want to perform semantic search using the Hyperscale or Composite Vector Indexes, please take a look at [this.](https://developer.couchbase.com/tutorial-mistralai-couchbase-vector-search-with-hyperscale-or-composite-vector-index)\n",
    "\n",
    "Couchbase is a NoSQL distributed document database (JSON) with many of the best features of a relational DBMS: SQL, distributed ACID transactions, and much more. [Couchbase Capella™](https://cloud.couchbase.com/sign-up) is the easiest way to get started, but you can also download and run [Couchbase Server](http://couchbase.com/downloads) on-premises.\n",
    "\n",
    "Mistral AI is a research lab building the best open source models in the world. La Plateforme enables developers and enterprises to build new products and applications, powered by Mistral’s open source and commercial LLMs. \n",
    "\n",
    "The [Mistral AI APIs](https://console.mistral.ai/) empower LLM applications via:\n",
    "\n",
    "- [Text generation](https://docs.mistral.ai/capabilities/completion/), enables streaming and provides the ability to display partial model results in real-time\n",
    "- [Code generation](https://docs.mistral.ai/capabilities/code_generation/), enpowers code generation tasks, including fill-in-the-middle and code completion\n",
    "- [Embeddings](https://docs.mistral.ai/capabilities/embeddings/), useful for RAG where it represents the meaning of text as a list of numbers\n",
    "- [Function calling](https://docs.mistral.ai/capabilities/function_calling/), enables Mistral models to connect to external tools\n",
    "- [Fine-tuning](https://docs.mistral.ai/capabilities/finetuning/), enables developers to create customized and specilized models\n",
    "- [JSON mode](https://docs.mistral.ai/capabilities/json_mode/), enables developers to set the response format to json_object\n",
    "- [Guardrailing](https://docs.mistral.ai/capabilities/guardrailing/), enables developers to enforce policies at the system level of Mistral models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898559f",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "\n",
    "## Get Credentials for Mistral AI\n",
    "\n",
    "Please follow the [instructions](https://console.mistral.ai/api-keys/) to generate the Mistral AI credentials.\n",
    "\n",
    "## Create and Deploy Your Free Tier Operational cluster on Capella\n",
    "\n",
    "To get started with Couchbase Capella, create an account and use it to deploy a forever free tier operational cluster. This account provides you with a environment where you can explore and learn about Capella with no time constraint.\n",
    "\n",
    "To know more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).\n",
    "\n",
    "### Couchbase Capella Configuration\n",
    "\n",
    "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met.\n",
    "\n",
    "* Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the travel-sample bucket (Read and Write) used in the application.\n",
    "* [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db87cf",
   "metadata": {},
   "source": [
    "# Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8100b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting couchbase==4.3.5\n",
      "  Using cached couchbase-4.3.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (23 kB)\n",
      "Collecting mistralai==1.7.0\n",
      "  Downloading mistralai-1.7.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting eval-type-backport>=0.2.0 (from mistralai==1.7.0)\n",
      "  Using cached eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from mistralai==1.7.0) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.10.3 in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from mistralai==1.7.0) (2.11.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from mistralai==1.7.0) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from mistralai==1.7.0) (0.4.0)\n",
      "Requirement already satisfied: anyio in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai==1.7.0) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai==1.7.0) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai==1.7.0) (1.0.8)\n",
      "Requirement already satisfied: idna in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->mistralai==1.7.0) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->mistralai==1.7.0) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from pydantic>=2.10.3->mistralai==1.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from pydantic>=2.10.3->mistralai==1.7.0) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from pydantic>=2.10.3->mistralai==1.7.0) (4.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->mistralai==1.7.0) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/aayush.tyagi/Documents/AI/vector-search-cookbook/.venv/lib/python3.12/site-packages (from anyio->httpx>=0.28.1->mistralai==1.7.0) (1.3.1)\n",
      "Using cached couchbase-4.3.5-cp312-cp312-macosx_11_0_arm64.whl (4.0 MB)\n",
      "Downloading mistralai-1.7.0-py3-none-any.whl (301 kB)\n",
      "Using cached eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Installing collected packages: eval-type-backport, couchbase, mistralai\n",
      "  Attempting uninstall: couchbase\n",
      "    Found existing installation: couchbase 4.3.3\n",
      "    Uninstalling couchbase-4.3.3:\n",
      "      Successfully uninstalled couchbase-4.3.3\n",
      "Successfully installed couchbase-4.3.5 eval-type-backport-0.2.2 mistralai-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install couchbase==4.3.5 mistralai==1.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5587c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d80648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "from mistralai import Mistral\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.options import (ClusterOptions, ClusterTimeoutOptions,\n",
    "                               QueryOptions)\n",
    "import couchbase.search as search\n",
    "from couchbase.options import SearchOptions\n",
    "from couchbase.vector_search import VectorQuery, VectorSearch\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa75df1",
   "metadata": {},
   "source": [
    "# Prerequisites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25ebb6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster URL: localhost\n",
      "Couchbase username: Administrator\n",
      "Couchbase password: ········\n",
      "Couchbase bucket: mistralai\n",
      "Couchbase scope: _default\n",
      "Couchbase collection: mistralai\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "couchbase_cluster_url = input(\"Cluster URL:\")\n",
    "couchbase_username = input(\"Couchbase username:\")\n",
    "couchbase_password = getpass.getpass(\"Couchbase password:\")\n",
    "couchbase_bucket = input(\"Couchbase bucket:\")\n",
    "couchbase_scope = input(\"Couchbase scope:\")\n",
    "couchbase_collection = input(\"Couchbase collection:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb5f0b",
   "metadata": {},
   "source": [
    "# Couchbase Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f782ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = PasswordAuthenticator(\n",
    "    couchbase_username,\n",
    "    couchbase_password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a50befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(couchbase_cluster_url, ClusterOptions(auth))\n",
    "cluster.wait_until_ready(timedelta(seconds=5))\n",
    "\n",
    "bucket = cluster.bucket(couchbase_bucket)\n",
    "scope = bucket.scope(couchbase_scope)\n",
    "collection = scope.collection(couchbase_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7180bf",
   "metadata": {},
   "source": [
    "# Creating Couchbase Search Vector Index\n",
    "In order to store Mistral embeddings onto a Couchbase Cluster, a search vector index needs to be created first. We included a sample index definition that will work with this tutorial in the `mistralai_index.json` file. The definition can be used to create a vector index using Couchbase server web console, on more information on vector indexes, please read [Create a Vector Search Index with the Server Web Console](https://docs.couchbase.com/server/current/vector-search/create-vector-search-index-ui.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c997407",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_index_name = couchbase_bucket + \"._default.vector_test\"\n",
    "search_index = cluster.search_indexes().get_index(search_index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e678c12e",
   "metadata": {},
   "source": [
    "# Mistral Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1f557f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_API_KEY = getpass.getpass(\"Mistral API Key:\")\n",
    "mistral_client = Mistral(api_key=MISTRAL_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c4df0",
   "metadata": {},
   "source": [
    "# Embedding Documents\n",
    "Mistral client can be used to generate vector embeddings for given text fragments. These embeddings represent the sentiment of corresponding fragments and can be stored in Couchbase for further retrieval. A custom embedding text can also be added into the embedding texts array by running this code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Couchbase Server is a multipurpose, distributed database that fuses the strengths of relational databases such as SQL and ACID transactions with JSON’s versatility, with a foundation that is extremely fast and scalable.\",\n",
    "    \"It’s used across industries for things like user profiles, dynamic product catalogs, GenAI apps, vector search, high-speed caching, and much more.\",\n",
    "    input(\"custom embedding text\")\n",
    "]\n",
    "embeddings = mistral_client.embeddings.create(\n",
    "    model=\"mistral-embed\",\n",
    "    inputs=texts,\n",
    ")\n",
    "\n",
    "print(\"Output embeddings: \" + str(len(embeddings.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa18f3",
   "metadata": {},
   "source": [
    "The output `embeddings` is an EmbeddingResponse object with the embeddings and the token usage information:\n",
    "\n",
    "```\n",
    "EmbeddingResponse(\n",
    "    id='eb4c2c739780415bb3af4e47580318cc', object='list', data=[\n",
    "        Data(object='embedding', embedding=[-0.0165863037109375,...], index=0),\n",
    "        Data(object='embedding', embedding=[-0.0234222412109375,...], index=1)],\n",
    "        Data(object='embedding', embedding=[-0.0466222735279375,...], index=2)],\n",
    "    model='mistral-embed', usage=EmbeddingResponseUsage(prompt_tokens=15, total_tokens=15)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0779926",
   "metadata": {},
   "source": [
    "# Storing Embeddings in Couchbase\n",
    "Each embedding needs to be stored as a couchbase document. According to provided search index, embedding vector values need to be stored in the `vector` field. The original text of the embedding can be stored in the same document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9150357",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(texts)):\n",
    "    doc = {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"text\": texts[i],\n",
    "        \"vector\": embeddings.data[i].embedding,\n",
    "    }\n",
    "    collection.upsert(doc[\"id\"], doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83173d1a",
   "metadata": {},
   "source": [
    "# Searching For Embeddings\n",
    "Stored in Couchbase embeddings later can be searched using the vector index to, for example, find text fragments that would be the most relevant to some user-entered prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3801f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found answer: 7a4c24dd-393f-4f08-ae42-69ea7009dcda; score: 1.7320726542316662\n",
      "Answer text: Couchbase Server is a multipurpose, distributed database that fuses the strengths of relational databases such as SQL and ACID transactions with JSON’s versatility, with a foundation that is extremely fast and scalable.\n"
     ]
    }
   ],
   "source": [
    "search_embedding = mistral_client.embeddings.create(\n",
    "    model=\"mistral-embed\",\n",
    "    inputs=[\"name a multipurpose database with distributed capability\"],\n",
    ").data[0]\n",
    "\n",
    "search_req = search.SearchRequest.create(search.MatchNoneQuery()).with_vector_search(\n",
    "    VectorSearch.from_vector_query(\n",
    "        VectorQuery(\n",
    "            \"vector\", search_embedding.embedding, num_candidates=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "result = scope.search(\n",
    "    \"vector_test\", \n",
    "    search_req, \n",
    "    SearchOptions(\n",
    "        limit=13, \n",
    "        fields=[\"vector\", \"id\", \"text\"]\n",
    "    )\n",
    ")\n",
    "for row in result.rows():\n",
    "    print(\"Found answer: \" + row.id + \"; score: \" + str(row.score))\n",
    "    doc = collection.get(row.id)\n",
    "    print(\"Answer text: \" + doc.value[\"text\"])\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
