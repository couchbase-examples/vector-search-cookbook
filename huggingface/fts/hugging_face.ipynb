{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c60986a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this guide, we will walk you through building a powerful semantic search engine using Couchbase as the backend database, [Hugging Face](https://huggingface.co/) as the AI-powered embedding Model. Semantic search goes beyond simple keyword matching by understanding the context and meaning behind the words in a query, making it an essential tool for applications that require intelligent information retrieval. This tutorial is designed to be beginner-friendly, with clear, step-by-step instructions that will equip you with the knowledge to create a fully functional semantic search system from scratch. Alternatively, if you want to perform semantic search using the GSI index, please take a look at [this.](https://developer.couchbase.com//tutorial-huggingface-couchbase-vector-search-with-global-secondary-index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6178e6b3",
   "metadata": {},
   "source": [
    "# How to run this tutorial\n",
    "\n",
    "This tutorial is available as a Jupyter Notebook (`.ipynb` file) that you can run interactively. You can access the original notebook [here](https://github.com/couchbase-examples/vector-search-cookbook/blob/main/huggingface/hugging_face.ipynb).\n",
    "\n",
    "You can either download the notebook file and run it on [Google Colab](https://colab.research.google.com/) or run it on your system by setting up the Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef73d80c",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "\n",
    "## Create and Deploy Your Free Tier Operational cluster on Capella\n",
    "\n",
    "To get started with Couchbase Capella, create an account and use it to deploy a forever free tier operational cluster. This account provides you with a environment where you can explore and learn about Capella with no time constraint.\n",
    "\n",
    "To know more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).\n",
    "\n",
    "### Couchbase Capella Configuration\n",
    "\n",
    "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met.\n",
    "\n",
    "* Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the travel-sample bucket (Read and Write) used in the application.\n",
    "* [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77308721",
   "metadata": {},
   "source": [
    "# Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208a54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --quiet install couchbase==4.4.0 transformers==4.56.1 sentence_transformers==5.1.0 langchain-community==0.3.29 langchain_huggingface==0.3.1 python-dotenv==1.1.1 ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9470f9e3-311b-45c8-81c3-baa5fe0995d2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd83070-32d7-4b22-9a7b-25b5c7e4d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "from transformers import pipeline, AutoModel, AutoTokenizer\n",
    "from langchain_huggingface.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.options import (ClusterOptions, ClusterTimeoutOptions,\n",
    "                               QueryOptions)\n",
    "import couchbase.search as search\n",
    "from couchbase.options import SearchOptions\n",
    "from couchbase.vector_search import VectorQuery, VectorSearch\n",
    "import uuid\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import getpass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a3edf-f5f7-43e1-99b9-b775e94fbfe6",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "In order to run this tutorial, you will need access to a Couchbase Cluster with Full Text Search service either through Couchbase Capella or by running it locally and have credentials to acces a collection on that cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56551dec-1029-4951-83f9-7899ee4cc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(\"./.env\")\n",
    "\n",
    "# Configuration\n",
    "couchbase_cluster_url = os.getenv('CB_CLUSTER_URL') or input(\"Couchbase Cluster URL:\")\n",
    "couchbase_username = os.getenv('CB_USERNAME') or input(\"Couchbase Username:\")\n",
    "couchbase_password = os.getenv('CB_PASSWORD') or getpass.getpass(\"Couchbase password:\")\n",
    "couchbase_bucket = os.getenv('CB_BUCKET') or input(\"Couchbase Bucket:\")\n",
    "couchbase_scope = os.getenv('CB_SCOPE') or input(\"Couchbase Scope:\")\n",
    "couchbase_collection = os.getenv('CB_COLLECTION') or input(\"Couchbase Collection:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15edfec2-64bd-4ba1-b072-4fadacddb01a",
   "metadata": {},
   "source": [
    "# Couchbase Connection\n",
    "In this section, we first need to create a `PasswordAuthenticator` object that would hold our Couchbase credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae34ded-a52e-45bd-9712-c3bb5ea4f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = PasswordAuthenticator(\n",
    "    couchbase_username,\n",
    "    couchbase_password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b07864-1b17-4a6c-9127-3f74ab1117c3",
   "metadata": {},
   "source": [
    "Then, we use this object to connect to Couchbase Cluster and select specified above bucket, scope and collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea57ff8-2556-46d3-9211-3803420d93ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to cluster\n",
      "Connected to the cluster\n"
     ]
    }
   ],
   "source": [
    "print(\"Connecting to cluster\")\n",
    "cluster = Cluster(couchbase_cluster_url, ClusterOptions(auth))\n",
    "cluster.wait_until_ready(timedelta(seconds=5))\n",
    "\n",
    "bucket = cluster.bucket(couchbase_bucket)\n",
    "scope = bucket.scope(couchbase_scope)\n",
    "collection = scope.collection(couchbase_collection)\n",
    "print(\"Connected to the cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625881d5-39e2-44ed-bbca-0db67e98f765",
   "metadata": {},
   "source": [
    "# Creating Couchbase Vector Search Index\n",
    "In order to store generated with Hugging Face embeddings onto a Couchbase Cluster, a vector search index needs to be created first. We included a sample index definition that will work with this tutorial in a file named `huggingface_index.json` located in the folder with this tutorial. The definition can be used to create a vector index using Couchbase server web console, on more information on vector indexes, please read [Create a Vector Search Index with the Server Web Console](https://docs.couchbase.com/server/current/vector-search/create-vector-search-index-ui.html). Please note that the index is configured for documents from bucket `hugginface`, scope `_default` and collection `huggingface` and you will have to edit `source` and document type name in the index definition file if your collection, scope or bucket names are different.\n",
    "\n",
    "Here, our code verifies the existence of the index and will throw an exception if the index has not been found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66753ba-22d4-4eaf-8275-ffd9fd53b2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found index: huggingface._default.vector_test\n"
     ]
    }
   ],
   "source": [
    "search_index_name = couchbase_bucket + \"._default.vector_test\"\n",
    "search_index = cluster.search_indexes().get_index(search_index_name)\n",
    "print(\"Found index: \" + search_index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a7207-54d1-44fd-aa9d-d361b42d2c96",
   "metadata": {},
   "source": [
    "# Hugging Face Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14fe91cb-41a5-4e71-ac5a-3a8070f21e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized successfully\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings()\n",
    "print(\"Initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d8e261-d670-4c40-8037-3d4e3084c360",
   "metadata": {},
   "source": [
    "# Embedding Documents\n",
    "After initializing Hugging Face transformers library, it can be used to generate vector embeddings for user input or predefined set of phrases. Here, we're generating 2 embeddings for contained in the array strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe90414b-2611-4c99-9dfc-c0d634eb2af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Couchbase Server is a multipurpose, distributed database that fuses the strengths of relational databases such as SQL and ACID transactions with JSON’s versatility, with a foundation that is extremely fast and scalable.\",\n",
    "    \"It’s used across industries for things like user profiles, dynamic product catalogs, GenAI apps, vector search, high-speed caching, and much more.\",\n",
    "    input(\"Enter custom embedding text:\")\n",
    "]\n",
    "embeddings = []\n",
    "for i in range(0, len(texts)):\n",
    "    embeddings.append(embedding_model.embed_query(texts[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80814e90-699f-4201-8cd3-7ef8adab9966",
   "metadata": {},
   "source": [
    "# Storing Embeddings in Couchbase\n",
    "Generated embeddings are then stored as vector fields inside documents that can contain additional information about the vector, including the original text. The documents are then upserted onto the couchbase cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f779554-b197-4fcb-8ca1-09d55dab149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(texts)):\n",
    "    doc = {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"text\": texts[i],\n",
    "        \"vector\": embeddings[i],\n",
    "    }\n",
    "    collection.upsert(doc[\"id\"], doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a0d98-bcf5-4fe4-b602-6e8a23edf95e",
   "metadata": {},
   "source": [
    "# Searching For Embeddings\n",
    "After the documents are upserted onto the cluster, their vector fields will be added into previously imported vector index. Later, new embeddings can be added or used to perform a similarity search on the previously added documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7e8283c-73ff-452e-98ee-e89fa992371e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity search for phrase: \"name a multipurpose database with distributed capability\"\n",
      "Found answer: 3993ec2e-c184-4d7f-8fc3-55961afe264c; score: 0.9256534967756203\n",
      "Answer text: Couchbase Server is a multipurpose, distributed database that fuses the strengths of relational databases such as SQL and ACID transactions with JSON’s versatility, with a foundation that is extremely fast and scalable.\n",
      "------\n",
      "Vector similarity search for phrase: \"What is the data in the sample text?\"\n",
      "Found answer: a7748fac-b41f-4846-bebc-d89bdcd645e3; score: 1.0016003788325407\n",
      "Answer text: this is a sample text with the data \"Qwerty\"\n"
     ]
    }
   ],
   "source": [
    "def search_similar(text):\n",
    "    print(\"Vector similarity search for phrase: \\\"\" + text + \"\\\"\")\n",
    "    search_embedding = embedding_model.embed_query(text)\n",
    "    \n",
    "    search_req = search.SearchRequest.create(search.MatchNoneQuery()).with_vector_search(\n",
    "        VectorSearch.from_vector_query(\n",
    "            VectorQuery(\n",
    "                \"vector\", search_embedding, num_candidates=1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    result = scope.search(\n",
    "        \"vector_test\", \n",
    "        search_req, \n",
    "        SearchOptions(\n",
    "            limit=13, \n",
    "            fields=[\"vector\", \"id\", \"text\"]\n",
    "        )\n",
    "    )\n",
    "    for row in result.rows():\n",
    "        print(\"Found answer: \" + row.id + \"; score: \" + str(row.score))\n",
    "        doc = collection.get(row.id)\n",
    "        print(\"Answer text: \" + doc.value[\"text\"])\n",
    "        \n",
    "search_similar(\"name a multipurpose database with distributed capability\")\n",
    "print(\"------\")\n",
    "search_similar(input(\"Enter custom search phrase:\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
