{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYUkZqeoEykk",
        "outputId": "dc7c8f75-be6a-4ac7-8094-71a78a26a0ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: couchbase in /usr/local/lib/python3.10/dist-packages (4.3.0)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (5.6.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.10/dist-packages (0.2.28)\n",
            "Requirement already satisfied: langchain_couchbase in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.20)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (2024.5.0)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.34.154)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.5)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.27.0)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.8.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.0.20240712)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (0.1.98)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (8.5.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.39.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.154 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere) (1.34.154)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere) (0.10.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (3.10.6)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (2.20.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.7.24)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install python-dotenv\n",
        "!pip install python-dotenv couchbase cohere datasets langchain_core langchain_couchbase langchain_openai pyarrow requests fsspec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRnVLPc8FRAL",
        "outputId": "ebf94ae2-16c4-4a00-bbc9-fee078d756d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw3IL3GEJSj7"
      },
      "source": [
        "# Importing Necessary Libraries\n",
        "This block imports all the required libraries and modules used in the notebook. These include libraries for environment management, data handling, natural language processing, interaction with Couchbase, and embeddings generation. Each library serves a specific function, such as managing environment variables, handling datasets, or interacting with the Couchbase database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oziN03NZJLQw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "from datetime import timedelta\n",
        "\n",
        "import numpy as np\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.exceptions import CouchbaseException\n",
        "from couchbase.options import ClusterOptions\n",
        "from datasets import load_dataset\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.globals import set_llm_cache\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_couchbase.cache import CouchbaseCache\n",
        "from langchain_couchbase.vectorstores import CouchbaseVectorStore\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "import cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOwSwRoHJLXv"
      },
      "source": [
        "# Loading Environment Variables\n",
        "The purpose of this block is to load environment variables from a .env file, which is a common practice for securely handling sensitive information like API keys and database credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2H9xphrJLbP",
        "outputId": "858f3f32-00c3-4c96-ca45-094f8c7fbd61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmBKUwAjJLej"
      },
      "source": [
        "# Get Environment Variables\n",
        "This function is designed to retrieve environment variables. If the variable is not set, it either returns a default value or raises an error. This ensures that all necessary configurations are available before proceeding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ym0gbMvpJLiU"
      },
      "outputs": [],
      "source": [
        "def get_env_variable(var_name, default_value=None):\n",
        "    value = os.getenv(var_name)\n",
        "    if value is None:\n",
        "        if default_value is not None:\n",
        "            warnings.warn(f\"Environment variable {var_name} is missing. Assigning default value: {default_value}\")\n",
        "            return default_value\n",
        "        else:\n",
        "            raise ValueError(f\"Environment variable {var_name} is missing and no default value is provided.\")\n",
        "    return value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdKdLg9pJLl5"
      },
      "source": [
        "# Connect to Couchbase\n",
        "This function establishes a connection to a Couchbase cluster using the provided credentials. It uses the PasswordAuthenticator to authenticate the connection and waits until the cluster is ready."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HubiGMCSJLqw"
      },
      "outputs": [],
      "source": [
        "def connect_to_couchbase(connection_string, db_username, db_password):\n",
        "    \"\"\"Connect to Couchbase\"\"\"\n",
        "    auth = PasswordAuthenticator(db_username, db_password)\n",
        "    options = ClusterOptions(auth)\n",
        "    cluster = Cluster(connection_string, options)\n",
        "    cluster.wait_until_ready(timedelta(seconds=5))\n",
        "    return cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXGj5YokJLuU"
      },
      "source": [
        "#  Fetch The Couchbase Vector Store\n",
        "This function initializes and returns a CouchbaseVectorStore, which is used for storing and retrieving vectors (embeddings) in Couchbase. This is crucial for enabling vector-based operations like similarity search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VHeB_AVmLJlx"
      },
      "outputs": [],
      "source": [
        "def get_vector_store(cluster, db_bucket, db_scope, db_collection, embedding, index_name):\n",
        "    \"\"\"Return the Couchbase vector store\"\"\"\n",
        "    vector_store = CouchbaseVectorStore(\n",
        "        cluster=cluster,\n",
        "        bucket_name=db_bucket,\n",
        "        scope_name=db_scope,\n",
        "        collection_name=db_collection,\n",
        "        embedding=embedding,\n",
        "        index_name=index_name,\n",
        "    )\n",
        "    return vector_store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iar2fABrLJjK"
      },
      "source": [
        "# Cache the Results\n",
        "This function initializes and returns a CouchbaseCache, which is used for caching purposes within the application. The cache helps in reducing redundant computations and improves the performance of operations like search and retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cjASXR3dLJgZ"
      },
      "outputs": [],
      "source": [
        "def get_cache(cluster, db_bucket, db_scope, cache_collection):\n",
        "    \"\"\"Return the Couchbase cache\"\"\"\n",
        "    cache = CouchbaseCache(\n",
        "        cluster=cluster,\n",
        "        bucket_name=db_bucket,\n",
        "        scope_name=db_scope,\n",
        "        collection_name=cache_collection,\n",
        "    )\n",
        "    return cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdmbxLdCLJdl"
      },
      "source": [
        "# Save the embeddings to Vector Store\n",
        "This function takes in texts and their corresponding embeddings, converts them into Document objects, and stores them in the Couchbase vector store. This is a key step for making the data searchable via semantic search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HrJbgaKRLJbS"
      },
      "outputs": [],
      "source": [
        "def save_to_vector_store(vector_store, texts, embeddings):\n",
        "    \"\"\"Store the documents in the vector store\"\"\"\n",
        "    documents = [\n",
        "        Document(page_content=text, metadata={'embedding': embed})\n",
        "        for embed, text in zip(embeddings, texts)\n",
        "    ]\n",
        "    vector_store.add_documents(documents)\n",
        "    print(f\"Stored {len(documents)} documents in Couchbase\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToQ2acrSLJY7"
      },
      "source": [
        "# Semantic Search\n",
        "This function performs a semantic search on the vector store using a query. It generates an embedding for the query using the Cohere API, and then retrieves the most similar documents from the Couchbase vector store based on this embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qZDXvq88LJWH"
      },
      "outputs": [],
      "source": [
        "def semantic_search(vector_store, query, co, top_k=10):\n",
        "    \"\"\"Perform semantic search\"\"\"\n",
        "    try:\n",
        "        query_embed = co.embed(texts=[query], model='small', truncate='LEFT').embeddings[0]\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating query embedding: {e}\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        search_results = vector_store.similarity_search_by_vector(embedding=query_embed, k=top_k)\n",
        "\n",
        "        results = [{'id': doc.metadata['id'], 'text': doc.page_content, 'distance': score}\n",
        "                   for doc, score in search_results]\n",
        "        return results\n",
        "    except CouchbaseException as e:\n",
        "        print(f\"Error performing semantic search: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQpib0zKLJTh"
      },
      "source": [
        "# Main Function\n",
        "The main function orchestrates the entire process. It initializes the necessary components like the Cohere client, Couchbase connection, and vector store, loads a dataset, generates embeddings, stores them in Couchbase, sets up the cache, and finally performs a semantic search with the RAG chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7eV1X5xILJRC"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # Get environment variables or use default values\n",
        "    COHERE_API_KEY = get_env_variable('COHERE_API_KEY')  # No default for COHERE_API_KEY, must be provided\n",
        "    OPENAI_API_KEY = get_env_variable(\"OPENAI_API_KEY\")\n",
        "    CB_USERNAME = get_env_variable('CB_USERNAME', 'default-username')\n",
        "    CB_PASSWORD = get_env_variable('CB_PASSWORD', 'default-password')\n",
        "    CB_BUCKET_NAME = get_env_variable('CB_BUCKET_NAME', 'default-bucket-name')\n",
        "    CB_HOST = get_env_variable('CB_HOST', 'couchbase://localhost')\n",
        "    INDEX_NAME = get_env_variable('INDEX_NAME', 'default-index-name')\n",
        "    CACHE_COLLECTION = get_env_variable('CACHE_COLLECTION', 'default-cache-collection')\n",
        "\n",
        "    # Initialize Cohere client\n",
        "    try:\n",
        "        co = cohere.Client(COHERE_API_KEY)\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Cohere client: {e}\")\n",
        "        return\n",
        "\n",
        "    # Load the TREC dataset\n",
        "    try:\n",
        "        trec = load_dataset('trec', split='train[:1000]')\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading TREC dataset: {e}\")\n",
        "        return\n",
        "\n",
        "    # Create embeddings\n",
        "    try:\n",
        "        embeds = co.embed(texts=trec['text'], model='small', truncate='LEFT').embeddings\n",
        "        print(f\"Embedding shape: {np.array(embeds).shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating embeddings: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Connect to Couchbase\n",
        "        cluster = connect_to_couchbase(CB_HOST, CB_USERNAME, CB_PASSWORD)\n",
        "        bucket = cluster.bucket(CB_BUCKET_NAME)\n",
        "        scope = bucket.scope(\"shared\")\n",
        "\n",
        "        # Use OpenAIEmbeddings as a fallback for compatibility\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "\n",
        "        # Initialize CouchbaseVectorStore\n",
        "        vector_store = get_vector_store(cluster, CB_BUCKET_NAME, \"shared\", \"docs\", embeddings, INDEX_NAME)\n",
        "\n",
        "        # Store embeddings and metadata in Couchbase\n",
        "        save_to_vector_store(vector_store, trec['text'], embeds)\n",
        "\n",
        "        # Set the LLM cache\n",
        "        cache = get_cache(cluster, CB_BUCKET_NAME, \"shared\", CACHE_COLLECTION)\n",
        "        set_llm_cache(cache)\n",
        "\n",
        "        # Build the prompt for the RAG\n",
        "        template = \"\"\"You are a helpful bot. If you cannot answer based on the context provided, respond with a generic answer. Answer the question as truthfully as possible using the context below:\n",
        "        {context}\n",
        "\n",
        "        Question: {question}\"\"\"\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "        # Use OpenAI GPT-4 as the LLM for the RAG\n",
        "        llm = ChatOpenAI(temperature=0, model=\"gpt-4-1106-preview\", streaming=True)\n",
        "\n",
        "        # RAG chain\n",
        "        chain = (\n",
        "            {\"context\": vector_store.as_retriever(), \"question\": RunnablePassthrough()}\n",
        "            | prompt\n",
        "            | llm\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "\n",
        "        # Pure OpenAI output without RAG\n",
        "        template_without_rag = \"\"\"You are a helpful bot. Answer the question as truthfully as possible.\n",
        "\n",
        "        Question: {question}\"\"\"\n",
        "\n",
        "        prompt_without_rag = ChatPromptTemplate.from_template(template_without_rag)\n",
        "        llm_without_rag = ChatOpenAI(model=\"gpt-4-1106-preview\", streaming=True)\n",
        "\n",
        "        chain_without_rag = (\n",
        "            {\"question\": RunnablePassthrough()}\n",
        "            | prompt_without_rag\n",
        "            | llm_without_rag\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "\n",
        "        # Sample query for testing\n",
        "        query = \"What caused the 1929 Great Depression?\"\n",
        "        results = semantic_search(vector_store, query, co)\n",
        "\n",
        "        for result in results:\n",
        "            print(f\"Distance: {result['distance']:.4f}, Text: {result['text']}\")\n",
        "\n",
        "        # Get the response from the RAG\n",
        "        rag_response = chain.invoke(query)\n",
        "        print(f\"RAG Response: {rag_response}\")\n",
        "\n",
        "        # Get the response from the pure LLM\n",
        "        pure_llm_response = chain_without_rag.invoke(query)\n",
        "        print(f\"Pure LLM Response: {pure_llm_response}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt44X6-bLJOb"
      },
      "source": [
        "# Running the Main Function\n",
        "This block ensures that the main function is executed when the script is run directly. It acts as the entry point for the program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cGJfwS2LI_O",
        "outputId": "b75d330f-132d-43d0-bb91-b41a94e6f704"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-93180e975f1b>:5: UserWarning: Environment variable CACHE_COLLECTION is missing. Assigning default value: default-cache-collection\n",
            "  warnings.warn(f\"Environment variable {var_name} is missing. Assigning default value: {default_value}\")\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding shape: (1000, 1024)\n",
            "Stored 1000 documents in Couchbase\n",
            "RAG Response: The 1929 Great Depression was caused by a combination of factors, including:\n",
            "\n",
            "1. Stock Market Crash of 1929: A significant contributing factor was the stock market crash in October 1929, which wiped out millions of investors and led to a loss of confidence in the economy.\n",
            "\n",
            "2. Bank Failures: Following the crash, many banks experienced runs and ultimately failed, leading to a reduction in the money supply and a decrease in consumer spending and investment.\n",
            "\n",
            "3. Reduction in Purchasing Across the Board: As banks failed and the stock market crashed, consumers and businesses cut back on spending, leading to a decrease in production and an increase in unemployment.\n",
            "\n",
            "4. Overproduction: Industries such as agriculture and manufacturing were producing more goods than could be consumed, leading to falling prices and profits, which in turn led to layoffs and further reductions in consumer spending.\n",
            "\n",
            "5. High Tariffs and War Debts: The introduction of high tariffs, such as the Smoot-Hawley Tariff in 1930, restricted trade and worsened the global economic situation. Additionally, war debts from World War I limited European countries' ability to purchase American goods.\n",
            "\n",
            "6. Drought Conditions: Severe drought conditions, particularly in the agricultural heartland of the United States, exacerbated the economic downturn and led to further reductions in farm income.\n",
            "\n",
            "These factors, among others, interacted to create a downward economic spiral that resulted in the Great Depression, which lasted throughout the 1930s until the onset of World War II, which helped to stimulate economic activity and employment.\n",
            "Pure LLM Response: The Great Depression, which began in 1929 and lasted throughout the 1930s, was a severe worldwide economic downturn. Multiple factors contributed to its onset, and economists have debated the relative importance of each. Some of the key factors that caused or exacerbated the Great Depression include:\n",
            "\n",
            "1. Stock Market Crash of 1929: The immediate catalyst for the Great Depression was the stock market crash in October 1929. As stock prices plummeted, panic selling ensued and the market collapsed. Millions of shares became worthless, and those who had borrowed money to buy stocks were left with huge debts.\n",
            "\n",
            "2. Bank Failures: Following the stock market crash, many banks experienced runs by depositors and subsequently failed. The failure of banks not only wiped out savings but also reduced the availability of credit, which was crucial for businesses to fund operations and for consumers to make purchases.\n",
            "\n",
            "3. Reduction in Purchasing Across the Board: As banks failed and the stock market crashed, consumer confidence plummeted. People began to reduce their expenditures, leading to a decrease in the demand for goods. This, in turn, caused businesses to cut back on production, leading to layoffs and further decreases in consumer spending.\n",
            "\n",
            "4. American Economic Policy with Europe: The United States had lent substantial amounts of money to European countries during World War I. When the U.S. stock market crashed, it affected the European economy as well. Moreover, policies like the Smoot-Hawley Tariff Act of 1930 erected trade barriers that stifled international trade and made the economic situation worse.\n",
            "\n",
            "5. Drought Conditions: Known as the Dust Bowl, severe drought and bad farming practices led to a failure in the wheat crop, among others. This added to the distress of the agricultural sector, which had already been suffering from low prices due to overproduction, further exacerbating the economic downturn.\n",
            "\n",
            "6. Credit Structure of the Economy: The economic growth of the 1920s had been built on a large amount of credit. Many consumers and businesses had taken on substantial debt, and when income and revenue fell during the Depression, they found themselves unable to maintain their debt payments.\n",
            "\n",
            "7. Overproduction: There was an overproduction of goods that led to falling prices and unsold stock, which hurt businesses and led to further reductions in workforce and wages.\n",
            "\n",
            "8. Lack of Government Intervention: Initially, the government response was limited. The Hoover administration's policies were largely unable to stem the economic decline, partially because the government did not intervene aggressively in the economy as it would in later downturns.\n",
            "\n",
            "9. Psychological Factors: The Great Depression was further deepened by the psychological impact on the American public. Fear and pessimism led to decreased consumer spending and business investment, which slowed down economic recovery.\n",
            "\n",
            "The Great Depression was a complex event with numerous interconnected causes. It led to significant changes in economic policy and financial regulation, including the establishment of the Federal Deposit Insurance Corporation (FDIC) and the Securities and Exchange Commission (SEC), as well as the implementation of the New Deal by President Franklin D. Roosevelt, which aimed at providing relief, recovery, and reform to the American economy.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wQ0fNbphbWpu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
