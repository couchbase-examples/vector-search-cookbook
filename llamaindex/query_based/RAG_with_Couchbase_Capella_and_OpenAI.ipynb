{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this guide, we will walk you through building a Retrieval Augmented Generation (RAG) application using Couchbase Capella as the database, [gpt-4o](https://platform.openai.com/docs/models/gpt-4o) model as the large language model provided by OpenAI. We will use the [text-embedding-3-large](https://platform.openai.com/docs/guides/embeddings/embedding-models) model for generating embeddings.\n",
    "\n",
    "This notebook demonstrates how to build a RAG system using:\n",
    "- The [BBC News dataset](https://huggingface.co/datasets/RealTimeData/bbc_news_alltime) containing news articles\n",
    "- Couchbase Capella as the vector store with Hyperscale and Composite Vector Indexes for vector search\n",
    "- LlamaIndex framework for the RAG pipeline\n",
    "- OpenAI for embeddings and text generation\n",
    "\n",
    "Couchbase offers two types of vector indexes for high-performance vector search:\n",
    "\n",
    "**Hyperscale Vector Indexes**: Best for pure vector searches - content discovery, recommendations, semantic search. Designed to scale to billions of vectors with low memory footprint and optimized for concurrent operations.\n",
    "\n",
    "**Composite Vector Indexes**: Best for filtered vector searches - combines vector search with scalar value filtering. Efficient pre-filtering allows scalar attributes to reduce the vector comparison scope.\n",
    "\n",
    "For more details, see the [Couchbase Vector Index documentation](https://docs.couchbase.com/cloud/vector-index/use-vector-indexes.html).\n",
    "\n",
    "Semantic search goes beyond simple keyword matching by understanding the context and meaning behind the words in a query, making it an essential tool for applications that require intelligent information retrieval. This tutorial will equip you with the knowledge to create a fully functional RAG system using OpenAI Services and LlamaIndex with Couchbase's Hyperscale and Composite Vector Indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "### Create and Deploy Your Operational cluster on Capella\n",
    "\n",
    "To get started with Couchbase Capella, create an account and use it to deploy an operational cluster.\n",
    "\n",
    "To know more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Couchbase Capella Configuration\n",
    "\n",
    "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met:\n",
    "\n",
    "* Have a multi-node Capella cluster running the Data, Query, Index, and Search services.\n",
    "* Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the bucket (Read and Write) used in the application.\n",
    "* [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running.\n",
    "\n",
    "### OpenAI Models Setup\n",
    "\n",
    "In order to create the RAG application, we need an embedding model to ingest the documents for Vector Search and a large language model (LLM) for generating the responses based on the context. \n",
    "\n",
    "For this implementation, we'll use OpenAI's models which provide state-of-the-art performance for both embeddings and text generation:\n",
    "\n",
    "**Embedding Model**: We'll use OpenAI's `text-embedding-3-large` model, which provides high-quality embeddings with 3,072 dimensions for semantic search capabilities.\n",
    "\n",
    "**Large Language Model**: We'll use OpenAI's `gpt-4o` model for generating responses based on the retrieved context. This model offers excellent reasoning capabilities and can handle complex queries effectively.\n",
    "\n",
    "**Prerequisites for OpenAI Integration**:\n",
    "* Create an OpenAI account at [platform.openai.com](https://platform.openai.com)\n",
    "* Generate an API key from your OpenAI dashboard\n",
    "* Ensure you have sufficient credits or a valid payment method set up\n",
    "* Set up your API key as an environment variable or input it securely in the notebook\n",
    "\n",
    "For more details about OpenAI's models and pricing, please refer to the [OpenAI documentation](https://platform.openai.com/docs/models).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Necessary Libraries\n",
    "To build our RAG system, we need a set of libraries. The libraries we install handle everything from connecting to databases to performing AI tasks. Each library has a specific role: Couchbase libraries manage database operations, LlamaIndex handles AI model integrations, and we will use the OpenAI SDK for generating embeddings and calling OpenAI's language models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install --no-user --quiet datasets==3.6.0 llama-index==0.14.13 llama-index-vector-stores-couchbase==0.6.0 llama-index-embeddings-openai==0.5.1 llama-index-llms-openai==0.6.18 python-dotenv==1.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "The script starts by importing a series of libraries required for various tasks, including handling JSON, logging, time tracking, Couchbase connections, embedding generation, and dataset loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaustavghosh/Desktop/vector-search-cookbook/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import hashlib\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.exceptions import CouchbaseException\n",
    "from couchbase.management.buckets import CreateBucketSettings\n",
    "from couchbase.options import ClusterOptions, KnownConfigProfiles, QueryOptions\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from llama_index.core import Settings, Document, VectorStoreIndex\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from llama_index.vector_stores.couchbase import CouchbaseQueryVectorStore, QueryVectorSearchSimilarity, QueryVectorSearchType\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Sensitive Information\n",
    "In this section, we prompt the user to input essential configuration settings needed. These settings include sensitive information like database credentials, collection names, and API keys. Instead of hardcoding these details into the script, we request the user to provide them at runtime, ensuring flexibility and security.\n",
    "\n",
    "The script also validates that all required inputs are provided, raising an error if any crucial information is missing. This approach ensures that your integration is both secure and correctly configured without hardcoding sensitive information, enhancing the overall security and maintainability of your code.\n",
    "\n",
    "**OPENAI_API_KEY** is your OpenAI API key which can be obtained from your OpenAI dashboard at [platform.openai.com](https://platform.openai.com/api-keys).\n",
    "\n",
    "**INDEX_NAME** is the name of the vector index we will create for vector search operations using Hyperscale or Composite Vector Indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or getpass.getpass('Enter your OpenAI API key: ')\n",
    "CB_HOST = os.getenv('CB_HOST', 'couchbase://localhost') or input('Enter Couchbase host (default: couchbase://localhost): ') or 'couchbase://localhost'\n",
    "CB_USERNAME = os.getenv('CB_USERNAME', 'Administrator') or input('Enter Couchbase username (default: Administrator): ') or 'Administrator'\n",
    "CB_PASSWORD = os.getenv('CB_PASSWORD', 'password') or getpass.getpass('Enter Couchbase password (default: password): ') or 'password'\n",
    "CB_BUCKET_NAME = os.getenv('CB_BUCKET_NAME', 'vector-search-testing') or input('Enter Couchbase bucket name: ')\n",
    "SCOPE_NAME = os.getenv('SCOPE_NAME', 'shared') or input('Enter scope name: ')\n",
    "COLLECTION_NAME = os.getenv('COLLECTION_NAME', 'llamaindex') or input('Enter collection name: ')\n",
    "INDEX_NAME = os.getenv('INDEX_NAME', 'vector_search_llamaindex') or input('Enter index name: ')\n",
    "\n",
    "if not all([OPENAI_API_KEY, CB_HOST, CB_USERNAME, CB_PASSWORD, CB_BUCKET_NAME, SCOPE_NAME, COLLECTION_NAME, INDEX_NAME]):\n",
    "    raise ValueError(\"All configuration variables must be provided.\")\n",
    "\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Logging\n",
    "Logging is essential for tracking the execution of our script and debugging any issues that may arise. We set up a logger that will display information about the script's progress, including timestamps and log levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Couchbase Capella\n",
    "The next step is to establish a connection to our Couchbase Capella cluster. This connection will allow us to interact with the database, store and retrieve documents, and perform vector searches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-10 14:45:22,139 - INFO - Successfully connected to the Couchbase cluster\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize the Couchbase Cluster\n",
    "    auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
    "    options = ClusterOptions(auth)\n",
    "    options.apply_profile(KnownConfigProfiles.WanDevelopment)\n",
    "    # Connect to the cluster\n",
    "    cluster = Cluster(CB_HOST, options)\n",
    "    \n",
    "    # Wait for the cluster to be ready\n",
    "    cluster.wait_until_ready(timedelta(seconds=5))\n",
    "\n",
    "    logging.info(\"Successfully connected to the Couchbase cluster\")\n",
    "except CouchbaseException as e:\n",
    "    raise RuntimeError(f\"Failed to connect to Couchbase: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Bucket, Scope, and Collection\n",
    "Before we can store our data, we need to ensure that the appropriate bucket, scope, and collection exist in our Couchbase cluster. The code below checks if these components exist and creates them if they don't, providing a foundation for storing our vector embeddings and documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'vector-search-testing' already exists.\n",
      "Scope 'shared' already exists.\n",
      "Collection 'llamaindex' already exists in scope 'shared'.\n"
     ]
    }
   ],
   "source": [
    "# Create bucket if it does not exist\n",
    "bucket_manager = cluster.buckets()\n",
    "try:\n",
    "    bucket_manager.get_bucket(CB_BUCKET_NAME)\n",
    "    print(f\"Bucket '{CB_BUCKET_NAME}' already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Bucket '{CB_BUCKET_NAME}' does not exist. Creating bucket...\")\n",
    "    bucket_settings = CreateBucketSettings(name=CB_BUCKET_NAME, ram_quota_mb=500)\n",
    "    bucket_manager.create_bucket(bucket_settings)\n",
    "    print(f\"Bucket '{CB_BUCKET_NAME}' created successfully.\")\n",
    "\n",
    "# Create scope and collection if they do not exist\n",
    "collection_manager = cluster.bucket(CB_BUCKET_NAME).collections()\n",
    "scopes = collection_manager.get_all_scopes()\n",
    "scope_exists = any(scope.name == SCOPE_NAME for scope in scopes)\n",
    "\n",
    "if scope_exists:\n",
    "    print(f\"Scope '{SCOPE_NAME}' already exists.\")\n",
    "else:\n",
    "    print(f\"Scope '{SCOPE_NAME}' does not exist. Creating scope...\")\n",
    "    collection_manager.create_scope(SCOPE_NAME)\n",
    "    print(f\"Scope '{SCOPE_NAME}' created successfully.\")\n",
    "\n",
    "collections = [collection.name for scope in scopes if scope.name == SCOPE_NAME for collection in scope.collections]\n",
    "collection_exists = COLLECTION_NAME in collections\n",
    "\n",
    "if collection_exists:\n",
    "    print(f\"Collection '{COLLECTION_NAME}' already exists in scope '{SCOPE_NAME}'.\")\n",
    "else:\n",
    "    print(f\"Collection '{COLLECTION_NAME}' does not exist in scope '{SCOPE_NAME}'. Creating collection...\")\n",
    "    collection_manager.create_collection(collection_name=COLLECTION_NAME, scope_name=SCOPE_NAME)\n",
    "    print(f\"Collection '{COLLECTION_NAME}' created successfully.\")\n",
    "\n",
    "scope = cluster.bucket(CB_BUCKET_NAME).scope(SCOPE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Query-Based Vector Search\n",
    "In this section, we'll set up the Couchbase vector store using Couchbase Hyperscale and Composite Vector Index for high-performance vector search. Unlike FTS-based vector search, Hyperscale and Composite Vector Index search provides optimized performance for pure vector similarity operations and can scale to billions of vectors with low memory footprint.\n",
    "\n",
    "Hyperscale and Composite Vector Index search supports two main index types:\n",
    "- **Hyperscale Vector Indexes**: Best for pure vector searches with high performance and concurrent operations\n",
    "- **Composite Vector Indexes**: Best for filtered vector searches combining vector similarity with scalar filtering\n",
    "\n",
    "For this tutorial, we'll use the Query vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the BBC News Dataset\n",
    "To build a RAG engine, we need data to search through. We use the [BBC Realtime News dataset](https://huggingface.co/datasets/RealTimeData/bbc_news_alltime), a dataset with up-to-date BBC news articles grouped by month. This dataset contains articles that were created after the LLM was trained. It will showcase the use of RAG to augment the LLM. \n",
    "\n",
    "The BBC News dataset's varied content allows us to simulate real-world scenarios where users ask complex questions, enabling us to fine-tune our RAG's ability to understand and respond to various types of queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the BBC News dataset with 2687 rows\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    news_dataset = load_dataset('RealTimeData/bbc_news_alltime', '2024-12', split=\"train\")\n",
    "    print(f\"Loaded the BBC News dataset with {len(news_dataset)} rows\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading TREC dataset: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns: ['title', 'published_date', 'authors', 'description', 'section', 'content', 'link', 'top_image']\n",
      "\n",
      "First two examples:\n",
      "{'title': [\"Pakistan protest: Bushra Bibi's march for Imran Khan disappeared - BBC News\", 'Lockdown DIY linked to Walleys Quarry gases - BBC News'], 'published_date': ['2024-12-01', '2024-12-01'], 'authors': ['https://www.facebook.com/bbcnews', 'https://www.facebook.com/bbcnews'], 'description': [\"Imran Khan's third wife guided protesters to the heart of the capital - and then disappeared.\", 'An academic says an increase in plasterboard sent to landfill could be behind a spike in smells.'], 'section': ['Asia', 'Stoke & Staffordshire'], 'content': ['Bushra Bibi led a protest to free Imran Khan - what happened next is a mystery\\n\\nImran Khan\\'s wife, Bushra Bibi, encouraged protesters into the heart of Pakistan\\'s capital, Islamabad\\n\\nA charred lorry, empty tear gas shells and posters of former Pakistan Prime Minister Imran Khan - it was all that remained of a massive protest led by Khan’s wife, Bushra Bibi, that had sent the entire capital into lockdown. Just a day earlier, faith healer Bibi - wrapped in a white shawl, her face covered by a white veil - stood atop a shipping container on the edge of the city as thousands of her husband’s devoted followers waved flags and chanted slogans beneath her. It was the latest protest to flare since Khan, the 72-year-old cricketing icon-turned-politician, was jailed more than a year ago after falling foul of the country\\'s influential military which helped catapult him to power. “My children and my brothers! You have to stand with me,” Bibi cried on Tuesday afternoon, her voice cutting through the deafening roar of the crowd. “But even if you don’t,” she continued, “I will still stand firm. “This is not just about my husband. It is about this country and its leader.” It was, noted some watchers of Pakistani politics, her political debut. But as the sun rose on Wednesday morning, there was no sign of Bibi, nor the thousands of protesters who had marched through the country to the heart of the capital, demanding the release of their jailed leader. While other PMs have fallen out with Pakistan\\'s military in the past, Khan\\'s refusal to stay quiet behind bars is presenting an extraordinary challenge - escalating the standoff and leaving the country deeply divided. Exactly what happened to the so-called “final march”, and Bibi, when the city went dark is still unclear. All eyewitnesses like Samia* can say for certain is that the lights went out suddenly, plunging D Chowk, the square where they had gathered, into blackness.\\n\\nWithin a day of arriving, the protesters had scattered - leaving behind Bibi\\'s burnt-out vehicle\\n\\nAs loud screams and clouds of tear gas blanketed the square, Samia describes holding her husband on the pavement, bloodied from a gun shot to his shoulder. \"Everyone was running for their lives,\" she later told BBC Urdu from a hospital in Islamabad, adding it was \"like doomsday or a war\". \"His blood was on my hands and the screams were unending.” But how did the tide turn so suddenly and decisively? Just hours earlier, protesters finally reached D Chowk late afternoon on Tuesday. They had overcome days of tear gas shelling and a maze of barricaded roads to get to the city centre. Many of them were supporters and workers of the Pakistan Tehreek-e-Insaf (PTI), the party led by Khan. He had called for the march from his jail cell, where he has been for more than a year on charges he says are politically motivated. Now Bibi - his third wife, a woman who had been largely shrouded in mystery and out of public view since their unexpected wedding in 2018 - was leading the charge. “We won’t go back until we have Khan with us,” she declared as the march reached D Chowk, deep in the heart of Islamabad’s government district.\\n\\nThousands had marched for days to reach Islamabad, demanding former Prime Minister Imran Khan be released from jail\\n\\nInsiders say even the choice of destination - a place where her husband had once led a successful sit in - was Bibi’s, made in the face of other party leader’s opposition, and appeals from the government to choose another gathering point. Her being at the forefront may have come as a surprise. Bibi, only recently released from prison herself, is often described as private and apolitical. Little is known about her early life, apart from the fact she was a spiritual guide long before she met Khan. Her teachings, rooted in Sufi traditions, attracted many followers - including Khan himself. Was she making her move into politics - or was her sudden appearance in the thick of it a tactical move to keep Imran Khan’s party afloat while he remains behind bars? For critics, it was a move that clashed with Imran Khan’s oft-stated opposition to dynastic politics. There wasn’t long to mull the possibilities. After the lights went out, witnesses say that police started firing fresh rounds of tear gas at around 21:30 local time (16:30 GMT). The crackdown was in full swing just over an hour later. At some point, amid the chaos, Bushra Bibi left. Videos on social media appeared to show her switching cars and leaving the scene. The BBC couldn’t verify the footage. By the time the dust settled, her container had already been set on fire by unknown individuals. By 01:00 authorities said all the protesters had fled.\\n\\nSecurity was tight in the city, and as night fell, lights were switched off - leaving many in the dark as to what exactly happened next\\n\\nEyewitnesses have described scenes of chaos, with tear gas fired and police rounding up protesters. One, Amin Khan, said from behind an oxygen mask that he joined the march knowing that, \"either I will bring back Imran Khan or I will be shot\". The authorities have have denied firing at the protesters. They also said some of the protesters were carrying firearms. The BBC has seen hospital records recording patients with gunshot injuries. However, government spokesperson Attaullah Tarar told the BBC that hospitals had denied receiving or treating gunshot wound victims. He added that \"all security personnel deployed on the ground have been forbidden\" from having live ammunition during protests. But one doctor told BBC Urdu that he had never done so many surgeries for gunshot wounds in a single night. \"Some of the injured came in such critical condition that we had to start surgery right away instead of waiting for anaesthesia,\" he said. While there has been no official toll released, the BBC has confirmed with local hospitals that at least five people have died. Police say at least 500 protesters were arrested that night and are being held in police stations. The PTI claims some people are missing. And one person in particular hasn’t been seen in days: Bushra Bibi.\\n\\nThe next morning, the protesters were gone - leaving behind just wrecked cars and smashed glass\\n\\nOthers defended her. “It wasn’t her fault,” insisted another. “She was forced to leave by the party leaders.” Political commentators have been more scathing. “Her exit damaged her political career before it even started,” said Mehmal Sarfraz, a journalist and analyst. But was that even what she wanted? Khan has previously dismissed any thought his wife might have her own political ambitions - “she only conveys my messages,” he said in a statement attributed to him on his X account.\\n\\nImran Khan and Bushra Bibi, pictured here arriving at court in May 2023, married in 2018\\n\\nSpeaking to BBC Urdu, analyst Imtiaz Gul calls her participation “an extraordinary step in extraordinary circumstances\". Gul believes Bushra Bibi’s role today is only about “keeping the party and its workers active during Imran Khan’s absence”. It is a feeling echoed by some PTI members, who believe she is “stepping in only because Khan trusts her deeply”. Insiders, though, had often whispered that she was pulling the strings behind the scenes - advising her husband on political appointments and guiding high-stakes decisions during his tenure. A more direct intervention came for the first time earlier this month, when she urged a meeting of PTI leaders to back Khan’s call for a rally. Pakistan’s defence minister Khawaja Asif accused her of “opportunism”, claiming she sees “a future for herself as a political leader”. But Asma Faiz, an associate professor of political science at Lahore University of Management Sciences, suspects the PTI’s leadership may have simply underestimated Bibi. “It was assumed that there was an understanding that she is a non-political person, hence she will not be a threat,” she told the AFP news agency. “However, the events of the last few days have shown a different side of Bushra Bibi.” But it probably doesn’t matter what analysts and politicians think. Many PTI supporters still see her as their connection to Imran Khan. It was clear her presence was enough to electrify the base. “She is the one who truly wants to get him out,” says Asim Ali, a resident of Islamabad. “I trust her. Absolutely!”', 'Walleys Quarry was ordered not to accept any new waste as of Friday\\n\\nA chemist and former senior lecturer in environmental sustainability has said powerful odours from a controversial landfill site may be linked to people doing more DIY during the Covid-19 pandemic. Complaints about Walleys Quarry in Silverdale, Staffordshire – which was ordered to close as of Friday – increased significantly during and after coronavirus lockdowns. Issuing the closure notice, the Environment Agency described management of the site as poor, adding it had exhausted all other enforcement tactics at premises where gases had been noxious and periodically above emission level guidelines - which some campaigners linked to ill health locally. Dr Sharon George, who used to teach at Keele University, said she had been to the site with students and found it to be clean and well-managed, and suggested an increase in plasterboard heading to landfills in 2020 could be behind a spike in stenches.\\n\\n“One of the materials that is particularly bad for producing odours and awful emissions is plasterboard,\" she said. “That’s one of the theories behind why Walleys Quarry got worse at that time.” She said the landfill was in a low-lying area, and that some of the gases that came from the site were quite heavy. “They react with water in the atmosphere, so some of the gases you smell can be quite awful and not very good for our health. “It’s why, on some days when it’s colder and muggy and a bit misty, you can smell it more.” Dr George added: “With any landfill, you’re putting things into the ground – and when you put things into the ground, if they can they will start to rot. When they start to rot they’re going to give off gases.” She believed Walleys Quarry’s proximity to people’s homes was another major factor in the amount of complaints that arose from its operation. “If you’ve got a gas that people can smell, they’re going to report it much more than perhaps a pollutant that might go unnoticed.”\\n\\nRebecca Currie said she did not think the site would ever be closed\\n\\nLocal resident and campaigner Rebecca Currie said the closure notice served to Walleys Quarry was \"absolutely amazing\". Her son Matthew has had breathing difficulties after being born prematurely with chronic lung disease, and Ms Currie says the site has made his symptoms worse. “I never thought this day was going to happen,” she explained. “We fought and fought for years.” She told BBC Midlands Today: “Our community have suffered. We\\'ve got kids who are really poorly, people have moved homes.”\\n\\nComplaints about Walleys Quarry to Newcastle-under-Lyme Borough Council exceeded 700 in November, the highest amount since 2021 according to council leader Simon Tagg. The Environment Agency (EA), which is responsible for regulating landfill sites, said it had concluded further operation at the site could result in \"significant long-term pollution\". A spokesperson for Walley\\'s Quarry Ltd said the firm rejected the EA\\'s accusations of poor management, and would be challenging the closure notice. Dr George said she believed the EA was likely to be erring on the side of caution and public safety, adding safety standards were strict. She said a lack of landfill space in the country overall was one of the broader issues that needed addressing. “As people, we just keep using stuff and then have nowhere to put it, and then when we end up putting it in places like Walleys Quarry that is next to houses, I think that’s where the problems are.”\\n\\nTell us which stories we should cover in Staffordshire'], 'link': ['http://www.bbc.co.uk/news/articles/cvg02lvj1e7o', 'http://www.bbc.co.uk/news/articles/c5yg1v16nkpo'], 'top_image': ['https://ichef.bbci.co.uk/ace/standard/3840/cpsprodpb/9975/live/b22229e0-ad5a-11ef-83bc-1153ed943d1c.jpg', 'https://ichef.bbci.co.uk/ace/standard/3840/cpsprodpb/0896/live/55209f80-adb2-11ef-8f6c-f1a86bb055ec.jpg']}\n"
     ]
    }
   ],
   "source": [
    "# Print the first two examples from the dataset\n",
    "print(\"Dataset columns:\", news_dataset.column_names)\n",
    "print(\"\\nFirst two examples:\")\n",
    "print(news_dataset[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for RAG\n",
    "\n",
    "We need to extract the context passages from the dataset to use as our knowledge base for the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-10 14:45:26,118 - INFO - We have 1749 unique articles in our database.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    news_articles = news_dataset\n",
    "    unique_articles = {}\n",
    "\n",
    "    for article in news_articles:\n",
    "        content = article.get(\"content\")\n",
    "        if content:\n",
    "            content_hash = hashlib.md5(content.encode()).hexdigest()\n",
    "            if content_hash not in unique_articles:\n",
    "                unique_articles[content_hash] = article\n",
    "\n",
    "    unique_news_articles = list(unique_articles.values())\n",
    "\n",
    "    logging.info(f\"We have {len(unique_news_articles)} unique articles in our database.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to prepare data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Embeddings using OpenAI\n",
    "Embeddings are numerical representations of text that capture semantic meaning. Unlike keyword-based search, embeddings enable semantic search to understand context and retrieve documents that are conceptually similar even without exact keyword matches. We'll use OpenAI's `text-embedding-3-large` model to create high-quality embeddings with 3,072 dimensions. This model transforms our text data into vector representations that can be efficiently searched, with a batch size of 30 for optimal processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created embedding model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Set up the embedding model\n",
    "    embed_model = OpenAIEmbedding(\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        embed_batch_size=30,\n",
    "        model=\"text-embedding-3-large\"\n",
    "    )\n",
    "    \n",
    "    # Configure LlamaIndex to use this embedding model\n",
    "    Settings.embed_model = embed_model\n",
    "    print(\"Successfully created embedding model\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error creating embedding model: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Embeddings Model\n",
    "We can test the embeddings model by generating an embedding for a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-10 14:45:28,056 - INFO - Embedding dimension: 3072\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_embedding = embed_model.get_text_embedding(\"this is a test sentence\")\n",
    "    logging.info(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to generate test embedding: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Hyperscale and Composite Vector Search\n",
    "\n",
    "### Optimizing Vector Search with Hyperscale and Composite Vector Index\n",
    "\n",
    "With Couchbase 8.0+, you can leverage the power of query-based vector search, which offers significant performance improvements over traditional Full-Text Search (FTS) approaches for vector-first workloads. Hyperscale and Composite Vector Index search provides high-performance vector similarity search with advanced filtering capabilities and is designed to scale to billions of vectors.\n",
    "\n",
    "#### Hyperscale/Composite vs Search Vector Index: Choosing the Right Approach\n",
    "\n",
    "| Feature               | Hyperscale/Composite Vector Index                                               | Search Vector Index                         |\n",
    "| --------------------- | --------------------------------------------------------------- | ----------------------------------------- |\n",
    "| **Best For**          | Vector-first workloads, complex filtering, high QPS performance| Hybrid search and high recall rates      |\n",
    "| **Couchbase Version** | 8.0.0+                                                         | 7.6+                                      |\n",
    "| **Filtering**         | Pre-filtering with `WHERE` clauses (Composite) or post-filtering (Hyperscale) | Pre-filtering with flexible ordering |\n",
    "| **Scalability**       | Up to billions of vectors (Hyperscale)                              | Up to 10 million vectors                  |\n",
    "| **Performance**       | Optimized for concurrent operations with low memory footprint  | Good for mixed text and vector queries   |\n",
    "\n",
    "#### Query-Based Vector Index Types\n",
    "\n",
    "Couchbase offers two distinct query-based vector index types, each optimized for different use cases:\n",
    "\n",
    "##### Hyperscale Vector Indexes\n",
    "\n",
    "- **Best for**: Pure vector searches like content discovery, recommendations, and semantic search\n",
    "- **Use when**: You primarily perform vector-only queries without complex scalar filtering\n",
    "- **Features**: \n",
    "  - High performance with low memory footprint\n",
    "  - Optimized for concurrent operations\n",
    "  - Designed to scale to billions of vectors\n",
    "  - Supports post-scan filtering for basic metadata filtering\n",
    "\n",
    "##### Composite Vector Indexes\n",
    "\n",
    "- **Best for**: Filtered vector searches that combine vector similarity with scalar value filtering\n",
    "- **Use when**: Your queries combine vector similarity with scalar filters that eliminate large portions of data\n",
    "- **Features**: \n",
    "  - Efficient pre-filtering where scalar attributes reduce the vector comparison scope\n",
    "  - Best for well-defined workloads requiring complex filtering\n",
    "  - Supports range lookups combined with vector search\n",
    "\n",
    "#### Understanding Index Configuration\n",
    "\n",
    "The `index_description` parameter controls how Couchbase optimizes vector storage through centroids and quantization.\n",
    "\n",
    "##### Index Description Format: `'IVF[<centroids>],{PQ|SQ}<settings>'`\n",
    "\n",
    "**Centroids (IVF - Inverted File)**:\n",
    "- Controls how the dataset is subdivided for faster searches\n",
    "- More centroids = faster search, slower training\n",
    "- If omitted (like `IVF,SQ8`), Couchbase auto-selects based on dataset size\n",
    "\n",
    "**Quantization Options**:\n",
    "- **SQ (Scalar Quantization)**: SQ4, SQ6, SQ8 (4, 6, or 8 bits per dimension)\n",
    "- **PQ (Product Quantization)**: PQ<subquantizers>x<bits> (e.g., PQ32x8)\n",
    "\n",
    "For detailed configuration options, see the [Quantization & Centroid Settings](https://docs.couchbase.com/cloud/vector-index/hyperscale-vector-index.html#algo_settings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Couchbase Query Vector Store\n",
    "The query vector store is set up to store the documents from the dataset using Couchbase's query-based vector search capabilities. This vector store is optimized for high-performance vector similarity search operations and can scale to billions of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created vector store\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Create the Couchbase vector store\n",
    "    vector_store = CouchbaseQueryVectorStore(\n",
    "        cluster=cluster,\n",
    "        bucket_name=CB_BUCKET_NAME,\n",
    "        scope_name=SCOPE_NAME,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        search_type=QueryVectorSearchType.ANN,\n",
    "        similarity=QueryVectorSearchSimilarity.DOT,\n",
    "        nprobes=10\n",
    "    )\n",
    "    print(\"Successfully created vector store\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to create vector store: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating LlamaIndex Documents\n",
    "In this section, we'll process our news articles and create LlamaIndex Document objects.\n",
    "Each Document is created with specific metadata and formatting templates to control what the LLM and embedding model see.\n",
    "We'll observe examples of the formatted content to understand how the documents are structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LLM sees this:\n",
      "Metadata: \n",
      "title=>Pakistan protest: Bushra Bibi's march for Imran Khan disappeared - BBC News\n",
      "published_date=>2024-12-01\n",
      "link=>http://www.bbc.co.uk/news/articles/cvg02lvj1e7o\n",
      "-----\n",
      "Content: Bushra Bibi led a protest to free Imran Khan - what happened next is a mystery\n",
      "\n",
      "Imran Khan's wife, Bushra Bibi, encouraged protesters into the heart of Pakistan's capital, Islamabad\n",
      "\n",
      "A charred lorry, empty tear gas shells and posters of former Pakistan Prime Minister Imran Khan - it was all that remained of a massive protest led by Khan’s wife, Bushra Bibi, that had sent the entire capital into lockdown. Just a day earlier, faith healer Bibi - wrapped in a white shawl, her face covered by a white veil - stood atop a shipping container on the edge of the city as thousands of her husband’s devoted followers waved flags and chanted slogans beneath her. It was the latest protest to flare since Khan, the 72-year-old cricketing icon-turned-politician, was jailed more than a year ago after falling foul of the country's influential military which helped catapult him to power. “My children and my brothers! You have to stand with me,” Bibi cried on Tuesday afternoon, her voice cutting through the deafening roar of the crowd. “But even if you don’t,” she continued, “I will still stand firm. “This is not just about my husband. It is about this country and its leader.” It was, noted some watchers of Pakistani politics, her political debut. But as the sun rose on Wednesday morning, there was no sign of Bibi, nor the thousands of protesters who had marched through the country to the heart of the capital, demanding the release of their jailed leader. While other PMs have fallen out with Pakistan's military in the past, Khan's refusal to stay quiet behind bars is presenting an extraordinary challenge - escalating the standoff and leaving the country deeply divided. Exactly what happened to the so-called “final march”, and Bibi, when the city went dark is still unclear. All eyewitnesses like Samia* can say for certain is that the lights went out suddenly, plunging D Chowk, the square where they had gathered, into blackness.\n",
      "\n",
      "Within a day of arriving, the protesters had scattered - leaving behind Bibi's burnt-out vehicle\n",
      "\n",
      "As loud screams and clouds of tear gas blanketed the square, Samia describes holding her husband on the pavement, bloodied from a gun shot to his shoulder. \"Everyone was running for their lives,\" she later told BBC Urdu from a hospital in Islamabad, adding it was \"like doomsday or a war\". \"His blood was on my hands and the screams were unending.” But how did the tide turn so suddenly and decisively? Just hours earlier, protesters finally reached D Chowk late afternoon on Tuesday. They had overcome days of tear gas shelling and a maze of barricaded roads to get to the city centre. Many of them were supporters and workers of the Pakistan Tehreek-e-Insaf (PTI), the party led by Khan. He had called for the march from his jail cell, where he has been for more than a year on charges he says are politically motivated. Now Bibi - his third wife, a woman who had been largely shrouded in mystery and out of public view since their unexpected wedding in 2018 - was leading the charge. “We won’t go back until we have Khan with us,” she declared as the march reached D Chowk, deep in the heart of Islamabad’s government district.\n",
      "\n",
      "Thousands had marched for days to reach Islamabad, demanding former Prime Minister Imran Khan be released from jail\n",
      "\n",
      "Insiders say even the choice of destination - a place where her husband had once led a successful sit in - was Bibi’s, made in the face of other party leader’s opposition, and appeals from the government to choose another gathering point. Her being at the forefront may have come as a surprise. Bibi, only recently released from prison herself, is often described as private and apolitical. Little is known about her early life, apart from the fact she was a spiritual guide long before she met Khan. Her teachings, rooted in Sufi traditions, attracted many followers - including Khan himself. Was she making her move into politics - or was her sudden appearance in the thick of it a tactical move to keep Imran Khan’s party afloat while he remains behind bars? For critics, it was a move that clashed with Imran Khan’s oft-stated opposition to dynastic politics. There wasn’t long to mull the possibilities. After the lights went out, witnesses say that police started firing fresh rounds of tear gas at around 21:30 local time (16:30 GMT). The crackdown was in full swing just over an hour later. At some point, amid the chaos, Bushra Bibi left. Videos on social media appeared to show her switching cars and leaving the scene. The BBC couldn’t verify the footage. By the time the dust settled, her container had already been set on fire by unknown individuals. By 01:00 authorities said all the protesters had fled.\n",
      "\n",
      "Security was tight in the city, and as night fell, lights were switched off - leaving many in the dark as to what exactly happened next\n",
      "\n",
      "Eyewitnesses have described scenes of chaos, with tear gas fired and police rounding up protesters. One, Amin Khan, said from behind an oxygen mask that he joined the march knowing that, \"either I will bring back Imran Khan or I will be shot\". The authorities have have denied firing at the protesters. They also said some of the protesters were carrying firearms. The BBC has seen hospital records recording patients with gunshot injuries. However, government spokesperson Attaullah Tarar told the BBC that hospitals had denied receiving or treating gunshot wound victims. He added that \"all security personnel deployed on the ground have been forbidden\" from having live ammunition during protests. But one doctor told BBC Urdu that he had never done so many surgeries for gunshot wounds in a single night. \"Some of the injured came in such critical condition that we had to start surgery right away instead of waiting for anaesthesia,\" he said. While there has been no official toll released, the BBC has confirmed with local hospitals that at least five people have died. Police say at least 500 protesters were arrested that night and are being held in police stations. The PTI claims some people are missing. And one person in particular hasn’t been seen in days: Bushra Bibi.\n",
      "\n",
      "The next morning, the protesters were gone - leaving behind just wrecked cars and smashed glass\n",
      "\n",
      "Others defended her. “It wasn’t her fault,” insisted another. “She was forced to leave by the party leaders.” Political commentators have been more scathing. “Her exit damaged her political career before it even started,” said Mehmal Sarfraz, a journalist and analyst. But was that even what she wanted? Khan has previously dismissed any thought his wife might have her own political ambitions - “she only conveys my messages,” he said in a statement attributed to him on his X account.\n",
      "\n",
      "Imran Khan and Bushra Bibi, pictured here arriving at court in May 2023, married in 2018\n",
      "\n",
      "Speaking to BBC Urdu, analyst Imtiaz Gul calls her participation “an extraordinary step in extraordinary circumstances\". Gul believes Bushra Bibi’s role today is only about “keeping the party and its workers active during Imran Khan’s absence”. It is a feeling echoed by some PTI members, who believe she is “stepping in only because Khan trusts her deeply”. Insiders, though, had often whispered that she was pulling the strings behind the scenes - advising her husband on political appointments and guiding high-stakes decisions during his tenure. A more direct intervention came for the first time earlier this month, when she urged a meeting of PTI leaders to back Khan’s call for a rally. Pakistan’s defence minister Khawaja Asif accused her of “opportunism”, claiming she sees “a future for herself as a political leader”. But Asma Faiz, an associate professor of political science at Lahore University of Management Sciences, suspects the PTI’s leadership may have simply underestimated Bibi. “It was assumed that there was an understanding that she is a non-political person, hence she will not be a threat,” she told the AFP news agency. “However, the events of the last few days have shown a different side of Bushra Bibi.” But it probably doesn’t matter what analysts and politicians think. Many PTI supporters still see her as their connection to Imran Khan. It was clear her presence was enough to electrify the base. “She is the one who truly wants to get him out,” says Asim Ali, a resident of Islamabad. “I trust her. Absolutely!”\n",
      "The Embedding model sees this:\n",
      "Metadata: \n",
      "title=>Pakistan protest: Bushra Bibi's march for Imran Khan disappeared - BBC News\n",
      "-----\n",
      "Content: Bushra Bibi led a protest to free Imran Khan - what happened next is a mystery\n",
      "\n",
      "Imran Khan's wife, Bushra Bibi, encouraged protesters into the heart of Pakistan's capital, Islamabad\n",
      "\n",
      "A charred lorry, empty tear gas shells and posters of former Pakistan Prime Minister Imran Khan - it was all that remained of a massive protest led by Khan’s wife, Bushra Bibi, that had sent the entire capital into lockdown. Just a day earlier, faith healer Bibi - wrapped in a white shawl, her face covered by a white veil - stood atop a shipping container on the edge of the city as thousands of her husband’s devoted followers waved flags and chanted slogans beneath her. It was the latest protest to flare since Khan, the 72-year-old cricketing icon-turned-politician, was jailed more than a year ago after falling foul of the country's influential military which helped catapult him to power. “My children and my brothers! You have to stand with me,” Bibi cried on Tuesday afternoon, her voice cutting through the deafening roar of the crowd. “But even if you don’t,” she continued, “I will still stand firm. “This is not just about my husband. It is about this country and its leader.” It was, noted some watchers of Pakistani politics, her political debut. But as the sun rose on Wednesday morning, there was no sign of Bibi, nor the thousands of protesters who had marched through the country to the heart of the capital, demanding the release of their jailed leader. While other PMs have fallen out with Pakistan's military in the past, Khan's refusal to stay quiet behind bars is presenting an extraordinary challenge - escalating the standoff and leaving the country deeply divided. Exactly what happened to the so-called “final march”, and Bibi, when the city went dark is still unclear. All eyewitnesses like Samia* can say for certain is that the lights went out suddenly, plunging D Chowk, the square where they had gathered, into blackness.\n",
      "\n",
      "Within a day of arriving, the protesters had scattered - leaving behind Bibi's burnt-out vehicle\n",
      "\n",
      "As loud screams and clouds of tear gas blanketed the square, Samia describes holding her husband on the pavement, bloodied from a gun shot to his shoulder. \"Everyone was running for their lives,\" she later told BBC Urdu from a hospital in Islamabad, adding it was \"like doomsday or a war\". \"His blood was on my hands and the screams were unending.” But how did the tide turn so suddenly and decisively? Just hours earlier, protesters finally reached D Chowk late afternoon on Tuesday. They had overcome days of tear gas shelling and a maze of barricaded roads to get to the city centre. Many of them were supporters and workers of the Pakistan Tehreek-e-Insaf (PTI), the party led by Khan. He had called for the march from his jail cell, where he has been for more than a year on charges he says are politically motivated. Now Bibi - his third wife, a woman who had been largely shrouded in mystery and out of public view since their unexpected wedding in 2018 - was leading the charge. “We won’t go back until we have Khan with us,” she declared as the march reached D Chowk, deep in the heart of Islamabad’s government district.\n",
      "\n",
      "Thousands had marched for days to reach Islamabad, demanding former Prime Minister Imran Khan be released from jail\n",
      "\n",
      "Insiders say even the choice of destination - a place where her husband had once led a successful sit in - was Bibi’s, made in the face of other party leader’s opposition, and appeals from the government to choose another gathering point. Her being at the forefront may have come as a surprise. Bibi, only recently released from prison herself, is often described as private and apolitical. Little is known about her early life, apart from the fact she was a spiritual guide long before she met Khan. Her teachings, rooted in Sufi traditions, attracted many followers - including Khan himself. Was she making her move into politics - or was her sudden appearance in the thick of it a tactical move to keep Imran Khan’s party afloat while he remains behind bars? For critics, it was a move that clashed with Imran Khan’s oft-stated opposition to dynastic politics. There wasn’t long to mull the possibilities. After the lights went out, witnesses say that police started firing fresh rounds of tear gas at around 21:30 local time (16:30 GMT). The crackdown was in full swing just over an hour later. At some point, amid the chaos, Bushra Bibi left. Videos on social media appeared to show her switching cars and leaving the scene. The BBC couldn’t verify the footage. By the time the dust settled, her container had already been set on fire by unknown individuals. By 01:00 authorities said all the protesters had fled.\n",
      "\n",
      "Security was tight in the city, and as night fell, lights were switched off - leaving many in the dark as to what exactly happened next\n",
      "\n",
      "Eyewitnesses have described scenes of chaos, with tear gas fired and police rounding up protesters. One, Amin Khan, said from behind an oxygen mask that he joined the march knowing that, \"either I will bring back Imran Khan or I will be shot\". The authorities have have denied firing at the protesters. They also said some of the protesters were carrying firearms. The BBC has seen hospital records recording patients with gunshot injuries. However, government spokesperson Attaullah Tarar told the BBC that hospitals had denied receiving or treating gunshot wound victims. He added that \"all security personnel deployed on the ground have been forbidden\" from having live ammunition during protests. But one doctor told BBC Urdu that he had never done so many surgeries for gunshot wounds in a single night. \"Some of the injured came in such critical condition that we had to start surgery right away instead of waiting for anaesthesia,\" he said. While there has been no official toll released, the BBC has confirmed with local hospitals that at least five people have died. Police say at least 500 protesters were arrested that night and are being held in police stations. The PTI claims some people are missing. And one person in particular hasn’t been seen in days: Bushra Bibi.\n",
      "\n",
      "The next morning, the protesters were gone - leaving behind just wrecked cars and smashed glass\n",
      "\n",
      "Others defended her. “It wasn’t her fault,” insisted another. “She was forced to leave by the party leaders.” Political commentators have been more scathing. “Her exit damaged her political career before it even started,” said Mehmal Sarfraz, a journalist and analyst. But was that even what she wanted? Khan has previously dismissed any thought his wife might have her own political ambitions - “she only conveys my messages,” he said in a statement attributed to him on his X account.\n",
      "\n",
      "Imran Khan and Bushra Bibi, pictured here arriving at court in May 2023, married in 2018\n",
      "\n",
      "Speaking to BBC Urdu, analyst Imtiaz Gul calls her participation “an extraordinary step in extraordinary circumstances\". Gul believes Bushra Bibi’s role today is only about “keeping the party and its workers active during Imran Khan’s absence”. It is a feeling echoed by some PTI members, who believe she is “stepping in only because Khan trusts her deeply”. Insiders, though, had often whispered that she was pulling the strings behind the scenes - advising her husband on political appointments and guiding high-stakes decisions during his tenure. A more direct intervention came for the first time earlier this month, when she urged a meeting of PTI leaders to back Khan’s call for a rally. Pakistan’s defence minister Khawaja Asif accused her of “opportunism”, claiming she sees “a future for herself as a political leader”. But Asma Faiz, an associate professor of political science at Lahore University of Management Sciences, suspects the PTI’s leadership may have simply underestimated Bibi. “It was assumed that there was an understanding that she is a non-political person, hence she will not be a threat,” she told the AFP news agency. “However, the events of the last few days have shown a different side of Bushra Bibi.” But it probably doesn’t matter what analysts and politicians think. Many PTI supporters still see her as their connection to Imran Khan. It was clear her presence was enough to electrify the base. “She is the one who truly wants to get him out,” says Asim Ali, a resident of Islamabad. “I trust her. Absolutely!”\n"
     ]
    }
   ],
   "source": [
    "llama_documents = []\n",
    "# Process and store documents\n",
    "for article in unique_news_articles:\n",
    "    try:\n",
    "        document = Document(\n",
    "            text=article[\"content\"],\n",
    "            metadata={\n",
    "                \"title\": article[\"title\"],\n",
    "                \"description\": article[\"description\"],\n",
    "                \"published_date\": article[\"published_date\"],\n",
    "                \"link\": article[\"link\"],\n",
    "            },\n",
    "            excluded_llm_metadata_keys=[\"description\"],\n",
    "            excluded_embed_metadata_keys=[\"description\", \"published_date\", \"link\"],\n",
    "            metadata_template=\"{key}=>{value}\",\n",
    "            text_template=\"Metadata: \\n{metadata_str}\\n-----\\nContent: {content}\",\n",
    "        )\n",
    "        llama_documents.append(document)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save document to vector store: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Observing an example of what the LLM and Embedding model receive as input\n",
    "print(\"The LLM sees this:\")\n",
    "print(llama_documents[0].get_content(metadata_mode=MetadataMode.LLM))\n",
    "print(\"The Embedding model sees this:\")\n",
    "print(llama_documents[0].get_content(metadata_mode=MetadataMode.EMBED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Running the Ingestion Pipeline\n",
    "\n",
    "In this section, we'll create an ingestion pipeline to process our documents. The pipeline will:\n",
    "\n",
    "1. Split the documents into smaller chunks (nodes) using the SentenceSplitter\n",
    "2. Generate embeddings for each node using our embedding model\n",
    "3. Store these nodes with their embeddings in our Couchbase vector store\n",
    "\n",
    "This process transforms our raw documents into a searchable knowledge base that can be queried semantically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-10 14:46:39,361 - INFO - Successfully ingested 2329 nodes into the vector store.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Process documents: split into nodes, generate embeddings, and store in vector database\n",
    "    index_pipeline = IngestionPipeline(\n",
    "        transformations=[SentenceSplitter(), embed_model],\n",
    "        vector_store=vector_store,\n",
    "    )\n",
    "\n",
    "    nodes = index_pipeline.run(documents=llama_documents)\n",
    "    logging.info(f\"Successfully ingested {len(nodes)} nodes into the vector store.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to run ingestion pipeline: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI's Large Language Model (LLM)\n",
    "Large language models are AI systems that are trained to understand and generate human language. We'll be using OpenAI's `gpt-4o` model to process user queries and generate meaningful responses based on the retrieved context from our Couchbase vector store. This model is a key component of our RAG system, allowing it to go beyond simple keyword matching and truly understand the intent behind a query. By integrating OpenAI's LLM, we equip our RAG system with the ability to interpret complex queries, understand the nuances of language, and provide more accurate and contextually relevant responses.\n",
    "\n",
    "The language model's ability to understand context and generate coherent responses is what makes our RAG system truly intelligent. It can not only find the right information but also present it in a way that is useful and understandable to the user.\n",
    "\n",
    "The LLM is configured using LlamaIndex's OpenAI-like provider with OpenAI's API endpoint and your OpenAI API key for seamless integration with their services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-10 14:46:39,369 - INFO - Successfully created the OpenAI LLM\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Set up the LLM\n",
    "    llm = OpenAI(\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        model=\"gpt-4o\",\n",
    "        \n",
    "    )\n",
    "    # Configure LlamaIndex to use this LLM\n",
    "    Settings.llm = llm\n",
    "    logging.info(\"Successfully created the OpenAI LLM\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error creating OpenAI LLM: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Vector Store Index\n",
    "\n",
    "In this section, we'll create a VectorStoreIndex from our Couchbase vector store. This index serves as the foundation for our RAG system, enabling semantic search capabilities and efficient retrieval of relevant information.\n",
    "\n",
    "The VectorStoreIndex provides a high-level interface to interact with our vector store, allowing us to:\n",
    "1. Perform semantic searches based on user queries\n",
    "2. Retrieve the most relevant documents or chunks\n",
    "3. Generate contextually appropriate responses using our LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-10 14:46:39,377 - INFO - Successfully created vector store index and query engine.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Create your index\n",
    "    index = VectorStoreIndex.from_vector_store(vector_store)\n",
    "    rag = index.as_query_engine()\n",
    "    logging.info(\"Successfully created vector store index and query engine.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to create vector store index: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Semantic Search in Couchbase\n",
    "\n",
    "Semantic search goes beyond traditional keyword matching by understanding the meaning and context behind queries. Here's how it works in Couchbase:\n",
    "\n",
    "### How Semantic Search Works\n",
    "\n",
    "1. **Vector Embeddings**: Documents and queries are converted into high-dimensional vectors using an embeddings model (in our case, OpenAI's text-embedding-3-large model)\n",
    "\n",
    "2. **Similarity Calculation**: When a query is made, Couchbase compares the query vector against stored document vectors using the DOT product similarity metric\n",
    "\n",
    "3. **Result Ranking**: Documents are ranked by their vector similarity scores\n",
    "\n",
    "4. **Flexible Configuration**: Different similarity metrics (dot product, cosine, euclidean) and embedding models can be used based on your needs\n",
    "\n",
    "Now let's see semantic search in action and measure its performance with different optimization strategies.\n",
    "\n",
    "## Vector Search Performance Testing\n",
    "\n",
    "### Phase 1: Baseline Performance (No Hyperscale Index)\n",
    "\n",
    "First, we'll run a RAG query without using a Hyperscale index to establish our baseline performance. This search uses linear brute force which compares the query vector against every document in the collection. This works for small datasets but can become slow as the dataset grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic Search Results (completed in 1.37 seconds):\n",
      "Daniel Dubois will fight Joseph Parker in Saudi Arabia on 22 February.\n"
     ]
    }
   ],
   "source": [
    "# Sample query from the dataset\n",
    "\n",
    "query = \"Who will Daniel Dubois fight in Saudi Arabia on 22 February?\"\n",
    "\n",
    "try:\n",
    "    # Perform the semantic search\n",
    "    start_time = time.time()\n",
    "    response = rag.query(query)\n",
    "    search_elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Display search results\n",
    "    print(f\"\\nSemantic Search Results (completed in {search_elapsed_time:.2f} seconds):\")\n",
    "    print(response)\n",
    "\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error performing semantic search: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Hyperscale Index\n",
    "\n",
    "Now we'll create a Hyperscale index to significantly improve query performance. The index uses IVF (Inverted File) with PQ (Product Quantization) for optimal balance between speed and accuracy.\n",
    "\n",
    "The index configuration uses:\n",
    "- **IVF1024**: 1024 centroids for fast search\n",
    "- **PQ32x8**: Product quantization with 32 subquantizers and 8 bits each\n",
    "- **DOT similarity**: Optimized for dot product similarity matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperscale Vector Index may already exist or error occurred: QueryIndexAlreadyExistsException(<ec=18, category=couchbase.common, message=index_exists (18), context=QueryErrorContext({'last_dispatched_to': '[::1]:8093', 'last_dispatched_from': '[::1]:50293', 'retry_attempts': 0, 'client_context_id': '307cb1-5404-c145-ee6c-386a11e6a2e210', 'method': 'POST', 'path': '/query/service', 'http_status': 409, 'http_body': '{\\n\"requestID\": \"7fbcc5a7-e359-4d59-b069-605cbbd0883f\",\\n\"clientContextID\": \"307cb1-5404-c145-ee6c-386a11e6a2e210\",\\n\"signature\": null,\\n\"results\": [\\n],\\n\"errors\": [{\"code\":4300,\"msg\":\"The index vector_search_llamaindex_hyperscale already exists.\",\"reason\":{\"name\":\"vector_search_llamaindex_hyperscale\"}}],\\n\"status\": \"fatal\"\\n}\\n', 'first_error_code': 4300, 'first_error_message': 'The index vector_search_llamaindex_hyperscale already exists.', 'statement': '\\n        CREATE INDEX vector_search_llamaindex_hyperscale\\n        ON llamaindex (embedding VECTOR)\\n        USING GSI WITH {\"dimension\": 3072, \"description\": \"IVF1024,PQ32x8\", \"similarity\": \"DOT\"}\\n        ', 'parameters': '{\"client_context_id\":\"307cb1-5404-c145-ee6c-386a11e6a2e210\",\"metrics\":false,\"query_context\":\"`vector-search-testing`.`shared`\",\"statement\":\"\\\\n        CREATE INDEX vector_search_llamaindex_hyperscale\\\\n        ON llamaindex (embedding VECTOR)\\\\n        USING GSI WITH {\\\\\"dimension\\\\\": 3072, \\\\\"description\\\\\": \\\\\"IVF1024,PQ32x8\\\\\", \\\\\"similarity\\\\\": \\\\\"DOT\\\\\"}\\\\n        \",\"timeout\":\"299500ms\"}', 'context_type': 'QueryErrorContext'}), C Source=/Users/couchbase/jenkins/workspace/python/sdk/python-scripted-build-pipeline/py-client/src/n1ql.cxx:279>)\n"
     ]
    }
   ],
   "source": [
    "# Create a Hyperscale Vector Index for optimized vector search\n",
    "try:\n",
    "    hyperscale_index_name = f\"{INDEX_NAME}_hyperscale\"\n",
    "\n",
    "    options = {\n",
    "        \"dimension\": 3072,\n",
    "        \"description\": \"IVF1024,PQ32x8\",\n",
    "        \"similarity\": \"DOT\",\n",
    "    }\n",
    "    scope.query(\n",
    "        f\"\"\"\n",
    "        CREATE INDEX {hyperscale_index_name}\n",
    "        ON {COLLECTION_NAME} (embedding VECTOR)\n",
    "        USING GSI WITH {json.dumps(options)}\n",
    "        \"\"\",\n",
    "    QueryOptions(\n",
    "        timeout=timedelta(seconds=300)\n",
    "    )).execute()\n",
    "    print(f\"Successfully created Hyperscale Vector Index: {hyperscale_index_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Hyperscale Vector Index may already exist or error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2: Hyperscale-Optimized Performance\n",
    "\n",
    "Now let's run the same RAG query using the Hyperscale index we just created. You'll notice improved performance as the index efficiently retrieves data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Vector Search Results (completed in 1.98 seconds):\n",
      "Daniel Dubois will fight Joseph Parker in Saudi Arabia on 22 February.\n"
     ]
    }
   ],
   "source": [
    "# Test the optimized vector search with Hyperscale Vector Index\n",
    "query = \"Who will Daniel Dubois fight in Saudi Arabia on 22 February?\"\n",
    "try:\n",
    "    # Create a new query engine using the optimized vector store\n",
    "    optimized_rag = index.as_query_engine()\n",
    "    \n",
    "    # Perform the semantic search with Hyperscale Vector Index optimization\n",
    "    start_time = time.time()\n",
    "    response = optimized_rag.query(query)\n",
    "    search_elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Display search results\n",
    "    print(f\"\\nOptimized Vector Search Results (completed in {search_elapsed_time:.2f} seconds):\")\n",
    "    print(response)\n",
    "\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error performing optimized semantic search: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Analysis Summary\n",
    "\n",
    "The performance comparison between Phase 1 (baseline) and Phase 2 (Hyperscale-optimized) demonstrates the significant benefits of using Hyperscale indexes for vector search:\n",
    "\n",
    "| Metric | Phase 1 (Baseline) | Phase 2 (Hyperscale) | Improvement |\n",
    "|--------|-------------------|---------------------|-------------|\n",
    "| Search Method | Brute force | IVF + PQ indexed | Optimized |\n",
    "| Index Type | None | Hyperscale (IVF1024,PQ32x8) | Optimized |\n",
    "| Scalability | Limited | Billions of vectors | High |\n",
    "\n",
    "**Key Takeaways:**\n",
    "- **Hyperscale indexes** provide substantial performance improvements for semantic search\n",
    "- The **IVF + PQ configuration** offers an excellent balance of speed and accuracy\n",
    "- For production workloads, always create appropriate indexes based on your query patterns\n",
    "- Consider **Composite indexes** when you need to combine vector search with scalar filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've built a RAG system using Couchbase Hyperscale/Composite indexes with OpenAI and LlamaIndex. For the Search Vector Index alternative, see the [search_based tutorial](https://developer.couchbase.com/tutorial-openai-llamaindex-couchbase-rag-with-search-vector-index)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
