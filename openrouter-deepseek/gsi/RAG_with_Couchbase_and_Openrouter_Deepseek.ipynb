{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction \n",
        "In this guide, we will walk you through building a powerful semantic search engine using Couchbase as the backend database and [Deepseek V3 as the language model provider (via OpenRouter or direct API)](https://deepseek.ai/) and OpenAI for embeddings. Semantic search goes beyond simple keyword matching by understanding the context and meaning behind the words in a query, making it an essential tool for applications that require intelligent information retrieval. This tutorial is designed to be beginner-friendly, with clear, step-by-step instructions that will equip you with the knowledge to create a fully functional semantic search system using GSI( Global Secondary Index) from scratch. Alternatively if you want to perform semantic search using the FTS index, please take a look at [this.](https://developer.couchbase.com/tutorial-openrouter-deepseek-with-fts/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# How to run this tutorial\n",
        "\n",
        "This tutorial is available as a Jupyter Notebook (`.ipynb` file) that you can run interactively. You can access the original notebook [here](https://github.com/couchbase-examples/vector-search-cookbook/openrouter-deepseek/RAG_with_Couchbase_and_Openrouter_Deepseek.ipynb).\n",
        "\n",
        "You can either download the notebook file and run it on [Google Colab](https://colab.research.google.com/) or run it on your system by setting up the Python environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Before you start\n",
        "\n",
        "## Get Credentials for OpenRouter and Deepseek\n",
        "* Sign up for an account at [OpenRouter](https://openrouter.ai/) to get your API key\n",
        "* OpenRouter provides access to Deepseek models, so no separate Deepseek credentials are needed\n",
        "* Store your OpenRouter API key securely as it will be used to access the models\n",
        "* For [Deepseek](https://deepseek.ai/) models, you can use the default models provided by OpenRouter\n",
        "\n",
        "## Create and Deploy Your Free Tier Operational cluster on Capella\n",
        "\n",
        "To get started with Couchbase Capella, create an account and use it to deploy a forever free tier operational cluster. This account provides you with an environment where you can explore and learn about Capella with no time constraint.\n",
        "\n",
        "To learn more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).\n",
        "\n",
        "Note: To run this this tutorial, you will need Capella with Couchbase Server version 8.0 or above as GSI vector search is supported only from version 8.0\n",
        "\n",
        "### Couchbase Capella Configuration\n",
        "\n",
        "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met.\n",
        "\n",
        "* Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the required bucket (Read and Write) used in the application.\n",
        "* [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting the Stage: Installing Necessary Libraries\n",
        "\n",
        "To build our semantic search engine, we need a robust set of tools. The libraries we install handle everything from connecting to databases to performing complex machine learning tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --quiet datasets==3.5.0 langchain-couchbase==0.5.0 langchain-deepseek==0.1.3 langchain-openai==0.3.13 python-dotenv==1.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Necessary Libraries\n",
        "\n",
        "The script starts by importing a series of libraries required for various tasks, including handling JSON, logging, time tracking, Couchbase connections, embedding generation, and dataset loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.exceptions import (CouchbaseException,\n",
        "                                InternalServerFailureException,\n",
        "                                QueryIndexAlreadyExistsException,ServiceUnavailableException)\n",
        "from couchbase.management.buckets import CreateBucketSettings\n",
        "from couchbase.management.search import SearchIndex\n",
        "from couchbase.options import ClusterOptions\n",
        "from datasets import load_dataset\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.globals import set_llm_cache\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts.chat import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_couchbase.cache import CouchbaseCache\n",
        "from langchain_couchbase.vectorstores import CouchbaseQueryVectorStore\n",
        "from langchain_couchbase.vectorstores import DistanceStrategy\n",
        "from langchain_couchbase.vectorstores import IndexType\n",
        "from langchain_openai import OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Logging\n",
        "Logging is configured to track the progress of the script and capture any errors or warnings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n",
        "\n",
        "# Suppress httpx logging\n",
        "logging.getLogger('httpx').setLevel(logging.CRITICAL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Variables and Configuration\n",
        "\n",
        "This section handles loading and validating environment variables and configuration settings:\n",
        "#\n",
        "1. API Keys:\n",
        "   - Supports either direct Deepseek API or OpenRouter API access\n",
        "   - Prompts for API key input if not found in environment\n",
        "   - Requires OpenAI API key for embeddings\n",
        "#\n",
        "2. Couchbase Settings:\n",
        "   - Connection details (host, username, password)\n",
        "   - Bucket, scope and collection names\n",
        "   - Vector search index configuration\n",
        "   - Cache collection settings\n",
        "#\n",
        "The code validates that all required credentials are present before proceeding.\n",
        "It allows flexible configuration through environment variables or interactive prompts,\n",
        "with sensible defaults for local development.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load environment variables from .env file if it exists\n",
        "load_dotenv(override= True)\n",
        "\n",
        "# API Keys\n",
        "# Allow either Deepseek API directly or via OpenRouter\n",
        "DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')\n",
        "OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\n",
        "\n",
        "if not DEEPSEEK_API_KEY and not OPENROUTER_API_KEY:\n",
        "    api_choice = input('Choose API (1 for Deepseek direct, 2 for OpenRouter): ')\n",
        "    if api_choice == '1':\n",
        "        DEEPSEEK_API_KEY = getpass.getpass('Enter your Deepseek API Key: ')\n",
        "    else:\n",
        "        OPENROUTER_API_KEY = getpass.getpass('Enter your OpenRouter API Key: ')\n",
        "\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or getpass.getpass('Enter your OpenAI API Key: ')\n",
        "\n",
        "# Couchbase Settings\n",
        "CB_HOST = os.getenv('CB_HOST') or input('Enter your Couchbase host (default: couchbase://localhost): ') or 'couchbase://localhost'\n",
        "CB_USERNAME = os.getenv('CB_USERNAME') or input('Enter your Couchbase username (default: Administrator): ') or 'Administrator'\n",
        "CB_PASSWORD = os.getenv('CB_PASSWORD') or getpass.getpass('Enter your Couchbase password (default: password): ') or 'password'\n",
        "CB_BUCKET_NAME = os.getenv('CB_BUCKET_NAME') or input('Enter your Couchbase bucket name (default: query-vector-search-testing): ') or 'query-vector-search-testing'\n",
        "SCOPE_NAME = os.getenv('SCOPE_NAME') or input('Enter your scope name (default: shared): ') or 'shared'\n",
        "COLLECTION_NAME = os.getenv('COLLECTION_NAME') or input('Enter your collection name (default: deepseek): ') or 'deepseek'\n",
        "CACHE_COLLECTION = os.getenv('CACHE_COLLECTION') or input('Enter your cache collection name (default: cache): ') or 'cache'\n",
        "\n",
        "# Check if required credentials are set\n",
        "required_creds = {\n",
        "    'OPENAI_API_KEY': OPENAI_API_KEY,\n",
        "    'CB_HOST': CB_HOST,\n",
        "    'CB_USERNAME': CB_USERNAME,\n",
        "    'CB_PASSWORD': CB_PASSWORD,\n",
        "    'CB_BUCKET_NAME': CB_BUCKET_NAME\n",
        "}\n",
        "\n",
        "# Add the API key that was chosen\n",
        "if DEEPSEEK_API_KEY:\n",
        "    required_creds['DEEPSEEK_API_KEY'] = DEEPSEEK_API_KEY\n",
        "elif OPENROUTER_API_KEY:\n",
        "    required_creds['OPENROUTER_API_KEY'] = OPENROUTER_API_KEY\n",
        "else:\n",
        "    raise ValueError(\"Either Deepseek API Key or OpenRouter API Key must be provided\")\n",
        "\n",
        "for cred_name, cred_value in required_creds.items():\n",
        "    if not cred_value:\n",
        "        raise ValueError(f\"{cred_name} is not set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connecting to the Couchbase Cluster\n",
        "Connecting to a Couchbase cluster is the foundation of our project. Couchbase will serve as our primary data store, handling all the storage and retrieval operations required for our semantic search engine. By establishing this connection, we enable our application to interact with the database, allowing us to perform operations such as storing embeddings, querying data, and managing collections. This connection is the gateway through which all data will flow, so ensuring it's set up correctly is paramount.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-17 15:40:27,133 - INFO - Successfully connected to Couchbase\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
        "    options = ClusterOptions(auth)\n",
        "    cluster = Cluster(CB_HOST, options)\n",
        "    cluster.wait_until_ready(timedelta(seconds=5))\n",
        "    logging.info(\"Successfully connected to Couchbase\")\n",
        "except Exception as e:\n",
        "    raise ConnectionError(f\"Failed to connect to Couchbase: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting Up Collections in Couchbase\n",
        "\n",
        "The setup_collection() function handles creating and configuring the hierarchical data organization in Couchbase:\n",
        "\n",
        "1. Bucket Creation:\n",
        "   - Checks if specified bucket exists, creates it if not\n",
        "   - Sets bucket properties like RAM quota (1024MB) and replication (disabled)\n",
        "   - Note: If you are using Capella, create a bucket manually called vector-search-testing(or any name you prefer) with the same properties.\n",
        "\n",
        "2. Scope Management:  \n",
        "   - Verifies if requested scope exists within bucket\n",
        "   - Creates new scope if needed (unless it's the default \"_default\" scope)\n",
        "\n",
        "3. Collection Setup:\n",
        "   - Checks for collection existence within scope\n",
        "   - Creates collection if it doesn't exist\n",
        "   - Waits 2 seconds for collection to be ready\n",
        "\n",
        "Additional Tasks:\n",
        "- Clears any existing documents for clean state\n",
        "- Implements comprehensive error handling and logging\n",
        "\n",
        "The function is called twice to set up:\n",
        "1. Main collection for vector embeddings\n",
        "2. Cache collection for storing results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-17 15:41:01,398 - INFO - Bucket 'query-vector-search-testing' exists.\n",
            "2025-09-17 15:41:01,410 - INFO - Collection 'deepseek' does not exist. Creating it...\n",
            "2025-09-17 15:41:01,453 - INFO - Collection 'deepseek' created successfully.\n",
            "2025-09-17 15:41:03,712 - INFO - All documents cleared from the collection.\n",
            "2025-09-17 15:41:03,713 - INFO - Bucket 'query-vector-search-testing' exists.\n",
            "2025-09-17 15:41:03,728 - INFO - Collection 'cache' already exists. Skipping creation.\n",
            "2025-09-17 15:41:05,821 - INFO - All documents cleared from the collection.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<couchbase.collection.Collection at 0x126371450>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def setup_collection(cluster, bucket_name, scope_name, collection_name):\n",
        "    try:\n",
        "        # Check if bucket exists, create if it doesn't\n",
        "        try:\n",
        "            bucket = cluster.bucket(bucket_name)\n",
        "            logging.info(f\"Bucket '{bucket_name}' exists.\")\n",
        "        except Exception as e:\n",
        "            logging.info(f\"Bucket '{bucket_name}' does not exist. Creating it...\")\n",
        "            bucket_settings = CreateBucketSettings(\n",
        "                name=bucket_name,\n",
        "                bucket_type='couchbase',\n",
        "                ram_quota_mb=1024,\n",
        "                flush_enabled=True,\n",
        "                num_replicas=0\n",
        "            )\n",
        "            cluster.buckets().create_bucket(bucket_settings)\n",
        "            time.sleep(2)  # Wait for bucket creation to complete and become available\n",
        "            bucket = cluster.bucket(bucket_name)\n",
        "            logging.info(f\"Bucket '{bucket_name}' created successfully.\")\n",
        "\n",
        "        bucket_manager = bucket.collections()\n",
        "\n",
        "        # Check if scope exists, create if it doesn't\n",
        "        scopes = bucket_manager.get_all_scopes()\n",
        "        scope_exists = any(scope.name == scope_name for scope in scopes)\n",
        "        \n",
        "        if not scope_exists and scope_name != \"_default\":\n",
        "            logging.info(f\"Scope '{scope_name}' does not exist. Creating it...\")\n",
        "            bucket_manager.create_scope(scope_name)\n",
        "            logging.info(f\"Scope '{scope_name}' created successfully.\")\n",
        "\n",
        "        # Check if collection exists, create if it doesn't\n",
        "        collections = bucket_manager.get_all_scopes()\n",
        "        collection_exists = any(\n",
        "            scope.name == scope_name and collection_name in [col.name for col in scope.collections]\n",
        "            for scope in collections\n",
        "        )\n",
        "\n",
        "        if not collection_exists:\n",
        "            logging.info(f\"Collection '{collection_name}' does not exist. Creating it...\")\n",
        "            bucket_manager.create_collection(scope_name, collection_name)\n",
        "            logging.info(f\"Collection '{collection_name}' created successfully.\")\n",
        "        else:\n",
        "            logging.info(f\"Collection '{collection_name}' already exists. Skipping creation.\")\n",
        "\n",
        "        # Wait for collection to be ready\n",
        "        collection = bucket.scope(scope_name).collection(collection_name)\n",
        "        time.sleep(2)  # Give the collection time to be ready for queries\n",
        "\n",
        "        # Clear all documents in the collection\n",
        "        try:\n",
        "            query = f\"DELETE FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            cluster.query(query).execute()\n",
        "            logging.info(\"All documents cleared from the collection.\")\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"Error while clearing documents: {str(e)}. The collection might be empty.\")\n",
        "\n",
        "        return collection\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error setting up collection: {str(e)}\")\n",
        "    \n",
        "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, COLLECTION_NAME)\n",
        "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, CACHE_COLLECTION)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the Embeddings client\n",
        "This section creates an OpenAI embeddings client using the OpenAI API key.\n",
        "The embeddings client is configured to use the \"text-embedding-3-small\" model,\n",
        "which converts text into numerical vector representations.\n",
        "These vector embeddings are essential for semantic search and similarity matching.\n",
        "The client will be used by the vector store to generate embeddings for documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-17 15:41:27,149 - INFO - Successfully created OpenAI embeddings client\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    embeddings = OpenAIEmbeddings(\n",
        "        api_key=OPENAI_API_KEY,\n",
        "        model=\"text-embedding-3-small\"\n",
        "    )\n",
        "    logging.info(\"Successfully created OpenAI embeddings client\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Error creating OpenAI embeddings client: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Setting Up the Couchbase Vector Store\n",
        "A vector store is where we'll keep our embeddings. Unlike the FTS index, which is used for text-based search, the vector store is specifically designed to handle embeddings and perform similarity searches. When a user inputs a query, the search engine converts the query into an embedding and compares it against the embeddings stored in the vector store. This allows the engine to find documents that are semantically similar to the query, even if they don't contain the exact same words. By setting up the vector store in Couchbase, we create a powerful tool that enables our search engine to understand and retrieve information based on the meaning and context of the query, rather than just the specific words used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-17 15:41:55,394 - INFO - Successfully created vector store\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    vector_store = CouchbaseQueryVectorStore(\n",
        "        cluster=cluster,\n",
        "        bucket_name=CB_BUCKET_NAME,\n",
        "        scope_name=SCOPE_NAME,\n",
        "        collection_name=COLLECTION_NAME,\n",
        "        embedding = embeddings,\n",
        "        distance_metric=DistanceStrategy.COSINE\n",
        "    )\n",
        "    logging.info(\"Successfully created vector store\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Failed to create vector store: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the BBC News Dataset\n",
        "To build a search engine, we need data to search through. We use the BBC News dataset from RealTimeData, which provides real-world news articles. This dataset contains news articles from BBC covering various topics and time periods. Loading the dataset is a crucial step because it provides the raw material that our search engine will work with. The quality and diversity of the news articles make it an excellent choice for testing and refining our search engine, ensuring it can handle real-world news content effectively.\n",
        "\n",
        "The BBC News dataset allows us to work with authentic news articles, enabling us to build and test a search engine that can effectively process and retrieve relevant news content. The dataset is loaded using the Hugging Face datasets library, specifically accessing the \"RealTimeData/bbc_news_alltime\" dataset with the \"2024-12\" version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-17 15:42:04,530 - INFO - Successfully loaded the BBC News dataset with 2687 rows.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded the BBC News dataset with 2687 rows\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    news_dataset = load_dataset(\n",
        "        \"RealTimeData/bbc_news_alltime\", \"2024-12\", split=\"train\"\n",
        "    )\n",
        "    print(f\"Loaded the BBC News dataset with {len(news_dataset)} rows\")\n",
        "    logging.info(f\"Successfully loaded the BBC News dataset with {len(news_dataset)} rows.\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Error loading the BBC News dataset: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning up the Data\n",
        "We will use the content of the news articles for our RAG system.\n",
        "\n",
        "The dataset contains a few duplicate records. We are removing them to avoid duplicate results in the retrieval stage of our RAG system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We have 1749 unique articles in our database.\n"
          ]
        }
      ],
      "source": [
        "news_articles = news_dataset[\"content\"]\n",
        "unique_articles = set()\n",
        "for article in news_articles:\n",
        "    if article:\n",
        "        unique_articles.add(article)\n",
        "unique_news_articles = list(unique_articles)\n",
        "print(f\"We have {len(unique_news_articles)} unique articles in our database.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Data to the Vector Store\n",
        "To efficiently handle the large number of articles, we process them in batches of articles at a time. This batch processing approach helps manage memory usage and provides better control over the ingestion process.\n",
        "\n",
        "We first filter out any articles that exceed 50,000 characters to avoid potential issues with token limits. Then, using the vector store's add_texts method, we add the filtered articles to our vector database. The batch_size parameter controls how many articles are processed in each iteration.\n",
        "\n",
        "This approach offers several benefits:\n",
        "1. Memory Efficiency: Processing in smaller batches prevents memory overload\n",
        "2. Progress Tracking: Easier to monitor and track the ingestion progress\n",
        "3. Resource Management: Better control over CPU and network resource utilization\n",
        "\n",
        "We use a conservative batch size of 50 to ensure reliable operation.\n",
        "The optimal batch size depends on many factors including:\n",
        "- Document sizes being inserted\n",
        "- Available system resources\n",
        "- Network conditions\n",
        "- Concurrent workload\n",
        "\n",
        "Consider measuring performance with your specific workload before adjusting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-17 16:08:51,054 - INFO - Document ingestion completed successfully.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 50\n",
        "\n",
        "# Automatic Batch Processing\n",
        "articles = [article for article in unique_news_articles if article and len(article) <= 50000]\n",
        "\n",
        "try:\n",
        "    vector_store.add_texts(\n",
        "        texts=articles,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    logging.info(\"Document ingestion completed successfully.\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Failed to save documents to vector store: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting Up the LLM Model\n",
        "In this section, we set up the Large Language Model (LLM) for our RAG system. We're using the Deepseek model, which can be accessed through two different methods:\n",
        "\n",
        "1. **Deepseek API Key**: This is obtained directly from Deepseek's platform (https://deepseek.ai) by creating an account and subscribing to their API services. With this key, you can access Deepseek's models directly using the `ChatDeepSeek` class from the `langchain_deepseek` package.\n",
        "\n",
        "2. **OpenRouter API Key**: OpenRouter (https://openrouter.ai) is a service that provides unified access to multiple LLM providers, including Deepseek. You can obtain an API key by creating an account on OpenRouter's website. This approach uses the `ChatOpenAI` class from `langchain_openai` but with a custom base URL pointing to OpenRouter's API endpoint.\n",
        "\n",
        "The key difference is that OpenRouter acts as an intermediary service that can route your requests to various LLM providers, while the Deepseek API gives you direct access to only Deepseek's models. OpenRouter can be useful if you want to switch between different LLM providers without changing your code significantly.\n",
        "\n",
        "In our implementation, we check for both keys and prioritize using the Deepseek API directly if available, falling back to OpenRouter if not. The model is configured with temperature=0 to ensure deterministic, focused responses suitable for RAG applications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-18 11:18:25,192 - INFO - Successfully created Deepseek LLM client through OpenRouter\n"
          ]
        }
      ],
      "source": [
        "from langchain_deepseek import ChatDeepSeek\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "if DEEPSEEK_API_KEY:\n",
        "    try:\n",
        "        llm = ChatDeepSeek(\n",
        "            api_key=DEEPSEEK_API_KEY,\n",
        "            model_name=\"deepseek-chat\",\n",
        "            temperature=0\n",
        "        )\n",
        "        logging.info(\"Successfully created Deepseek LLM client\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error creating Deepseek LLM client: {str(e)}\")\n",
        "elif OPENROUTER_API_KEY:\n",
        "    try:\n",
        "        llm = ChatOpenAI(\n",
        "            api_key=OPENROUTER_API_KEY,\n",
        "            base_url=\"https://openrouter.ai/api/v1\",\n",
        "            model=\"deepseek/deepseek-chat-v3.1\", \n",
        "            temperature=0,\n",
        "        )\n",
        "        logging.info(\"Successfully created Deepseek LLM client through OpenRouter\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error creating Deepseek LLM client: {str(e)}\")\n",
        "else:\n",
        "    raise ValueError(\"Either Deepseek API Key or OpenRouter API Key must be provided\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Perform Semantic Search\n",
        "Semantic search in Couchbase involves converting queries and documents into vector representations using an embeddings model. These vectors capture the semantic meaning of the text and are stored directly in Couchbase. When a query is made, Couchbase performs a similarity search by comparing the query vector against the stored document vectors. The similarity metric used for this comparison is configurable, allowing flexibility in how the relevance of documents is determined. Common metrics include cosine similarity, Euclidean distance, or dot product, but other metrics can be implemented based on specific use cases. Different embedding models like BERT, Word2Vec, or GloVe can also be used depending on the application's needs, with the vectors generated by these models stored and searched within Couchbase itself.\n",
        "\n",
        "In the provided code, the search process begins by recording the start time, followed by executing the `similarity_search_with_score` method of the `CouchbaseQueryVectorStore`. This method searches Couchbase for the most relevant documents based on the vector similarity to the query. The search results include the document content and the distance that reflects how closely each document aligns with the query in the defined semantic space. The time taken to perform this search is then calculated and logged, and the results are displayed, showing the most relevant documents along with their similarity scores. This approach leverages Couchbase as both a storage and retrieval engine for vector data, enabling efficient and scalable semantic searches. The integration of vector storage and search capabilities within Couchbase allows for sophisticated semantic search operations without relying on external services for vector storage or comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-17 16:11:07,177 - INFO - Semantic search completed in 2.46 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Semantic Search Results (completed in 2.46 seconds):\n",
            "--------------------------------------------------------------------------------\n",
            "Distance: 0.3693, Text: The Littler effect - how darts hit the bullseye\n",
            "\n",
            "Teenager Luke Littler began his bid to win the 2025 PDC World Darts Championship with a second-round win against Ryan Meikle. Here we assess Littler's impact after a remarkable rise which saw him named BBC Young Sports Personality of the Year and runner-up in the main award to athlete Keely Hodgkinson.\n",
            "\n",
            "One year ago, he was barely a household name in his own home. Now he is a sporting phenomenon. After emerging from obscurity aged 16 to reach the World Championship final, the life of Luke Littler and the sport he loves has been transformed. Viewing figures, ticket sales and social media interest have rocketed. Darts has hit the bullseye. This Christmas more than 100,000 children are expected to be opening Littler-branded magnetic dartboards as presents. His impact has helped double the number of junior academies, prompted plans to expand the World Championship and generated interest in darts from Saudi Arabian backers.\n",
            "\n",
            "Just months after taking his GCSE exams and ranked 164th in the world, Littler beat former champions Raymond van Barneveld and Rob Cross en route to the PDC World Championship final in January, before his run ended with a 7-4 loss to Luke Humphries. With his nickname 'The Nuke' on his purple and yellow shirt and the Alexandra Palace crowd belting out his walk-on song, Pitbull's tune Greenlight, he became an instant hit. Electric on the stage, calm off it. The down-to-earth teenager celebrated with a kebab and computer games. \"We've been watching his progress since he was about seven. He was on our radar, but we never anticipated what would happen. The next thing we know 'Littlermania' is spreading everywhere,\" PDC president Barry Hearn told BBC Sport. A peak TV audience of 3.7 million people watched the final - easily Sky's biggest figure for a non-football sporting event. The teenager from Warrington in Cheshire was too young to legally drive or drink alcohol, but earned £200,000 for finishing second - part of £1m prize money in his first year as a professional - and an invitation to the elite Premier League competition. He turned 17 later in January but was he too young for the demanding event over 17 Thursday nights in 17 locations? He ended up winning the whole thing, and hit a nine-dart finish against Humphries in the final. From Bahrain to Wolverhampton, Littler claimed 10 titles in 2024 and is now eyeing the World Championship.\n",
            "\n",
            "As he progressed at the Ally Pally, the Manchester United fan was sent a good luck message by the club's former midfielder and ex-England captain David Beckham. In 12 months, Littler's Instagram followers have risen from 4,000 to 1.3m. Commercial backers include a clothing range, cereal firm and train company and he will appear in a reboot of the TV darts show Bullseye. Google say he was the most searched-for athlete online in the UK during 2024. On the back of his success, Littler darts, boards, cabinets, shirts are being snapped up in big numbers. \"This Christmas the junior magnetic dartboard is selling out, we're talking over 100,000. They're 20 quid and a great introduction for young children,\" said Garry Plummer, the boss of sponsors Target Darts, who first signed a deal with Littler's family when he was aged 12. \"All the toy shops want it, they all want him - 17, clean, doesn't drink, wonderful.\"\n",
            "\n",
            "Littler beat Luke Humphries to win the Premier League title in May\n",
            "\n",
            "The number of academies for children under the age of 16 has doubled in the last year, says Junior Darts Corporation chairman Steve Brown. There are 115 dedicated groups offering youngsters equipment, tournaments and a place to develop, with bases including Australia, Bulgaria, Greece, Norway, USA and Mongolia. \"We've seen so many inquiries from around the world, it's been such a boom. It took us 14 years to get 1,600 members and within 12 months we have over 3,000, and waiting lists,\" said Brown. \"When I played darts as a child, I was quite embarrassed to tell my friends what my hobby was. All these kids playing darts now are pretty popular at school. It's a bit rock 'n roll and recognised as a cool thing to do.\" Plans are being hatched to extend the World Championship by four days and increase the number of players from 96 to 128. That will boost the number of tickets available by 25,000 to 115,000 but Hearn reckons he could sell three times as many. He says Saudi Arabia wants to host a tournament, which is likely to happen if no-alcohol regulations are relaxed. \"They will change their rules in the next 12 months probably for certain areas having alcohol, and we'll take darts there and have a party in Saudi,\" he said. \"When I got involved in darts, the total prize money was something like £300,000 for the year. This year it will go to £20m. I expect in five years' time, we'll be playing for £40m.\"\n",
            "\n",
            "Former electrician Cross charged to the 2018 world title in his first full season, while Adrian Lewis and Michael van Gerwen were multiple victors in their 20s and 16-time champion Phil ‘The Power’ Taylor is widely considered the greatest of all time. Littler is currently fourth in the world rankings, although that is based on a two-year Order of Merit. There have been suggestions from others the spotlight on the teenager means world number one Humphries, 29, has been denied the coverage he deserves, but no darts player has made a mark at such a young age as Littler. \"Luke Humphries is another fabulous player who is going to be around for years. Sport is a very brutal world. It is about winning and claiming the high ground. There will be envy around,\" Hearn said. \"Luke Littler is the next Tiger Woods for darts so they better get used to it, and the only way to compete is to get better.\" World number 38 Martin Lukeman was awestruck as he described facing a peak Littler after being crushed 16-3 in the Grand Slam final, with the teenager winning 15 consecutive legs. \"I can't compete with that, it was like Godly. He was relentless, he is so good it's ridiculous,\" he said. Lukeman can still see the benefits he brings, adding: \"What he's done for the sport is brilliant. If it wasn't for him, our wages wouldn't be going up. There's more sponsors, more money coming in, all good.\" Hearn feels future competition may come from players even younger than Littler. \"I watched a 10-year-old a few months ago who averaged 104.89 and checked out a 4-3 win with a 136 finish. They smell the money, the fame and put the hard work in,\" he said. How much better Littler can get is guesswork, although Plummer believes he wants to reach new heights. \"He never says 'how good was I?' But I think he wants to break records and beat Phil Taylor's 16 World Championships and 16 World Matchplay titles,\" he said. \"He's young enough to do it.\" A version of this article was originally published on 29 November.\n",
            "• None Know a lot about Littler? Take our quiz\n",
            "--------------------------------------------------------------------------------\n",
            "Distance: 0.3900, Text: Luke Littler has risen from 164th to fourth in the rankings in a year\n",
            "\n",
            "A tearful Luke Littler hit a tournament record 140.91 set average as he started his bid for the PDC World Championship title with a dramatic 3-1 win over Ryan Meikle. The 17-year-old made headlines around the world when he reached the tournament final in January, where he lost to Luke Humphries. Starting this campaign on Saturday, Littler was millimetres away from a nine-darter when he missed double 12 as he blew Meikle away in the fourth and final set of the second-round match. Littler was overcome with emotion at the end, cutting short his on-stage interview. \"It was probably the toughest game I've ever played. I had to fight until the end,\" he said later in a news conference. \"As soon as the question came on stage and then boom, the tears came. It was just a bit too much to speak on stage. \"It is the worst game I have played. I have never felt anything like that tonight.\" Admitting to nerves during the match, he told Sky Sports: \"Yes, probably the biggest time it's hit me. Coming into it I was fine, but as soon as [referee] George Noble said 'game on', I couldn't throw them.\" Littler started slowly against Meikle, who had two darts for the opening set, but he took the lead by twice hitting double 20. Meikle did not look overawed against his fellow Englishman and levelled, but Littler won the third set and exploded into life in the fourth. The tournament favourite hit four maximum 180s as he clinched three straight legs in 11, 10 and 11 darts for a record set average, and 100.85 overall. Meanwhile, two seeds crashed out on Saturday night – five-time world champion Raymond van Barneveld lost to Welshman Nick Kenny, while England's Ryan Joyce beat Danny Noppert. Australian Damon Heta was another to narrowly miss out on a nine-darter, just failing on double 12 when throwing for the match in a 3-1 win over Connor Scutt. Ninth seed Heta hit four 100-plus checkouts to come from a set down against Scutt in a match in which both men averaged more than 97.\n",
            "\n",
            "Littler was hugged by his parents after victory over Meikle\n",
            "\n... (output truncated for brevity)\n"
          ]
        }
      ],
      "source": [
        "query = \"What were Luke Littler's key achievements and records in his recent PDC World Championship match?\"\n",
        "\n",
        "try:\n",
        "    # Perform the semantic search\n",
        "    start_time = time.time()\n",
        "    search_results = vector_store.similarity_search_with_score(query, k=10)\n",
        "    search_elapsed_time = time.time() - start_time\n",
        "\n",
        "    logging.info(f\"Semantic search completed in {search_elapsed_time:.2f} seconds\")\n",
        "\n",
        "    # Display search results\n",
        "    print(f\"\\nSemantic Search Results (completed in {search_elapsed_time:.2f} seconds):\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for doc, score in search_results:\n",
        "        print(f\"Distance: {score:.4f}, Text: {doc.page_content}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "except CouchbaseException as e:\n",
        "    raise RuntimeError(f\"Error performing semantic search: {str(e)}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Unexpected error: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimizing Vector Search with Global Secondary Index (GSI)\n",
        "\n",
        "While the above semantic search using similarity_search_with_score works effectively, we can significantly improve query performance by leveraging Global Secondary Index (GSI) in Couchbase.\n",
        "\n",
        "Couchbase offers three types of vector indexes, but for GSI-based vector search we focus on two main types:\n",
        "\n",
        "Hyperscale Vector Indexes (BHIVE)\n",
        "- Best for pure vector searches - content discovery, recommendations, semantic search\n",
        "- High performance with low memory footprint - designed to scale to billions of vectors\n",
        "- Optimized for concurrent operations - supports simultaneous searches and inserts\n",
        "- Use when: You primarily perform vector-only queries without complex scalar filtering\n",
        "- Ideal for: Large-scale semantic search, recommendation systems, content discovery\n",
        "\n",
        "Composite Vector Indexes \n",
        "- Best for filtered vector searches - combines vector search with scalar value filtering\n",
        "- Efficient pre-filtering - scalar attributes reduce the vector comparison scope\n",
        "- Use when: Your queries combine vector similarity with scalar filters that eliminate large portions of data\n",
        "- Ideal for: Compliance-based filtering, user-specific searches, time-bounded queries\n",
        "\n",
        "Choosing the Right Index Type\n",
        "- Start with Hyperscale Vector Index for pure vector searches and large datasets\n",
        "- Use Composite Vector Index when scalar filters significantly reduce your search space\n",
        "- Consider your dataset size: Hyperscale scales to billions, Composite works well for tens of millions to billions\n",
        "\n",
        "For more information on GSI vector indexes, see [Couchbase GSI Vector Documentation](https://docs.couchbase.com/cloud/vector-index/use-vector-indexes.html).\n",
        "\n",
        "\n",
        "## Understanding Index Configuration (Couchbase 8.0 Feature)\n",
        "\n",
        "The index_description parameter controls how Couchbase optimizes vector storage and search performance through centroids and quantization:\n",
        "\n",
        "Format: `'IVF[<centroids>],{PQ|SQ}<settings>'`\n",
        "\n",
        "Centroids (IVF - Inverted File):\n",
        "- Controls how the dataset is subdivided for faster searches\n",
        "- More centroids = faster search, slower training  \n",
        "- Fewer centroids = slower search, faster training\n",
        "- If omitted (like IVF,SQ8), Couchbase auto-selects based on dataset size\n",
        "\n",
        "Quantization Options:\n",
        "- SQ (Scalar Quantization): SQ4, SQ6, SQ8 (4, 6, or 8 bits per dimension)\n",
        "- PQ (Product Quantization): PQ<subquantizers>x<bits> (e.g., PQ32x8)\n",
        "- Higher values = better accuracy, larger index size\n",
        "\n",
        "Common Examples:\n",
        "- IVF,SQ8 - Auto centroids, 8-bit scalar quantization (good default)\n",
        "- IVF1000,SQ6 - 1000 centroids, 6-bit scalar quantization  \n",
        "- IVF,PQ32x8 - Auto centroids, 32 subquantizers with 8 bits\n",
        "\n",
        "For detailed configuration options, see the [Quantization & Centroid Settings](https://docs.couchbase.com/cloud/vector-index/hyperscale-vector-index.html#algo_settings).\n",
        "\n",
        "In the code below, we demonstrate creating a BHIVE index. This method takes an index type (BHIVE or COMPOSITE) and description parameter for optimization settings. Alternatively, GSI indexes can be created manually from the Couchbase UI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store.create_index(index_type=IndexType.BHIVE, index_name=\"openrouterdeepseek_bhive_index\",index_description=\"IVF,SQ8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The example below shows running the same similarity search, but now using the BHIVE GSI index we created above. You'll notice improved performance as the index efficiently retrieves data.\n",
        "\n",
        "**Important**: When using Composite indexes, scalar filters take precedence over vector similarity, which can improve performance for filtered searches but may miss some semantically relevant results that don't match the scalar criteria.\n",
        "\n",
        "Note: In GSI vector search, the distance represents the vector distance between the query and document embeddings. Lower distance indicate higher similarity, while higher distance indicate lower similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-18 11:17:19,626 - INFO - Semantic search completed in 0.88 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Semantic Search Results (completed in 0.88 seconds):\n",
            "--------------------------------------------------------------------------------\n",
            "Distance: 0.3694, Text: The Littler effect - how darts hit the bullseye\n",
            "\n",
            "Teenager Luke Littler began his bid to win the 2025 PDC World Darts Championship with a second-round win against Ryan Meikle. Here we assess Littler's impact after a remarkable rise which saw him named BBC Young Sports Personality of the Year and runner-up in the main award to athlete Keely Hodgkinson.\n",
            "\n",
            "One year ago, he was barely a household name in his own home. Now he is a sporting phenomenon. After emerging from obscurity aged 16 to reach the World Championship final, the life of Luke Littler and the sport he loves has been transformed. Viewing figures, ticket sales and social media interest have rocketed. Darts has hit the bullseye. This Christmas more than 100,000 children are expected to be opening Littler-branded magnetic dartboards as presents. His impact has helped double the number of junior academies, prompted plans to expand the World Championship and generated interest in darts from Saudi Arabian backers.\n",
            "\n",
            "Just months after taking his GCSE exams and ranked 164th in the world, Littler beat former champions Raymond van Barneveld and Rob Cross en route to the PDC World Championship final in January, before his run ended with a 7-4 loss to Luke Humphries. With his nickname 'The Nuke' on his purple and yellow shirt and the Alexandra Palace crowd belting out his walk-on song, Pitbull's tune Greenlight, he became an instant hit. Electric on the stage, calm off it. The down-to-earth teenager celebrated with a kebab and computer games. \"We've been watching his progress since he was about seven. He was on our radar, but we never anticipated what would happen. The next thing we know 'Littlermania' is spreading everywhere,\" PDC president Barry Hearn told BBC Sport. A peak TV audience of 3.7 million people watched the final - easily Sky's biggest figure for a non-football sporting event. The teenager from Warrington in Cheshire was too young to legally drive or drink alcohol, but earned £200,000 for finishing second - part of £1m prize money in his first year as a professional - and an invitation to the elite Premier League competition. He turned 17 later in January but was he too young for the demanding event over 17 Thursday nights in 17 locations? He ended up winning the whole thing, and hit a nine-dart finish against Humphries in the final. From Bahrain to Wolverhampton, Littler claimed 10 titles in 2024 and is now eyeing the World Championship.\n",
            "\n",
            "As he progressed at the Ally Pally, the Manchester United fan was sent a good luck message by the club's former midfielder and ex-England captain David Beckham. In 12 months, Littler's Instagram followers have risen from 4,000 to 1.3m. Commercial backers include a clothing range, cereal firm and train company and he will appear in a reboot of the TV darts show Bullseye. Google say he was the most searched-for athlete online in the UK during 2024. On the back of his success, Littler darts, boards, cabinets, shirts are being snapped up in big numbers. \"This Christmas the junior magnetic dartboard is selling out, we're talking over 100,000. They're 20 quid and a great introduction for young children,\" said Garry Plummer, the boss of sponsors Target Darts, who first signed a deal with Littler's family when he was aged 12. \"All the toy shops want it, they all want him - 17, clean, doesn't drink, wonderful.\"\n",
            "\n",
            "Littler beat Luke Humphries to win the Premier League title in May\n",
            "\n",
            "The number of academies for children under the age of 16 has doubled in the last year, says Junior Darts Corporation chairman Steve Brown. There are 115 dedicated groups offering youngsters equipment, tournaments and a place to develop, with bases including Australia, Bulgaria, Greece, Norway, USA and Mongolia. \"We've seen so many inquiries from around the world, it's been such a boom. It took us 14 years to get 1,600 members and within 12 months we have over 3,000, and waiting lists,\" said Brown. \"When I played darts as a child, I was quite embarrassed to tell my friends what my hobby was. All these kids playing darts now are pretty popular at school. It's a bit rock 'n roll and recognised as a cool thing to do.\" Plans are being hatched to extend the World Championship by four days and increase the number of players from 96 to 128. That will boost the number of tickets available by 25,000 to 115,000 but Hearn reckons he could sell three times as many. He says Saudi Arabia wants to host a tournament, which is likely to happen if no-alcohol regulations are relaxed. \"They will change their rules in the next 12 months probably for certain areas having alcohol, and we'll take darts there and have a party in Saudi,\" he said. \"When I got involved in darts, the total prize money was something like £300,000 for the year. This year it will go to £20m. I expect in five years' time, we'll be playing for £40m.\"\n",
            "\n",
            "Former electrician Cross charged to the 2018 world title in his first full season, while Adrian Lewis and Michael van Gerwen were multiple victors in their 20s and 16-time champion Phil ‘The Power’ Taylor is widely considered the greatest of all time. Littler is currently fourth in the world rankings, although that is based on a two-year Order of Merit. There have been suggestions from others the spotlight on the teenager means world number one Humphries, 29, has been denied the coverage he deserves, but no darts player has made a mark at such a young age as Littler. \"Luke Humphries is another fabulous player who is going to be around for years. Sport is a very brutal world. It is about winning and claiming the high ground. There will be envy around,\" Hearn said. \"Luke Littler is the next Tiger Woods for darts so they better get used to it, and the only way to compete is to get better.\" World number 38 Martin Lukeman was awestruck as he described facing a peak Littler after being crushed 16-3 in the Grand Slam final, with the teenager winning 15 consecutive legs. \"I can't compete with that, it was like Godly. He was relentless, he is so good it's ridiculous,\" he said. Lukeman can still see the benefits he brings, adding: \"What he's done for the sport is brilliant. If it wasn't for him, our wages wouldn't be going up. There's more sponsors, more money coming in, all good.\" Hearn feels future competition may come from players even younger than Littler. \"I watched a 10-year-old a few months ago who averaged 104.89 and checked out a 4-3 win with a 136 finish. They smell the money, the fame and put the hard work in,\" he said. How much better Littler can get is guesswork, although Plummer believes he wants to reach new heights. \"He never says 'how good was I?' But I think he wants to break records and beat Phil Taylor's 16 World Championships and 16 World Matchplay titles,\" he said. \"He's young enough to do it.\" A version of this article was originally published on 29 November.\n",
            "• None Know a lot about Littler? Take our quiz\n",
            "--------------------------------------------------------------------------------\n",
            "Distance: 0.3901, Text: Luke Littler has risen from 164th to fourth in the rankings in a year\n",
            "\n",
            "A tearful Luke Littler hit a tournament record 140.91 set average as he started his bid for the PDC World Championship title with a dramatic 3-1 win over Ryan Meikle. The 17-year-old made headlines around the world when he reached the tournament final in January, where he lost to Luke Humphries. Starting this campaign on Saturday, Littler was millimetres away from a nine-darter when he missed double 12 as he blew Meikle away in the fourth and final set of the second-round match. Littler was overcome with emotion at the end, cutting short his on-stage interview. \"It was probably the toughest game I've ever played. I had to fight until the end,\" he said later in a news conference. \"As soon as the question came on stage and then boom, the tears came. It was just a bit too much to speak on stage. \"It is the worst game I have played. I have never felt anything like that tonight.\" Admitting to nerves during the match, he told Sky Sports: \"Yes, probably the biggest time it's hit me. Coming into it I was fine, but as soon as [referee] George Noble said 'game on', I couldn't throw them.\" Littler started slowly against Meikle, who had two darts for the opening set, but he took the lead by twice hitting double 20. Meikle did not look overawed against his fellow Englishman and levelled, but Littler won the third set and exploded into life in the fourth. The tournament favourite hit four maximum 180s as he clinched three straight legs in 11, 10 and 11 darts for a record set average, and 100.85 overall. Meanwhile, two seeds crashed out on Saturday night – five-time world champion Raymond van Barneveld lost to Welshman Nick Kenny, while England's Ryan Joyce beat Danny Noppert. Australian Damon Heta was another to narrowly miss out on a nine-darter, just failing on double 12 when throwing for the match in a 3-1 win over Connor Scutt. Ninth seed Heta hit four 100-plus checkouts to come from a set down against Scutt in a match in which both men averaged more than 97.\n",
            "\n",
            "Littler was hugged by his parents after victory over Meikle\n",
            "\n... (output truncated for brevity)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "query = \"What were Luke Littler's key achievements and records in his recent PDC World Championship match?\"\n",
        "\n",
        "try:\n",
        "    # Perform the semantic search\n",
        "    start_time = time.time()\n",
        "    search_results = vector_store.similarity_search_with_score(query, k=10)\n",
        "    search_elapsed_time = time.time() - start_time\n",
        "\n",
        "    logging.info(f\"Semantic search completed in {search_elapsed_time:.2f} seconds\")\n",
        "\n",
        "    # Display search results\n",
        "    print(f\"\\nSemantic Search Results (completed in {search_elapsed_time:.2f} seconds):\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for doc, score in search_results:\n",
        "        print(f\"Distance: {score:.4f}, Text: {doc.page_content}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "except CouchbaseException as e:\n",
        "    raise RuntimeError(f\"Error performing semantic search: {str(e)}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Unexpected error: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: To create a COMPOSITE index, the below code can be used.\n",
        "Choose based on your specific use case and query patterns. For this tutorial's news search scenario, either index type would work, but BHIVE might be more efficient for pure semantic search across news articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store.create_index(index_type=IndexType.COMPOSITE, index_name=\"openrouterdeepseek_composite_index\", index_description=\"IVF,SQ8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting Up a Couchbase Cache\n",
        "To further optimize our system, we set up a Couchbase-based cache. A cache is a temporary storage layer that holds data that is frequently accessed, speeding up operations by reducing the need to repeatedly retrieve the same information from the database. In our setup, the cache will help us accelerate repetitive tasks, such as looking up similar documents. By implementing a cache, we enhance the overall performance of our search engine, ensuring that it can handle high query volumes and deliver results quickly.\n",
        "\n",
        "Caching is particularly valuable in scenarios where users may submit similar queries multiple times or where certain pieces of information are frequently requested. By storing these in a cache, we can significantly reduce the time it takes to respond to these queries, improving the user experience.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-17 16:10:11,473 - INFO - Successfully created cache\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    cache = CouchbaseCache(\n",
        "        cluster=cluster,\n",
        "        bucket_name=CB_BUCKET_NAME,\n",
        "        scope_name=SCOPE_NAME,\n",
        "        collection_name=CACHE_COLLECTION,\n",
        "    )\n",
        "    logging.info(\"Successfully created cache\")\n",
        "    set_llm_cache(cache)\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Failed to create cache: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieval-Augmented Generation (RAG) with Couchbase and LangChain\n",
        "Couchbase and LangChain can be seamlessly integrated to create RAG (Retrieval-Augmented Generation) chains, enhancing the process of generating contextually relevant responses. In this setup, Couchbase serves as the vector store, where embeddings of documents are stored. When a query is made, LangChain retrieves the most relevant documents from Couchbase by comparing the query’s embedding with the stored document embeddings. These documents, which provide contextual information, are then passed to a generative language model within LangChain.\n",
        "\n",
        "The language model, equipped with the context from the retrieved documents, generates a response that is both informed and contextually accurate. This integration allows the RAG chain to leverage Couchbase’s efficient storage and retrieval capabilities, while LangChain handles the generation of responses based on the context provided by the retrieved documents. Together, they create a powerful system that can deliver highly relevant and accurate answers by combining the strengths of both retrieval and generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-18 11:18:34,032 - INFO - Successfully created RAG chain\n"
          ]
        }
      ],
      "source": [
        "# Create RAG prompt template\n",
        "rag_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that answers questions based on the provided context.\"),\n",
        "    (\"human\", \"Context: {context}\\n\\nQuestion: {question}\")\n",
        "])\n",
        "\n",
        "# Create RAG chain\n",
        "rag_chain = (\n",
        "    {\"context\": vector_store.as_retriever(), \"question\": RunnablePassthrough()}\n",
        "    | rag_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "logging.info(\"Successfully created RAG chain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAG Response: Based on the provided context, Luke Littler's key achievements and records in his recent PDC World Championship match (second-round win against Ryan Meikle) were:\n",
            "\n",
            "*   **Tournament Record Set Average:** He hit a tournament record 140.91 set average during the match.\n",
            "*   **Near Nine-Darter:** He was \"millimetres away from a nine-darter\" when he missed double 12.\n",
            "*   **Dominant Final Set:** He won the fourth and final set in just 32 darts (the minimum possible is 27), which included hitting four maximum 180s and clinching three straight legs in 11, 10, and 11 darts.\n",
            "*   **Overall High Average:** He maintained a high overall match average of 100.85.\n",
            "RAG response generated in 0.49 seconds\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    start_time = time.time()\n",
        "    rag_response = rag_chain.invoke(query)\n",
        "    rag_elapsed_time = time.time() - start_time\n",
        "\n",
        "    print(f\"RAG Response: {rag_response}\")\n",
        "    print(f\"RAG response generated in {rag_elapsed_time:.2f} seconds\")\n",
        "except InternalServerFailureException as e:\n",
        "    if \"query request rejected\" in str(e):\n",
        "        print(\"Error: Search request was rejected due to rate limiting. Please try again later.\")\n",
        "    else:\n",
        "        print(f\"Internal server error occurred: {str(e)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Unexpected error occurred: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Couchbase as a caching mechanism\n",
        "Couchbase can be effectively used as a caching mechanism for RAG (Retrieval-Augmented Generation) responses by storing and retrieving precomputed results for specific queries. This approach enhances the system's efficiency and speed, particularly when dealing with repeated or similar queries. When a query is first processed, the RAG chain retrieves relevant documents, generates a response using the language model, and then stores this response in Couchbase, with the query serving as the key.\n",
        "\n",
        "For subsequent requests with the same query, the system checks Couchbase first. If a cached response is found, it is retrieved directly from Couchbase, bypassing the need to re-run the entire RAG process. This significantly reduces response time because the computationally expensive steps of document retrieval and response generation are skipped. Couchbase's role in this setup is to provide a fast and scalable storage solution for caching these responses, ensuring that frequently asked queries can be answered more quickly and efficiently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query 1: What happened in the match between Fullham and Liverpool?\n",
            "Response: In the match between Fulham and Liverpool, Liverpool played the majority of the game with 10 men after Andy Robertson received a red card in the 17th minute. Despite being a player down, Liverpool came from behind twice to secure a 2-2 draw. Diogo Jota scored an 86th-minute equalizer to earn Liverpool a point. The performance was praised for its resilience, with Fulham's Antonee Robinson noting that Liverpool \"didn't feel like they had 10 men at all.\" Liverpool maintained over 60% possession and led in attacking metrics such as shots and chances. Both managers acknowledged the strong efforts of their teams in what was described as an enthralling encounter.\n",
            "Time taken: 4.65 seconds\n",
            "\n",
            "Query 2: What were Luke Littler's key achievements and records in his recent PDC World Championship match?\n",
            "Response: Based on the provided context, Luke Littler's key achievements and records in his recent PDC World Championship match (second-round win against Ryan Meikle) were:\n",
            "\n",
            "*   **Tournament Record Set Average:** He hit a tournament record 140.91 set average during the match.\n",
            "*   **Near Nine-Darter:** He was \"millimetres away from a nine-darter\" when he missed double 12.\n",
            "*   **Dominant Final Set:** He won the fourth and final set in just 32 darts (the minimum possible is 27), which included hitting four maximum 180s and clinching three straight legs in 11, 10, and 11 darts.\n",
            "*   **Overall High Average:** He maintained a high overall match average of 100.85.\n",
            "Time taken: 0.45 seconds\n",
            "\n",
            "Query 3: What happened in the match between Fullham and Liverpool?\n",
            "Response: In the match between Fulham and Liverpool, Liverpool played the majority of the game with 10 men after Andy Robertson received a red card in the 17th minute. Despite being a player down, Liverpool came from behind twice to secure a 2-2 draw. Diogo Jota scored an 86th-minute equalizer to earn Liverpool a point. The performance was praised for its resilience, with Fulham's Antonee Robinson noting that Liverpool \"didn't feel like they had 10 men at all.\" Liverpool maintained over 60% possession and led in attacking metrics such as shots and chances. Both managers acknowledged the strong efforts of their teams in what was described as an enthralling encounter.\n",
            "Time taken: 1.15 seconds\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    queries = [\n",
        "        \"What happened in the match between Fullham and Liverpool?\",\n",
        "        \"What were Luke Littler's key achievements and records in his recent PDC World Championship match?\", # Repeated query\n",
        "        \"What happened in the match between Fullham and Liverpool?\", # Repeated query\n",
        "    ]\n",
        "\n",
        "    for i, query in enumerate(queries, 1):\n",
        "        print(f\"\\nQuery {i}: {query}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        response = rag_chain.invoke(query)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"Response: {response}\")\n",
        "        print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "except InternalServerFailureException as e:\n",
        "    if \"query request rejected\" in str(e):\n",
        "        print(\"Error: Search request was rejected due to rate limiting. Please try again later.\")\n",
        "    else:\n",
        "        print(f\"Internal server error occurred: {str(e)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Unexpected error occurred: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "By following these steps, you'll have a fully functional semantic search engine that leverages the strengths of Couchbase and Deepseek(via Openrouter). This guide is designed not just to show you how to build the system, but also to explain why each step is necessary, giving you a deeper understanding of the principles behind semantic search and how to implement it effectively. Whether you're a newcomer to software development or an experienced developer looking to expand your skills, this guide will provide you with the knowledge and tools you need to create a powerful, AI-driven search engine."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}