{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this guide, we will walk you through building a powerful semantic search engine using Couchbase as the backend database and [Amazon Bedrock](https://aws.amazon.com/bedrock/) as both the embedding and language model provider. Semantic search goes beyond simple keyword matching by understanding the context and meaning behind the words in a query, making it an essential tool for applications that require intelligent information retrieval. This tutorial is designed to be beginner-friendly, with clear, step-by-step instructions that will equip you with the knowledge to create a fully functional semantic search system using Couchbase Hyperscale and Composite Vector Index from scratch. Alternatively if you want to perform semantic search using the Search Vector Index, please take a look at [this.](https://developer.couchbase.com/tutorial-aws-bedrock-couchbase-rag-with-search-vector-index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run this tutorial\n",
    "\n",
    "This tutorial is available as a Jupyter Notebook (`.ipynb` file) that you can run interactively. You can access the original notebook [here](https://github.com/couchbase-examples/vector-search-cookbook/blob/main/awsbedrock/query_based/RAG_with_Couchbase_and_Bedrock.ipynb).\n",
    "\n",
    "You can either download the notebook file and run it on [Google Colab](https://colab.research.google.com/) or run it on your system by setting up the Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "### Get Credentials for AWS Bedrock\n",
    "* Please follow the [instructions](https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html) to set up AWS Bedrock and generate credentials.\n",
    "* Ensure you have the necessary IAM permissions to access Bedrock services.\n",
    "\n",
    "### Create and Deploy Your Free Tier Operational cluster on Capella\n",
    "\n",
    "To get started with Couchbase Capella, create an account and use it to deploy a forever free tier operational cluster. This account provides you with an environment where you can explore and learn about Capella with no time constraint.\n",
    "\n",
    "To know more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).\n",
    "\n",
    "Note: To run this tutorial, you will need Capella with Couchbase Server version 8.0 or above as Hyperscale and Composite Vector Index is supported only from version 8.0\n",
    "\n",
    "#### Couchbase Capella Configuration\n",
    "\n",
    "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met.\n",
    "\n",
    "* Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the bucket (Read and Write) used in the application.\n",
    "* [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Stage: Installing Necessary Libraries\n",
    "\n",
    "To build our semantic search engine, we need a robust set of tools. The libraries we install handle everything from connecting to databases to performing complex machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --no-user --quiet datasets==3.5.0 langchain-couchbase==1.0.1 langchain-aws boto3 python-dotenv==1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "\n",
    "The script starts by importing a series of libraries required for various tasks, including handling JSON, logging, time tracking, Couchbase connections, embedding generation, and dataset loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaustavghosh/Desktop/vector-search-cookbook/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import boto3\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.exceptions import (CouchbaseException,\n",
    "                                InternalServerFailureException)\n",
    "from couchbase.management.buckets import CreateBucketSettings\n",
    "from couchbase.options import ClusterOptions\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from langchain_aws import BedrockEmbeddings, ChatBedrock\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_couchbase.cache import CouchbaseCache\n",
    "from langchain_couchbase.vectorstores import CouchbaseQueryVectorStore\n",
    "from langchain_couchbase.vectorstores import DistanceStrategy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Logging\n",
    "\n",
    "Logging is configured to track the progress of the script and capture any errors or warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n",
    "\n",
    "# Suppress excessive logging from libraries\n",
    "logging.getLogger('httpx').setLevel(logging.WARNING)\n",
    "logging.getLogger('httpcore').setLevel(logging.WARNING)\n",
    "logging.getLogger('botocore').setLevel(logging.WARNING)\n",
    "logging.getLogger('urllib3').setLevel(logging.WARNING)\n",
    "logging.getLogger('langchain_aws.llms.bedrock').setLevel(logging.WARNING)\n",
    "logging.getLogger('langchain_aws.embeddings.bedrock').setLevel(logging.WARNING)\n",
    "logging.getLogger('langchain_aws').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Sensitive Information\n",
    "In this section, we prompt the user to input essential configuration settings needed. These settings include sensitive information like AWS credentials, database credentials, and specific configuration names. Instead of hardcoding these details into the script, we request the user to provide them at runtime, ensuring flexibility and security.\n",
    "\n",
    "The project includes an `.env.sample` file that lists all the environment variables. To get started:\n",
    "\n",
    "1. Create a `.env` file in the same directory as this notebook\n",
    "2. Copy the contents from `.env.sample` to your `.env` file\n",
    "3. Fill in the required credentials\n",
    "\n",
    "The script also validates that all required inputs are provided, raising an error if any crucial information is missing. This approach ensures that your integration is both secure and correctly configured without hardcoding sensitive information, enhancing the overall security and maintainability of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load environment variables from .env file if it exists\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# AWS Credentials\n",
    "AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID') or input('Enter your AWS Access Key ID: ')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY') or getpass.getpass('Enter your AWS Secret Access Key: ')\n",
    "AWS_REGION = os.getenv('AWS_REGION') or input('Enter your AWS region (default: us-east-1): ') or 'us-east-1'\n",
    "\n",
    "# Couchbase Settings\n",
    "CB_HOST = os.getenv('CB_HOST') or input('Enter your Couchbase host (default: couchbase://localhost): ') or 'couchbase://localhost'\n",
    "CB_USERNAME = os.getenv('CB_USERNAME') or input('Enter your Couchbase username (default: Administrator): ') or 'Administrator'\n",
    "CB_PASSWORD = os.getenv('CB_PASSWORD') or getpass.getpass('Enter your Couchbase password (default: password): ') or 'password'\n",
    "CB_BUCKET_NAME = os.getenv('CB_BUCKET_NAME') or input('Enter your Couchbase bucket name (default: query-vector-search-testing): ') or 'query-vector-search-testing'\n",
    "SCOPE_NAME = os.getenv('SCOPE_NAME') or input('Enter your scope name (default: shared): ') or 'shared'\n",
    "COLLECTION_NAME = os.getenv('COLLECTION_NAME') or input('Enter your collection name (default: bedrock): ') or 'bedrock'\n",
    "CACHE_COLLECTION = os.getenv('CACHE_COLLECTION') or input('Enter your cache collection name (default: cache): ') or 'cache'\n",
    "\n",
    "# Check if required credentials are set\n",
    "for cred_name, cred_value in {\n",
    "    'AWS_ACCESS_KEY_ID': AWS_ACCESS_KEY_ID,\n",
    "    'AWS_SECRET_ACCESS_KEY': AWS_SECRET_ACCESS_KEY, \n",
    "    'CB_HOST': CB_HOST,\n",
    "    'CB_USERNAME': CB_USERNAME,\n",
    "    'CB_PASSWORD': CB_PASSWORD,\n",
    "    'CB_BUCKET_NAME': CB_BUCKET_NAME\n",
    "}.items():\n",
    "    if not cred_value:\n",
    "        raise ValueError(f\"{cred_name} is not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the Couchbase Cluster\n",
    "Connecting to a Couchbase cluster is the foundation of our project. Couchbase will serve as our primary data store, handling all the storage and retrieval operations required for our semantic search engine. By establishing this connection, we enable our application to interact with the database, allowing us to perform operations such as storing embeddings, querying data, and managing collections. This connection is the gateway through which all data will flow, so ensuring it's set up correctly is paramount.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:20:11,530 - INFO - Successfully connected to Couchbase\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
    "    options = ClusterOptions(auth)\n",
    "    cluster = Cluster(CB_HOST, options)\n",
    "    cluster.wait_until_ready(timedelta(seconds=5))\n",
    "    logging.info(\"Successfully connected to Couchbase\")\n",
    "except Exception as e:\n",
    "    raise ConnectionError(f\"Failed to connect to Couchbase: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Collections in Couchbase\n",
    "\n",
    "The setup_collection() function handles creating and configuring the hierarchical data organization in Couchbase:\n",
    "\n",
    "1. Bucket Creation:\n",
    "   - Checks if specified bucket exists, creates it if not\n",
    "   - Sets bucket properties like RAM quota (1024MB) and replication (disabled)\n",
    "   - Note: You will not be able to create a bucket on Capella\n",
    "\n",
    "2. Scope Management:  \n",
    "   - Verifies if requested scope exists within bucket\n",
    "   - Creates new scope if needed (unless it's the default \"_default\" scope)\n",
    "\n",
    "3. Collection Setup:\n",
    "   - Checks for collection existence within scope\n",
    "   - Creates collection if it doesn't exist\n",
    "   - Waits 2 seconds for collection to be ready\n",
    "\n",
    "Additional Tasks:\n",
    "- Clears any existing documents for clean state\n",
    "- Implements comprehensive error handling and logging\n",
    "\n",
    "The function is called twice to set up:\n",
    "1. Main collection for vector embeddings\n",
    "2. Cache collection for storing results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:20:11,543 - INFO - Bucket 'vector-search-testing' exists.\n",
      "2026-02-05 13:20:11,546 - INFO - Collection 'bedrock' already exists.\n",
      "2026-02-05 13:20:13,672 - INFO - Collection 'bedrock' cleared.\n",
      "2026-02-05 13:20:13,672 - INFO - Bucket 'vector-search-testing' exists.\n",
      "2026-02-05 13:20:13,674 - INFO - Collection 'cache' already exists.\n",
      "2026-02-05 13:20:15,682 - INFO - Collection 'cache' cleared.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<couchbase.collection.Collection at 0x111a98080>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setup_collection(cluster, bucket_name, scope_name, collection_name):\n",
    "    try:\n",
    "        # Check if bucket exists, create if it doesn't\n",
    "        try:\n",
    "            bucket = cluster.bucket(bucket_name)\n",
    "            logging.info(f\"Bucket '{bucket_name}' exists.\")\n",
    "        except Exception as e:\n",
    "            logging.info(f\"Bucket '{bucket_name}' does not exist. Creating it...\")\n",
    "            bucket_settings = CreateBucketSettings(\n",
    "                name=bucket_name,\n",
    "                bucket_type='couchbase',\n",
    "                ram_quota_mb=1024,\n",
    "                flush_enabled=True,\n",
    "                num_replicas=0\n",
    "            )\n",
    "            cluster.buckets().create_bucket(bucket_settings)\n",
    "            time.sleep(2)\n",
    "            bucket = cluster.bucket(bucket_name)\n",
    "            logging.info(f\"Bucket '{bucket_name}' created successfully.\")\n",
    "\n",
    "        bucket_manager = bucket.collections()\n",
    "\n",
    "        # Check if scope exists, create if it doesn't\n",
    "        scopes = bucket_manager.get_all_scopes()\n",
    "        scope_exists = any(scope.name == scope_name for scope in scopes)\n",
    "        \n",
    "        if not scope_exists and scope_name != \"_default\":\n",
    "            logging.info(f\"Scope '{scope_name}' does not exist. Creating it...\")\n",
    "            bucket_manager.create_scope(scope_name)\n",
    "            logging.info(f\"Scope '{scope_name}' created successfully.\")\n",
    "            scopes = bucket_manager.get_all_scopes()\n",
    "\n",
    "        # Check if collection exists, create if it doesn't\n",
    "        collection_exists = any(\n",
    "            scope.name == scope_name and collection_name in [col.name for col in scope.collections]\n",
    "            for scope in scopes\n",
    "        )\n",
    "\n",
    "        if not collection_exists:\n",
    "            logging.info(f\"Collection '{collection_name}' does not exist. Creating it...\")\n",
    "            bucket_manager.create_collection(scope_name, collection_name)\n",
    "            logging.info(f\"Collection '{collection_name}' created successfully.\")\n",
    "        else:\n",
    "            logging.info(f\"Collection '{collection_name}' already exists.\")\n",
    "\n",
    "        # Wait for collection to be ready\n",
    "        collection = bucket.scope(scope_name).collection(collection_name)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Create primary index for the collection (required for DELETE operations)\n",
    "        try:\n",
    "            index_keyspace = f\"`{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
    "            cluster.query(f\"CREATE PRIMARY INDEX IF NOT EXISTS ON {index_keyspace}\").execute()\n",
    "        except Exception:\n",
    "            pass  # Index may already exist\n",
    "\n",
    "        # Clear all documents in the collection\n",
    "        try:\n",
    "            query = f\"DELETE FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
    "            cluster.query(query).execute()\n",
    "            logging.info(f\"Collection '{collection_name}' cleared.\")\n",
    "        except Exception:\n",
    "            pass  # Collection might be empty or index not ready\n",
    "\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error setting up collection: {str(e)}\")\n",
    "    \n",
    "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, COLLECTION_NAME)\n",
    "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, CACHE_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Bedrock Embeddings\n",
    "\n",
    "Embeddings are at the heart of semantic search. They are numerical representations of text that capture the semantic meaning of the words and phrases. Unlike traditional keyword-based search, which looks for exact matches, embeddings allow our search engine to understand the context and nuances of language, enabling it to retrieve documents that are semantically similar to the query, even if they don't contain the exact keywords. By creating embeddings using Amazon Bedrock's Titan Embedding model, we equip our search engine with the ability to understand and process natural language in a way that's much closer to how humans understand language. This step transforms our raw text data into a format that the search engine can use to find and rank relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:20:15,790 - INFO - Successfully created Bedrock embeddings client\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bedrock_client = boto3.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name=AWS_REGION,\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    "    )\n",
    "    \n",
    "    embeddings = BedrockEmbeddings(\n",
    "        client=bedrock_client,\n",
    "        model_id=\"amazon.titan-embed-text-v2:0\"\n",
    "    )\n",
    "    logging.info(\"Successfully created Bedrock embeddings client\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error creating Bedrock embeddings client: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Hyperscale and Composite Vector Search\n",
    "\n",
    "### Optimizing Vector Search with Hyperscale and Composite Vector Index\n",
    "\n",
    "With Couchbase 8.0+, you can leverage the power of query-based vector search, which offers significant performance improvements over traditional Full-Text Search (FTS) approaches for vector-first workloads. Hyperscale and Composite Vector Index search provides high-performance vector similarity search with advanced filtering capabilities and is designed to scale to billions of vectors.\n",
    "\n",
    "#### Hyperscale/Composite vs Search Vector Index: Choosing the Right Approach\n",
    "\n",
    "| Feature               | Hyperscale/Composite Vector Index                                               | Search Vector Index                         |\n",
    "| --------------------- | --------------------------------------------------------------- | ----------------------------------------- |\n",
    "| **Best For**          | Vector-first workloads, complex filtering, high QPS performance| Hybrid search and high recall rates      |\n",
    "| **Couchbase Version** | 8.0.0+                                                         | 7.6+                                      |\n",
    "| **Filtering**         | Pre-filtering with `WHERE` clauses (Composite) or post-filtering (Hyperscale) | Pre-filtering with flexible ordering |\n",
    "| **Scalability**       | Up to billions of vectors (Hyperscale)                              | Up to 10 million vectors                  |\n",
    "| **Performance**       | Optimized for concurrent operations with low memory footprint  | Good for mixed text and vector queries   |\n",
    "\n",
    "\n",
    "#### Query-Based Vector Index Types\n",
    "\n",
    "Couchbase offers two distinct query-based vector index types, each optimized for different use cases:\n",
    "\n",
    "##### Hyperscale Vector Indexes\n",
    "\n",
    "- **Best for**: Pure vector searches like content discovery, recommendations, and semantic search\n",
    "- **Use when**: You primarily perform vector-only queries without complex scalar filtering\n",
    "- **Features**: \n",
    "  - High performance with low memory footprint\n",
    "  - Optimized for concurrent operations\n",
    "  - Designed to scale to billions of vectors\n",
    "  - Supports post-scan filtering for basic metadata filtering\n",
    "\n",
    "##### Composite Vector Indexes\n",
    "\n",
    "  - **Best for**: Filtered vector searches that combine vector similarity with scalar value filtering\n",
    "- **Use when**: Your queries combine vector similarity with scalar filters that eliminate large portions of data\n",
    "- **Features**: \n",
    "  - Efficient pre-filtering where scalar attributes reduce the vector comparison scope\n",
    "  - Best for well-defined workloads requiring complex filtering using Hyperscale and Composite Vector Index features\n",
    "  - Supports range lookups combined with vector search\n",
    "\n",
    "#### Index Type Selection for This Tutorial\n",
    "\n",
    "In this tutorial, we'll demonstrate creating a **Hyperscale index** and running vector similarity queries using Hyperscale and Composite Vector Index. Hyperscale is ideal for semantic search scenarios where you want:\n",
    "\n",
    "1. **High-performance vector search** across large datasets\n",
    "2. **Low latency** for real-time applications\n",
    "3. **Scalability** to handle growing vector collections\n",
    "4. **Concurrent operations** for multi-user environments\n",
    "\n",
    "The Hyperscale index will provide optimal performance for our Bedrock embedding-based semantic search implementation.\n",
    "\n",
    "#### Alternative: Composite Vector Index\n",
    "\n",
    "If your use case requires complex filtering with scalar attributes, you may want to consider using a **Composite Vector Index** instead:\n",
    "\n",
    "```python\n",
    "## Alternative: Create a Composite index for filtered searches\n",
    "vector_store.create_index(\n",
    "    index_type=IndexType.COMPOSITE,\n",
    "    index_description=\"IVF,SQ8\",\n",
    "    distance_metric=DistanceStrategy.COSINE,\n",
    "    index_name=\"bedrock_composite_index\",\n",
    ")\n",
    "```\n",
    "\n",
    "**Use Composite indexes when:**\n",
    "- You need to filter by document metadata or attributes before vector similarity\n",
    "- Your queries combine vector search with WHERE clauses\n",
    "- You have well-defined filtering requirements that can reduce the search space\n",
    "\n",
    "**Note**: Composite indexes enable pre-filtering with scalar attributes, making them ideal for applications where you need to search within specific categories, date ranges, or user-specific data segments.\n",
    "\n",
    "#### Understanding Index Configuration (Couchbase 8.0 Feature)\n",
    "\n",
    "Before creating our Hyperscale index, it's important to understand the configuration parameters that optimize vector storage and search performance. The `index_description` parameter controls how Couchbase optimizes vector storage through centroids and quantization.\n",
    "\n",
    "##### Index Description Format: `'IVF[<centroids>],{PQ|SQ}<settings>'`\n",
    "\n",
    "##### Centroids (IVF - Inverted File)\n",
    "\n",
    "- Controls how the dataset is subdivided for faster searches\n",
    "- **More centroids** = faster search, slower training time\n",
    "- **Fewer centroids** = slower search, faster training time\n",
    "- If omitted (like `IVF,SQ8`), Couchbase auto-selects based on dataset size\n",
    "\n",
    "###### Quantization Options\n",
    "\n",
    "**Scalar Quantization (SQ):**\n",
    "- `SQ4`, `SQ6`, `SQ8` (4, 6, or 8 bits per dimension)\n",
    "- Lower memory usage, faster search, slightly reduced accuracy\n",
    "\n",
    "**Product Quantization (PQ):**\n",
    "- Format: `PQ<subquantizers>x<bits>` (e.g., `PQ32x8`)\n",
    "- Better compression for very large datasets\n",
    "- More complex but can maintain accuracy with smaller index size\n",
    "\n",
    "##### Common Configuration Examples\n",
    "\n",
    "- **`IVF,SQ8`** - Auto centroids, 8-bit scalar quantization (good default)\n",
    "- **`IVF1000,SQ6`** - 1000 centroids, 6-bit scalar quantization\n",
    "- **`IVF,PQ32x8`** - Auto centroids, 32 subquantizers with 8 bits\n",
    "\n",
    "For detailed configuration options, see the [Quantization & Centroid Settings](https://docs.couchbase.com/cloud/vector-index/hyperscale-vector-index.html#algo_settings).\n",
    "\n",
    "For more information on query-based vector indexes, see [Couchbase Vector Index Documentation](https://docs.couchbase.com/cloud/vector-index/use-vector-indexes.html).\n",
    "\n",
    "##### Our Configuration Choice\n",
    "\n",
    "In this tutorial, we use `IVF,SQ8` which provides:\n",
    "- **Auto-selected centroids** optimized for our dataset size\n",
    "- **8-bit scalar quantization** for good balance of speed, memory usage, and accuracy\n",
    "- **COSINE distance metric** ideal for semantic similarity search\n",
    "- **Optimal performance** for most semantic search use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Couchbase Query Vector Store\n",
    "A vector store is where we'll keep our embeddings. The query vector store is specifically designed to handle embeddings and perform similarity searches. When a user inputs a query, the query service converts the query into an embedding and compares it against the embeddings stored in the vector store. This allows the engine to find documents that are semantically similar to the query, even if they don't contain the exact same words. By setting up the vector store in Couchbase, we create a powerful tool that enables us to understand and retrieve information based on the meaning and context of the query, rather than just the specific words used.\n",
    "\n",
    "The vector store requires a distance metric to determine how similarity between vectors is calculated. This is crucial for accurate semantic search results as different distance metrics can yield different similarity rankings. Some of the supported Distance strategies are dot, l2, euclidean, cosine, l2_squared, euclidean_squared. In our implementation we will use cosine which is particularly effective for text embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:20:15,801 - INFO - Successfully created vector store\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vector_store = CouchbaseQueryVectorStore(\n",
    "        cluster=cluster,\n",
    "        bucket_name=CB_BUCKET_NAME,\n",
    "        scope_name=SCOPE_NAME,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        embedding = embeddings,\n",
    "        distance_metric=DistanceStrategy.COSINE\n",
    "    )\n",
    "    logging.info(\"Successfully created vector store\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to create vector store: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the BBC News Dataset\n",
    "To build a search engine, we need data to search through. We use the BBC News dataset from RealTimeData, which provides real-world news articles. This dataset contains news articles from BBC covering various topics and time periods. Loading the dataset is a crucial step because it provides the raw material that our search engine will work with. The quality and diversity of the news articles make it an excellent choice for testing and refining our search engine, ensuring it can handle real-world news content effectively.\n",
    "\n",
    "The BBC News dataset allows us to work with authentic news articles, enabling us to build and test a search engine that can effectively process and retrieve relevant news content. The dataset is loaded using the Hugging Face datasets library, specifically accessing the \"RealTimeData/bbc_news_alltime\" dataset with the \"2024-12\" version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:20:19,730 - INFO - Successfully loaded the BBC News dataset with 2687 rows.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the BBC News dataset with 2687 rows\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    news_dataset = load_dataset(\n",
    "        \"RealTimeData/bbc_news_alltime\", \"2024-12\", split=\"train\"\n",
    "    )\n",
    "    print(f\"Loaded the BBC News dataset with {len(news_dataset)} rows\")\n",
    "    logging.info(f\"Successfully loaded the BBC News dataset with {len(news_dataset)} rows.\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading the BBC News dataset: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the Data\n",
    "We will use the content of the news articles for our RAG system.\n",
    "\n",
    "The dataset contains a few duplicate records. We are removing them to avoid duplicate results in the retrieval stage of our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1749 unique articles in our database.\n"
     ]
    }
   ],
   "source": [
    "news_articles = news_dataset[\"content\"]\n",
    "unique_articles = set()\n",
    "for article in news_articles:\n",
    "    if article:\n",
    "        unique_articles.add(article)\n",
    "unique_news_articles = list(unique_articles)\n",
    "print(f\"We have {len(unique_news_articles)} unique articles in our database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data to the Vector Store\n",
    "\n",
    "To efficiently handle the large number of articles, we process them in batches of 50 articles at a time. This batch processing approach helps manage memory usage and provides better control over the ingestion process.\n",
    "\n",
    "We first filter out any articles that exceed 50,000 characters to avoid potential issues with token limits. Then, using the vector store's add_texts method, we add the filtered articles to our vector database. The batch_size parameter controls how many articles are processed in each iteration.\n",
    "\n",
    "This approach offers several benefits:\n",
    "1. Memory Efficiency: Processing in smaller batches prevents memory overload\n",
    "2. Progress Tracking: Easier to monitor and track the ingestion progress\n",
    "3. Resource Management: Better control over CPU and network resource utilization\n",
    "\n",
    "We use a batch size of 50 to ensure reliable operation. The optimal batch size depends on many factors including:\n",
    "- Document sizes being inserted\n",
    "- Available system resources\n",
    "- Network conditions\n",
    "- Concurrent workload\n",
    "\n",
    "Consider measuring performance with your specific workload before adjusting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:30:09,372 - INFO - Document ingestion completed successfully.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "# Filter articles within size limits\n",
    "articles = [article for article in unique_news_articles if article and len(article) <= 50000]\n",
    "\n",
    "try:\n",
    "    vector_store.add_texts(\n",
    "        texts=articles,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    logging.info(\"Document ingestion completed successfully.\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to save documents to vector store: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up LLM Response Cache\n",
    "A cache is set up using Couchbase to store intermediate results and frequently accessed data. Caching is important for improving performance, as it reduces the need to repeatedly calculate or retrieve the same data. The cache is linked to a specific collection in Couchbase, and it is used later in the script to store the results of language model queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:30:09,383 - INFO - Successfully created cache\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cache = CouchbaseCache(\n",
    "        cluster=cluster,\n",
    "        bucket_name=CB_BUCKET_NAME,\n",
    "        scope_name=SCOPE_NAME,\n",
    "        collection_name=CACHE_COLLECTION,\n",
    "    )\n",
    "    logging.info(\"Successfully created cache\")\n",
    "    set_llm_cache(cache)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to create cache: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Amazon Bedrock's Nova Pro Model\n",
    "\n",
    "Amazon Nova is the next-generation foundation model family from Amazon, replacing the Titan Text models. Nova Pro is the most capable model in the Nova family, designed for complex tasks including:\n",
    "\n",
    "- Text generation and completion\n",
    "- Question answering and RAG applications\n",
    "- Summarization and analysis\n",
    "- Multi-step reasoning\n",
    "\n",
    "Key features of Nova Pro:\n",
    "\n",
    "- High accuracy for complex reasoning tasks\n",
    "- Optimized for RAG and agentic workflows\n",
    "- Large context window support\n",
    "- Built-in content filtering and safety controls\n",
    "- Seamlessly integrates with AWS services\n",
    "\n",
    "The model uses a temperature parameter (0-1) to control randomness in responses:\n",
    "- Lower values (e.g. 0) produce more focused, deterministic outputs\n",
    "- Higher values introduce more creativity and variation\n",
    "\n",
    "We'll use Nova Pro through Amazon Bedrock's API to process user queries and generate contextually relevant responses based on our vector database content.\n",
    "\n",
    "**Note**: The Titan Text models (Premier, Express, Lite) reached Legacy status on January 31, 2025 and will EOL on August 15, 2025. Nova Pro is the recommended replacement for Titan Premier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:30:09,493 - INFO - Successfully created Bedrock LLM client with Nova Pro\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    llm = ChatBedrock(\n",
    "        client=bedrock_client,\n",
    "        model_id=\"amazon.nova-pro-v1:0\",\n",
    "        model_kwargs={\"temperature\": 0}\n",
    "    )\n",
    "    logging.info(\"Successfully created Bedrock LLM client with Nova Pro\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error creating Bedrock LLM client: {str(e)}. Please check your AWS credentials and Bedrock access.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Semantic Search in Couchbase\n",
    "\n",
    "Semantic search goes beyond traditional keyword matching by understanding the meaning and context behind queries. Here's how it works in Couchbase:\n",
    "\n",
    "### How Semantic Search Works\n",
    "\n",
    "1. **Vector Embeddings**: Documents and queries are converted into high-dimensional vectors using an embeddings model (in our case, Amazon Bedrock's Titan Embedding model)\n",
    "\n",
    "2. **Similarity Calculation**: When a query is made, Couchbase compares the query vector against stored document vectors using the COSINE distance metric\n",
    "\n",
    "3. **Result Ranking**: Documents are ranked by their vector distance (lower distance = more similar meaning)\n",
    "\n",
    "4. **Flexible Configuration**: Different distance metrics (cosine, euclidean, dot product) and embedding models can be used based on your needs\n",
    "\n",
    "The `similarity_search_with_score` method performs this entire process, returning documents along with their similarity scores. This enables you to find semantically related content even when exact keywords don't match.\n",
    "\n",
    "Now let's see semantic search in action and measure its performance with different optimization strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search Performance Testing\n",
    "\n",
    "Now let's measure and compare the performance benefits of different optimization strategies. We'll conduct a comprehensive performance analysis across two phases:\n",
    "\n",
    "**Performance Testing Phases:**\n",
    "\n",
    "1. **Phase 1 - Baseline Performance**: Test vector search without Hyperscale indexes to establish baseline metrics\n",
    "2. **Phase 2 - Hyperscale-Optimized Search**: Create Hyperscale index and measure performance improvements\n",
    "\n",
    "**Important Context:**\n",
    "- Hyperscale performance benefits scale with dataset size and concurrent load\n",
    "- With our dataset (~1,700 articles), improvements may be modest\n",
    "- Production environments with millions of vectors show significant Hyperscale advantages\n",
    "- The combination of Hyperscale + LLM caching provides optimal RAG performance\n",
    "\n",
    "### Phase 1: Baseline Performance (No Hyperscale Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:30:09,869 - INFO - Baseline search completed in 0.37 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Semantic Search Results (completed in 0.37 seconds):\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.3512, Text: Luke Littler has risen from 164th to fourth in the rankings in a year\n",
      "\n",
      "A tearful Luke Littler hit a tournament record 140.91 set average as he started his bid for the PDC World Championship title with...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.4124, Text: The Littler effect - how darts hit the bullseye\n",
      "\n",
      "Teenager Luke Littler began his bid to win the 2025 PDC World Darts Championship with a second-round win against Ryan Meikle. Here we assess Littler's ...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.4317, Text: Luke Littler is one of six contenders for the 2024 BBC Sports Personality of the Year award.\n",
      "\n",
      "Here BBC Sport takes a look at the darts player's year in five photos....\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.4817, Text: Littler is Young Sports Personality of the Year\n",
      "\n",
      "This video can not be played To play this video you need to enable JavaScript in your browser.\n",
      "\n",
      "Darts player Luke Littler has been named BBC Young Spor...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.4823, Text: Wright is the 17th seed at the World Championship\n",
      "\n",
      "Two-time champion Peter Wright won his opening game at the PDC World Championship, while Ryan Meikle edged out Fallon Sherrock to set up a match agai...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.5302, Text: Luke Littler trends higher than PM on Google in 2024\n",
      "\n",
      "Luke Littler shot to fame when he became the youngest player to reach the World Darts Championship final in January\n",
      "\n",
      "Dart sensation Luke Littler h...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.6582, Text: Cross loses as record number of seeds out of Worlds\n",
      "\n",
      "Rob Cross has suffered three second-round exits in his eight World Championships\n",
      "\n",
      "Former champion Rob Cross became the latest high-profile casualty...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.6872, Text: Michael van Gerwen has made just one major ranking event final in 2024\n",
      "\n",
      "Michael van Gerwen enjoyed a comfortable 3-0 victory over English debutant James Hurrell in his opening match of the PDC World D...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.7012, Text: Christian Kist was sealing his first televised nine-darter\n",
      "\n",
      "Christian Kist hit a nine-darter but lost his PDC World Championship first-round match to Madars Razma. The Dutchman became the first player...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.7059, Text: Gary Anderson was the fifth seed to be beaten on Sunday\n",
      "\n",
      "Two-time champion Gary Anderson has been dumped out of the PDC World Championship on his 54th birthday by Jeffrey de Graaf. The Scot, winner in...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"What were Luke Littler's key achievements and records in his recent PDC World Championship match?\"\n",
    "\n",
    "try:\n",
    "    # Perform the semantic search\n",
    "    start_time = time.time()\n",
    "    search_results = vector_store.similarity_search_with_score(query, k=10)\n",
    "    baseline_time = time.time() - start_time\n",
    "\n",
    "    logging.info(f\"Baseline search completed in {baseline_time:.2f} seconds\")\n",
    "\n",
    "    # Display search results\n",
    "    print(f\"\\nBaseline Semantic Search Results (completed in {baseline_time:.2f} seconds):\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for doc, score in search_results:\n",
    "        print(f\"Distance: {score:.4f}, Text: {doc.page_content[:200]}...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "except CouchbaseException as e:\n",
    "    raise RuntimeError(f\"Error performing semantic search: {str(e)}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Hyperscale Index\n",
    "\n",
    "Now that we understand the different index types and configuration options (covered in the \"Understanding Hyperscale and Composite Vector Search\" section above), let's create a Hyperscale index for our vector store. This method takes an index type (HYPERSCALE or COMPOSITE) and description parameter for optimization settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:30:10,162 - INFO - Hyperscale index already exists, continuing...\n"
     ]
    }
   ],
   "source": [
    "from langchain_couchbase.vectorstores import IndexType\n",
    "\n",
    "try:\n",
    "    vector_store.create_index(index_type=IndexType.HYPERSCALE, index_name=\"bedrock_hyperscale_index\", index_description=\"IVF,SQ8\")\n",
    "    logging.info(\"Hyperscale index created successfully\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e):\n",
    "        logging.info(\"Hyperscale index already exists, continuing...\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: To create a COMPOSITE index, the below code can be used.\n",
    "Choose based on your specific use case and query patterns. For this tutorial's news search scenario, either index type would work, but Hyperscale is more efficient for pure semantic search across news articles.\n",
    "\n",
    "vector_store.create_index(index_type=IndexType.COMPOSITE, index_name=\"bedrock_composite_index\", index_description=\"IVF,SQ8\")\n",
    "\n",
    "### Phase 2: Hyperscale-Optimized Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:30:10,487 - INFO - Hyperscale search completed in 0.32 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperscale Semantic Search Results (completed in 0.32 seconds):\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.3512, Text: Luke Littler has risen from 164th to fourth in the rankings in a year\n",
      "\n",
      "A tearful Luke Littler hit a tournament record 140.91 set average as he started his bid for the PDC World Championship title with...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.4124, Text: The Littler effect - how darts hit the bullseye\n",
      "\n",
      "Teenager Luke Littler began his bid to win the 2025 PDC World Darts Championship with a second-round win against Ryan Meikle. Here we assess Littler's ...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.4317, Text: Luke Littler is one of six contenders for the 2024 BBC Sports Personality of the Year award.\n",
      "\n",
      "Here BBC Sport takes a look at the darts player's year in five photos....\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.4817, Text: Littler is Young Sports Personality of the Year\n",
      "\n",
      "This video can not be played To play this video you need to enable JavaScript in your browser.\n",
      "\n",
      "Darts player Luke Littler has been named BBC Young Spor...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.4823, Text: Wright is the 17th seed at the World Championship\n",
      "\n",
      "Two-time champion Peter Wright won his opening game at the PDC World Championship, while Ryan Meikle edged out Fallon Sherrock to set up a match agai...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.5302, Text: Luke Littler trends higher than PM on Google in 2024\n",
      "\n",
      "Luke Littler shot to fame when he became the youngest player to reach the World Darts Championship final in January\n",
      "\n",
      "Dart sensation Luke Littler h...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.6582, Text: Cross loses as record number of seeds out of Worlds\n",
      "\n",
      "Rob Cross has suffered three second-round exits in his eight World Championships\n",
      "\n",
      "Former champion Rob Cross became the latest high-profile casualty...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.6872, Text: Michael van Gerwen has made just one major ranking event final in 2024\n",
      "\n",
      "Michael van Gerwen enjoyed a comfortable 3-0 victory over English debutant James Hurrell in his opening match of the PDC World D...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.7012, Text: Christian Kist was sealing his first televised nine-darter\n",
      "\n",
      "Christian Kist hit a nine-darter but lost his PDC World Championship first-round match to Madars Razma. The Dutchman became the first player...\n",
      "--------------------------------------------------------------------------------\n",
      "Distance: 0.7059, Text: Gary Anderson was the fifth seed to be beaten on Sunday\n",
      "\n",
      "Two-time champion Gary Anderson has been dumped out of the PDC World Championship on his 54th birthday by Jeffrey de Graaf. The Scot, winner in...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"What were Luke Littler's key achievements and records in his recent PDC World Championship match?\"\n",
    "\n",
    "try:\n",
    "    # Perform the semantic search with Hyperscale index\n",
    "    start_time = time.time()\n",
    "    search_results = vector_store.similarity_search_with_score(query, k=10)\n",
    "    hyperscale_time = time.time() - start_time\n",
    "\n",
    "    logging.info(f\"Hyperscale search completed in {hyperscale_time:.2f} seconds\")\n",
    "\n",
    "    # Display search results\n",
    "    print(f\"\\nHyperscale Semantic Search Results (completed in {hyperscale_time:.2f} seconds):\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for doc, score in search_results:\n",
    "        print(f\"Distance: {score:.4f}, Text: {doc.page_content[:200]}...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "except CouchbaseException as e:\n",
    "    raise RuntimeError(f\"Error performing semantic search: {str(e)}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Analysis Summary\n",
    "\n",
    "Let's analyze the performance improvements we've achieved through different optimization strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "Baseline Search Time:     0.3718 seconds\n",
      "Hyperscale Search Time:   0.3201 seconds (1.16x faster, 13.9% improvement)\n",
      "\n",
      "------------------------------------------------------------\n",
      "Index Recommendation:\n",
      "------------------------------------------------------------\n",
      "- Hyperscale: Best for pure vector searches, scales to billions of vectors\n",
      "- Composite: Best for filtered searches combining vector + scalar filters\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Baseline Search Time:     {baseline_time:.4f} seconds\")\n",
    "\n",
    "if baseline_time and hyperscale_time:\n",
    "    speedup = baseline_time / hyperscale_time if hyperscale_time > 0 else float('inf')\n",
    "    percent_improvement = ((baseline_time - hyperscale_time) / baseline_time) * 100 if baseline_time > 0 else 0\n",
    "    print(f\"Hyperscale Search Time:   {hyperscale_time:.4f} seconds ({speedup:.2f}x faster, {percent_improvement:.1f}% improvement)\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Index Recommendation:\")\n",
    "print(\"-\"*60)\n",
    "print(\"- Hyperscale: Best for pure vector searches, scales to billions of vectors\")\n",
    "print(\"- Composite: Best for filtered searches combining vector + scalar filters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation (RAG) with Couchbase and LangChain\n",
    "Couchbase and LangChain can be seamlessly integrated to create RAG (Retrieval-Augmented Generation) chains, enhancing the process of generating contextually relevant responses. In this setup, Couchbase serves as the vector store, where embeddings of documents are stored. When a query is made, LangChain retrieves the most relevant documents from Couchbase by comparing the query's embedding with the stored document embeddings. These documents, which provide contextual information, are then passed to a generative language model within LangChain.\n",
    "\n",
    "The language model, equipped with the context from the retrieved documents, generates a response that is both informed and contextually accurate. This integration allows the RAG chain to leverage Couchbase's efficient storage and retrieval capabilities, while LangChain handles the generation of responses based on the context provided by the retrieved documents. Together, they create a powerful system that can deliver highly relevant and accurate answers by combining the strengths of both retrieval and generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 13:30:10,496 - INFO - Successfully created RAG chain\n"
     ]
    }
   ],
   "source": [
    "# Create RAG prompt template\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that answers questions based on the provided context.\"),\n",
    "    (\"human\", \"Context: {context}\\n\\nQuestion: {question}\")\n",
    "])\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": vector_store.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "logging.info(\"Successfully created RAG chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Response: In his recent PDC World Championship match, Luke Littler achieved several key milestones:\n",
      "\n",
      "1. **Tournament Record Average**: Littler set a new tournament record with an average of 140.91 in a single set, showcasing his exceptional skill and precision.\n",
      "\n",
      "2. **Dramatic Win**: He secured a dramatic 3-1 victory over Ryan Meikle, demonstrating his ability to perform under pressure.\n",
      "\n",
      "3. **Nerves and Emotion**: Despite admitting to nerves during the match, Littler managed to overcome them and deliver a stellar performance, which moved him to tears during his post-match interview.\n",
      "\n",
      "4. **Rankings and Titles**: Littler's performance contributed to his rise from 164th to fourth in the world rankings. In his debut professional year, he has won 10 titles, including the Premier League and Grand Slam of Darts.\n",
      "\n",
      "5. **Impact on the Sport**: His success has significantly boosted interest in darts, leading to increased ticket sales, higher viewing figures, and a surge in junior academies. This Christmas, over 100,000 children are expected to receive Littler-branded magnetic dartboards.\n",
      "\n",
      "For more detailed information, please refer to the provided context documents.\n",
      "RAG response generated in 9.65 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Turn off excessive Logging \n",
    "logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n",
    "\n",
    "try:\n",
    "    rag_response = rag_chain.invoke(query)\n",
    "    rag_elapsed_time = time.time() - start_time\n",
    "    print(f\"RAG Response: {rag_response}\")\n",
    "    print(f\"RAG response generated in {rag_elapsed_time:.2f} seconds\")\n",
    "except InternalServerFailureException as e:\n",
    "    if \"query request rejected\" in str(e):\n",
    "        print(\"Error: Search request was rejected due to rate limiting. Please try again later.\")\n",
    "    else:\n",
    "        print(f\"Internal server error occurred: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating Cache Benefits\n",
    "Couchbase can be effectively used as a caching mechanism for RAG (Retrieval-Augmented Generation) responses by storing and retrieving precomputed results for specific queries. This approach enhances the system's efficiency and speed, particularly when dealing with repeated or similar queries. When a query is first processed, the RAG chain retrieves relevant documents, generates a response using the language model, and then stores this response in Couchbase, with the query serving as the key.\n",
    "\n",
    "For subsequent requests with the same query, the system checks Couchbase first. If a cached response is found, it is retrieved directly from Couchbase, bypassing the need to re-run the entire RAG process. This significantly reduces response time because the computationally expensive steps of document retrieval and response generation are skipped. Couchbase's role in this setup is to provide a fast and scalable storage solution for caching these responses, ensuring that frequently asked queries can be answered more quickly and efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 1: What happened in the match between Fullham and Liverpool?\n",
      "Response: In the match between Fulham and Liverpool, Liverpool played with 10 men for most of the game after Andy Robertson received a red card in the 17th minute. Despite this, Liverpool managed to draw 2-2 with Fulham. Liverpool fell behind twice but equalized both times, with the final goal coming from Diogo Jota in the 86th minute. Both teams delivered strong performances, with Liverpool's resilience and Fulham's attacking play being highlighted by pundits and players alike.\n",
      "Time taken: 5.73 seconds\n",
      "\n",
      "Query 2: What were Luke Littler's key achievements and records in his recent PDC World Championship match?\n",
      "Response: In his recent PDC World Championship match, Luke Littler achieved several key milestones:\n",
      "\n",
      "1. **Tournament Record Average**: Littler set a new tournament record with an average of 140.91 in a single set, showcasing his exceptional skill and precision.\n",
      "\n",
      "2. **Dramatic Win**: He secured a dramatic 3-1 victory over Ryan Meikle, demonstrating his ability to perform under pressure.\n",
      "\n",
      "3. **Nerves and Emotion**: Despite admitting to nerves during the match, Littler managed to overcome them and deliver a stellar performance, which moved him to tears during his post-match interview.\n",
      "\n",
      "4. **Rankings and Titles**: Littler's performance contributed to his rise from 164th to fourth in the world rankings. In his debut professional year, he has won 10 titles, including the Premier League and Grand Slam of Darts.\n",
      "\n",
      "5. **Impact on the Sport**: His success has significantly boosted interest in darts, leading to increased ticket sales, higher viewing figures, and a surge in junior academies. This Christmas, over 100,000 children are expected to receive Littler-branded magnetic dartboards.\n",
      "\n",
      "For more detailed information, please refer to the provided context documents.\n",
      "Time taken: 0.35 seconds\n",
      "\n",
      "Query 3: What happened in the match between Fullham and Liverpool?\n",
      "Response: In the match between Fulham and Liverpool, Liverpool played with 10 men for most of the game after Andy Robertson received a red card in the 17th minute. Despite this, Liverpool managed to draw 2-2 with Fulham. Liverpool fell behind twice but equalized both times, with the final goal coming from Diogo Jota in the 86th minute. Both teams delivered strong performances, with Liverpool's resilience and Fulham's attacking play being highlighted by pundits and players alike.\n",
      "Time taken: 0.30 seconds\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    queries = [\n",
    "        \"What happened in the match between Fullham and Liverpool?\",\n",
    "        \"What were Luke Littler's key achievements and records in his recent PDC World Championship match?\",\n",
    "        \"What happened in the match between Fullham and Liverpool?\", # Repeated query\n",
    "    ]\n",
    "\n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(f\"\\nQuery {i}: {query}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        response = rag_chain.invoke(query)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Response: {response}\")\n",
    "        print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "except InternalServerFailureException as e:\n",
    "    if \"query request rejected\" in str(e):\n",
    "        print(\"Error: Search request was rejected due to rate limiting. Please try again later.\")\n",
    "    else:\n",
    "        print(f\"Internal server error occurred: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've built a high-performance semantic search engine using Couchbase Hyperscale/Composite indexes with Amazon Bedrock and LangChain. For the Search Vector Index alternative, see the [search_based tutorial](https://developer.couchbase.com/tutorial-aws-bedrock-couchbase-rag-with-search-vector-index)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
