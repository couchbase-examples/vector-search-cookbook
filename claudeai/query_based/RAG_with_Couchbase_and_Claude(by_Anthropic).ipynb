{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNdImxzypDlm"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this guide, we will walk you through building a powerful semantic search engine using Couchbase as the backend database, [OpenAI](https://openai.com/) for embeddings, and [Anthropic's Claude](https://www.anthropic.com/) as the language model. Semantic search goes beyond simple keyword matching by understanding the context and meaning behind the words in a query, making it an essential tool for applications that require intelligent information retrieval. This tutorial is designed to be beginner-friendly, with clear, step-by-step instructions that will equip you with the knowledge to create a fully functional semantic search system using Couchbase Hyperscale and Composite Vector Index from scratch. Alternatively if you want to perform semantic search using the Search Vector Index, please take a look at [this.](https://developer.couchbase.com/tutorial-openai-anthropic-couchbase-rag-with-search-vector-index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run this tutorial\n",
    "\n",
    "This tutorial is available as a Jupyter Notebook (`.ipynb` file) that you can run interactively. You can access the original notebook [here](https://github.com/couchbase-examples/vector-search-cookbook/blob/main/claudeai/query_based/RAG_with_Couchbase_and_Claude(by_Anthropic).ipynb).\n",
    "\n",
    "You can either download the notebook file and run it on [Google Colab](https://colab.research.google.com/) or run it on your system by setting up the Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "### Get the API Keys\n",
    "* Get the OpenAI API key from [OpenAI](https://platform.openai.com/api-keys).\n",
    "* Get the Anthropic API key from [Anthropic](https://platform.claude.com/).\n",
    "\n",
    "### Create and Deploy Your Free Tier Operational cluster on Capella\n",
    "\n",
    "To get started with Couchbase Capella, create an account and use it to deploy a forever free tier operational cluster. This account provides you with an environment where you can explore and learn about Capella with no time constraint.\n",
    "\n",
    "To know more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).\n",
    "\n",
    "Note: To run this tutorial, you will need Capella with Couchbase Server version 8.0 or above as Hyperscale and Composite Vector Index is supported only from version 8.0\n",
    "\n",
    "#### Couchbase Capella Configuration\n",
    "\n",
    "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met.\n",
    "\n",
    "* Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the bucket (Read and Write) used in the application.\n",
    "* [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NH2o6pqa69oG"
   },
   "source": [
    "## Setting the Stage: Installing Necessary Libraries\n",
    "\n",
    "To build our semantic search engine, we need a robust set of tools. The libraries we install handle everything from connecting to databases to performing complex machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DYhPj0Ta8l_A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --no-user --quiet datasets==4.5.0 langchain-couchbase==1.0.1 langchain-anthropic==1.3.2 langchain-openai==1.1.8 python-dotenv==1.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pp7GtNg8mB9"
   },
   "source": [
    "## Importing Necessary Libraries\n",
    "\n",
    "The script starts by importing a series of libraries required for various tasks, including handling JSON, logging, time tracking, Couchbase connections, embedding generation, and dataset loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8GzS6tfL8mFP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaustavghosh/Desktop/vector-search-cookbook/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from multiprocessing import AuthenticationError\n",
    "\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.exceptions import (CouchbaseException,\n",
    "                                  InternalServerFailureException)\n",
    "from couchbase.management.buckets import CreateBucketSettings\n",
    "from couchbase.options import ClusterOptions\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.prompts.chat import (ChatPromptTemplate,\n",
    "                                         HumanMessagePromptTemplate,\n",
    "                                         SystemMessagePromptTemplate)\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_couchbase.cache import CouchbaseCache\n",
    "from langchain_couchbase.vectorstores import CouchbaseQueryVectorStore\n",
    "from langchain_couchbase.vectorstores import DistanceStrategy\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_couchbase.vectorstores import IndexType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBnMp5vb8mIb"
   },
   "source": [
    "## Setup Logging\n",
    "\n",
    "Logging is configured to track the progress of the script and capture any errors or warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Yv8kWcuf8mLx"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n",
    "\n",
    "# Disable all logging except critical to prevent OpenAI API request logs\n",
    "logging.getLogger(\"httpx\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9G5a0en8mPA"
   },
   "source": [
    "## Loading Sensitive Information\n",
    "In this section, we prompt the user to input essential configuration settings needed. These settings include sensitive information like API keys, database credentials, and specific configuration names. Instead of hardcoding these details into the script, we request the user to provide them at runtime, ensuring flexibility and security.\n",
    "\n",
    "The project includes an `.env.sample` file that lists all the environment variables. To get started:\n",
    "\n",
    "1. Create a `.env` file in the same directory as this notebook\n",
    "2. Copy the contents from `.env.sample` to your `.env` file\n",
    "3. Fill in the required credentials\n",
    "\n",
    "The script also validates that all required inputs are provided, raising an error if any crucial information is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PFGyHll18mSe"
   },
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "# Load from environment variables or prompt for input in one-liners\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY') or getpass.getpass('Enter your Anthropic API key: ')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or getpass.getpass('Enter your OpenAI API key: ')\n",
    "CB_HOST = os.getenv('CB_HOST', 'couchbase://localhost') or input('Enter your Couchbase host (default: couchbase://localhost): ') or 'couchbase://localhost'\n",
    "CB_USERNAME = os.getenv('CB_USERNAME', 'Administrator') or input('Enter your Couchbase username (default: Administrator): ') or 'Administrator'\n",
    "CB_PASSWORD = os.getenv('CB_PASSWORD', 'password') or getpass.getpass('Enter your Couchbase password (default: password): ') or 'password'\n",
    "CB_BUCKET_NAME = os.getenv('CB_BUCKET_NAME', 'query-vector-search-testing') or input('Enter your Couchbase bucket name (default: query-vector-search-testing): ') or 'query-vector-search-testing'\n",
    "SCOPE_NAME = os.getenv('SCOPE_NAME', 'shared') or input('Enter your scope name (default: shared): ') or 'shared'\n",
    "COLLECTION_NAME = os.getenv('COLLECTION_NAME', 'claude') or input('Enter your collection name (default: claude): ') or 'claude'\n",
    "CACHE_COLLECTION = os.getenv('CACHE_COLLECTION', 'cache') or input('Enter your cache collection name (default: cache): ') or 'cache'\n",
    "# Check if the variables are correctly loaded\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    raise ValueError(\"ANTHROPIC_API_KEY is not set in the environment.\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set in the environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtGrYzUY8mV3"
   },
   "source": [
    "## Connecting to the Couchbase Cluster\n",
    "Connecting to a Couchbase cluster is the foundation of our project. Couchbase will serve as our primary data store, handling all the storage and retrieval operations required for our semantic search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Zb3kK-7W8mZK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 10:55:30,308 - INFO - Successfully connected to Couchbase\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
    "    options = ClusterOptions(auth)\n",
    "    cluster = Cluster(CB_HOST, options)\n",
    "    cluster.wait_until_ready(timedelta(seconds=5))\n",
    "    logging.info(\"Successfully connected to Couchbase\")\n",
    "except Exception as e:\n",
    "    raise ConnectionError(f\"Failed to connect to Couchbase: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_Gpy32N8mcZ"
   },
   "source": [
    "## Setting Up Collections in Couchbase\n",
    "\n",
    "The setup_collection() function handles creating and configuring the hierarchical data organization in Couchbase:\n",
    "\n",
    "1. Bucket Creation:\n",
    "   - Checks if specified bucket exists, creates it if not\n",
    "   - Sets bucket properties like RAM quota (1024MB) and replication (disabled)\n",
    "   - Note: You will not be able to create a bucket on Capella\n",
    "\n",
    "\n",
    "2. Scope Management:  \n",
    "   - Verifies if requested scope exists within bucket\n",
    "   - Creates new scope if needed (unless it's the default \"_default\" scope)\n",
    "\n",
    "3. Collection Setup:\n",
    "   - Checks for collection existence within scope\n",
    "   - Creates collection if it doesn't exist\n",
    "   - Waits 2 seconds for collection to be ready\n",
    "\n",
    "Additional Tasks:\n",
    "- Clears any existing documents for clean state\n",
    "- Implements comprehensive error handling and logging\n",
    "\n",
    "The function is called twice to set up:\n",
    "1. Main collection for vector embeddings\n",
    "2. Cache collection for storing results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ACZcwUnG8mf2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 10:55:30,320 - INFO - Bucket 'vector-search-testing' exists.\n",
      "2026-02-19 10:55:30,324 - INFO - Collection 'claude' does not exist. Creating it...\n",
      "2026-02-19 10:55:30,367 - INFO - Collection 'claude' created successfully.\n",
      "2026-02-19 10:55:32,482 - INFO - All documents cleared from the collection.\n",
      "2026-02-19 10:55:32,483 - INFO - Bucket 'vector-search-testing' exists.\n",
      "2026-02-19 10:55:32,484 - INFO - Collection 'cache' already exists. Skipping creation.\n",
      "2026-02-19 10:55:34,497 - INFO - All documents cleared from the collection.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<couchbase.collection.Collection at 0x1256a06e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setup_collection(cluster, bucket_name, scope_name, collection_name):\n",
    "    try:\n",
    "        # Check if bucket exists, create if it doesn't\n",
    "        try:\n",
    "            bucket = cluster.bucket(bucket_name)\n",
    "            logging.info(f\"Bucket '{bucket_name}' exists.\")\n",
    "        except Exception as e:\n",
    "            logging.info(f\"Bucket '{bucket_name}' does not exist. Creating it...\")\n",
    "            bucket_settings = CreateBucketSettings(\n",
    "                name=bucket_name,\n",
    "                bucket_type='couchbase',\n",
    "                ram_quota_mb=1024,\n",
    "                flush_enabled=True,\n",
    "                num_replicas=0\n",
    "            )\n",
    "            cluster.buckets().create_bucket(bucket_settings)\n",
    "            time.sleep(2)  # Wait for bucket creation to complete and become available\n",
    "            bucket = cluster.bucket(bucket_name)\n",
    "            logging.info(f\"Bucket '{bucket_name}' created successfully.\")\n",
    "\n",
    "        bucket_manager = bucket.collections()\n",
    "\n",
    "        # Check if scope exists, create if it doesn't\n",
    "        scopes = bucket_manager.get_all_scopes()\n",
    "        scope_exists = any(scope.name == scope_name for scope in scopes)\n",
    "        \n",
    "        if not scope_exists and scope_name != \"_default\":\n",
    "            logging.info(f\"Scope '{scope_name}' does not exist. Creating it...\")\n",
    "            bucket_manager.create_scope(scope_name)\n",
    "            logging.info(f\"Scope '{scope_name}' created successfully.\")\n",
    "\n",
    "        # Check if collection exists, create if it doesn't\n",
    "        collection_exists = any(\n",
    "            scope.name == scope_name and collection_name in [col.name for col in scope.collections]\n",
    "            for scope in scopes\n",
    "        )\n",
    "\n",
    "        if not collection_exists:\n",
    "            logging.info(f\"Collection '{collection_name}' does not exist. Creating it...\")\n",
    "            bucket_manager.create_collection(scope_name, collection_name)\n",
    "            logging.info(f\"Collection '{collection_name}' created successfully.\")\n",
    "        else:\n",
    "            logging.info(f\"Collection '{collection_name}' already exists. Skipping creation.\")\n",
    "\n",
    "        # Wait for collection to be ready\n",
    "        collection = bucket.scope(scope_name).collection(collection_name)\n",
    "        time.sleep(2)  # Give the collection time to be ready for queries\n",
    "\n",
    "        # Clear all documents in the collection\n",
    "        try:\n",
    "            query = f\"DELETE FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
    "            cluster.query(query).execute()\n",
    "            logging.info(\"All documents cleared from the collection.\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error while clearing documents: {str(e)}. The collection might be empty.\")\n",
    "\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error setting up collection: {str(e)}\")\n",
    "    \n",
    "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, COLLECTION_NAME)\n",
    "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, CACHE_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FvxRsg38m3G"
   },
   "source": [
    "## Creating OpenAI Embeddings\n",
    "\n",
    "Embeddings are at the heart of semantic search. They are numerical representations of text that capture the semantic meaning of the words and phrases. We'll use OpenAI's embedding model to generate these vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_75ZyCRh8m6m"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 10:55:34,667 - INFO - Successfully created OpenAIEmbeddings\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model='text-embedding-3-small')\n",
    "    logging.info(\"Successfully created OpenAIEmbeddings\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error creating OpenAIEmbeddings: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IwZMUnF8m-N"
   },
   "source": [
    "## Setting Up the Couchbase Query Vector Store\n",
    "A vector store is where we'll keep our embeddings. The query vector store is specifically designed to handle embeddings and perform similarity searches. When a user inputs a query, the query service converts the query into an embedding and compares it against the embeddings stored in the vector store. This allows the engine to find documents that are semantically similar to the query, even if they don't contain the exact same words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DwIJQjYT9RV_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 10:55:36,174 - INFO - Successfully created vector store\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vector_store = CouchbaseQueryVectorStore(\n",
    "        cluster=cluster,\n",
    "        bucket_name=CB_BUCKET_NAME,\n",
    "        scope_name=SCOPE_NAME,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        embedding = embeddings,\n",
    "        distance_metric=DistanceStrategy.COSINE\n",
    "    )\n",
    "    logging.info(\"Successfully created vector store\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to create vector store: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the BBC News Dataset\n",
    "To build a search engine, we need data to search through. We use the BBC News dataset from RealTimeData, which provides real-world news articles. The dataset is loaded using the Hugging Face datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "2026-02-19 10:55:36,503 - WARNING - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "2026-02-19 10:55:39,452 - INFO - Successfully loaded the BBC News dataset with 2687 rows.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the BBC News dataset with 2687 rows\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    news_dataset = load_dataset(\n",
    "        \"RealTimeData/bbc_news_alltime\", \"2024-12\", split=\"train\"\n",
    "    )\n",
    "    print(f\"Loaded the BBC News dataset with {len(news_dataset)} rows\")\n",
    "    logging.info(f\"Successfully loaded the BBC News dataset with {len(news_dataset)} rows.\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading the BBC News dataset: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the Data\n",
    "We will use the content of the news articles for our RAG system.\n",
    "\n",
    "The dataset contains a few duplicate records. We are removing them to avoid duplicate results in the retrieval stage of our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1749 unique articles in our database.\n"
     ]
    }
   ],
   "source": [
    "news_articles = news_dataset[\"content\"]\n",
    "unique_articles = set()\n",
    "for article in news_articles:\n",
    "    if article:\n",
    "        unique_articles.add(article)\n",
    "unique_news_articles = list(unique_articles)\n",
    "print(f\"We have {len(unique_news_articles)} unique articles in our database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data to the Vector Store\n",
    "To efficiently handle the large number of articles, we process them in batches of articles at a time. This batch processing approach helps manage memory usage and provides better control over the ingestion process.\n",
    "\n",
    "We first filter out any articles that exceed 50,000 characters to avoid potential issues with token limits. Then, using the vector store's add_texts method, we add the filtered articles to our vector database. The batch_size parameter controls how many articles are processed in each iteration.\n",
    "\n",
    "This approach offers several benefits:\n",
    "1. Memory Efficiency: Processing in smaller batches prevents memory overload\n",
    "2. Progress Tracking: Easier to monitor and track the ingestion progress\n",
    "3. Resource Management: Better control over CPU and network resource utilization\n",
    "\n",
    "We use a conservative batch size of 100 to ensure reliable operation.\n",
    "The optimal batch size depends on many factors including:\n",
    "- Document sizes being inserted\n",
    "- Available system resources\n",
    "- Network conditions\n",
    "- Concurrent workload\n",
    "\n",
    "Consider measuring performance with your specific workload before adjusting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 11:00:06,390 - INFO - Retrying request to /embeddings in 0.438330 seconds\n",
      "2026-02-19 11:01:31,314 - INFO - Document ingestion completed successfully.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# Automatic Batch Processing\n",
    "articles = [article for article in unique_news_articles if article and len(article) <= 50000]\n",
    "\n",
    "try:\n",
    "    vector_store.add_texts(\n",
    "        texts=articles,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    logging.info(\"Document ingestion completed successfully.\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to save documents to vector store: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Pn8-dQw9RfQ"
   },
   "source": [
    "## Setting Up a Couchbase Cache\n",
    "To further optimize our system, we set up a Couchbase-based cache for storing frequently accessed results, reducing response times for repeated queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "V2y7dyjf9Rid"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 11:01:31,323 - INFO - Successfully created cache\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cache = CouchbaseCache(\n",
    "        cluster=cluster,\n",
    "        bucket_name=CB_BUCKET_NAME,\n",
    "        scope_name=SCOPE_NAME,\n",
    "        collection_name=CACHE_COLLECTION,\n",
    "    )\n",
    "    logging.info(\"Successfully created cache\")\n",
    "    set_llm_cache(cache)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to create cache: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uehAx36o9Rlm"
   },
   "source": [
    "## Using the Claude Sonnet 4.6 Language Model (LLM)\n",
    "\n",
    "We use Anthropic's Claude Sonnet 4.6 as the language model for generating responses based on the retrieved context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yRAfBRLH9RpO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 11:01:31,327 - INFO - Successfully created ChatAnthropic\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    llm = ChatAnthropic(temperature=0.1, anthropic_api_key=ANTHROPIC_API_KEY, model_name='claude-sonnet-4-6') \n",
    "    logging.info(\"Successfully created ChatAnthropic\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error creating ChatAnthropic: {str(e)}. Please check your API key and network connection.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_XDfCx19UvG"
   },
   "source": [
    "## Perform Semantic Search\n",
    "Semantic search in Couchbase involves converting queries and documents into vector representations using an embeddings model. These vectors capture the semantic meaning of the text and are stored directly in Couchbase. When a query is made, Couchbase performs a similarity search by comparing the query vector against the stored document vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Pk-oFbnC9Uym"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 11:01:36,946 - INFO - Semantic search completed in 5.62 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic Search Results (completed in 5.62 seconds):\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.2501, Text: A map shown during the draw for the 2026 Fifa World Cup has been criticised by Ukraine as an \"unacceptable error\" after it appeared to exclude Crimea as part of the country. The graphic - showing coun...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.5697, Text: Defending champions Manchester City will face Juventus in the group stage of the Fifa Club World Cup next summer, while Chelsea meet Brazilian side Flamengo. Pep Guardiola's City, who beat Brazilian s...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.5793, Text: After Fifa awards Saudi Arabia the hosting rights for the men's 2034 World Cup, BBC analysis editor Ros Atkins looks at how we got here and the controversies surrounding the decision....\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.5878, Text: FA still to decide on endorsing Saudi World Cup bid\n",
      "\n",
      "The King Abdullah Sports City Stadium in Jeddah would be refurbished before the tournament\n",
      "\n",
      "The Football Association is still to decide whether it ...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.5905, Text: Uefa 'not worried' at Euro 2025 clash with Club World Cup\n",
      "\n",
      "England won Euro 2022 on home soil beating Germany in the final at Wembley\n",
      "\n",
      "Uefa is \"not worried\" that some Women's Euro 2025 matches will cl...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6003, Text: The King Abdullah Sports City Stadium is one of 15 stadiums in line to host games in 2034\n",
      "\n",
      "The Football Association says it supported Saudi Arabia's bid to host the 2034 World Cup after being assured ...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6122, Text: BBC and ITV agree World Cup deal for 2026 and 2030\n",
      "\n",
      "Argentina, led by Lionel Messi, won the 2022 men's World Cup in Qatar\n",
      "\n",
      "BBC Sport has agreed a deal to share live coverage of the men's Fifa World Cu...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6444, Text: Five killed in strike on Russia's Kursk after deadly missile attack on Kyiv\n",
      "\n",
      "Ukrainian officials said at least one person was killed and nine others were injured in the attack on Kyiv\n",
      "\n",
      "Russia says fiv...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6465, Text: Watch five iconic England goals from Euro 2022 including Georgia Stanway's screamer against Spain and Alessia Russo's cheeky backheel versus Sweden.\n",
      "\n",
      "Watch Women’s Euro 2025 draw at 16:55 GMT on Monda...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6506, Text: I should have invaded Ukraine earlier, Putin tells Russians in TV marathon\n",
      "\n",
      "Russian President Vladimir Putin has said Russia should have launched a full-scale invasion of Ukraine earlier and been bett...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"What happened with the map shown during the 2026 FIFA World Cup draw regarding Ukraine and Crimea? What was the controversy?\"\n",
    "\n",
    "try:\n",
    "    # Perform the semantic search\n",
    "    start_time = time.time()\n",
    "    search_results = vector_store.similarity_search_with_score(query, k=10)\n",
    "    baseline_time = time.time() - start_time\n",
    "\n",
    "    logging.info(f\"Semantic search completed in {baseline_time:.2f} seconds\")\n",
    "\n",
    "    # Display search results\n",
    "    print(f\"\\nSemantic Search Results (completed in {baseline_time:.2f} seconds):\")\n",
    "    print(\"-\" * 80)  # Add separator line\n",
    "    for doc, score in search_results:\n",
    "        print(f\"Score: {score:.4f}, Text: {doc.page_content[:200]}...\")\n",
    "        print(\"-\" * 80)  # Add separator between results\n",
    "\n",
    "except CouchbaseException as e:\n",
    "    raise RuntimeError(f\"Error performing semantic search: {str(e)}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Vector Search with Hyperscale and Composite Vector Index\n",
    "\n",
    "While the above semantic search using similarity_search_with_score works effectively, we can significantly improve query performance by leveraging Couchbase's query-based vector indexing.\n",
    "\n",
    "Couchbase offers three types of vector indexes, but for Hyperscale and Composite Vector Index based search we focus on two main types:\n",
    "\n",
    "Hyperscale Vector Indexes\n",
    "- Best for pure vector searches - content discovery, recommendations, semantic search\n",
    "- High performance with low memory footprint - designed to scale to billions of vectors\n",
    "- Optimized for concurrent operations - supports simultaneous searches and inserts\n",
    "- Use when: You primarily perform vector-only queries without complex scalar filtering\n",
    "- Ideal for: Large-scale semantic search, recommendation systems, content discovery\n",
    "\n",
    "Composite Vector Indexes \n",
    "- Best for filtered vector searches - combines vector search with scalar value filtering\n",
    "- Efficient pre-filtering - scalar attributes reduce the vector comparison scope\n",
    "- Use when: Your queries combine vector similarity with scalar filters that eliminate large portions of data\n",
    "- Ideal for: Compliance-based filtering, user-specific searches, time-bounded queries\n",
    "\n",
    "Choosing the Right Index Type\n",
    "- Start with Hyperscale Vector Index for pure vector searches and large datasets\n",
    "- Use Composite Vector Index when scalar filters significantly reduce your search space\n",
    "- Consider your dataset size: Hyperscale scales to billions, Composite works well for tens of millions to billions\n",
    "\n",
    "For more details, see the [Couchbase Vector Index documentation](https://docs.couchbase.com/cloud/vector-index/use-vector-indexes.html).\n",
    "\n",
    "\n",
    "### Understanding Index Configuration (Couchbase 8.0 Feature)\n",
    "\n",
    "The index_description parameter controls how Couchbase optimizes vector storage and search performance through centroids and quantization:\n",
    "\n",
    "Format: `'IVF[<centroids>],{PQ|SQ}<settings>'`\n",
    "\n",
    "Centroids (IVF - Inverted File):\n",
    "- Controls how the dataset is subdivided for faster searches\n",
    "- More centroids = faster search, slower training  \n",
    "- Fewer centroids = slower search, faster training\n",
    "- If omitted (like IVF,SQ8), Couchbase auto-selects based on dataset size\n",
    "\n",
    "Quantization Options:\n",
    "- SQ (Scalar Quantization): SQ4, SQ6, SQ8 (4, 6, or 8 bits per dimension)\n",
    "- PQ (Product Quantization): PQ<subquantizers>x<bits> (e.g., PQ32x8)\n",
    "- Higher values = better accuracy, larger index size\n",
    "\n",
    "Common Examples:\n",
    "- IVF,SQ8 - Auto centroids, 8-bit scalar quantization (good default)\n",
    "- IVF1000,SQ6 - 1000 centroids, 6-bit scalar quantization  \n",
    "- IVF,PQ32x8 - Auto centroids, 32 subquantizers with 8 bits\n",
    "\n",
    "For detailed configuration options, see the [Quantization & Centroid Settings](https://docs.couchbase.com/cloud/vector-index/hyperscale-vector-index.html#algo_settings).\n",
    "\n",
    "In the code below, we demonstrate creating a Hyperscale index. This method takes an index type (HYPERSCALE or COMPOSITE) and description parameter for optimization settings. Alternatively, Hyperscale and Composite Vector Indexes can be created manually from the Couchbase UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.create_index(index_type=IndexType.HYPERSCALE, index_name=\"claude_hyperscale_index\", index_description=\"IVF,SQ8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 11:01:49,033 - INFO - Semantic search completed in 0.26 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Semantic Search Results (completed in 0.26 seconds):\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6444, Text: Five killed in strike on Russia's Kursk after deadly missile attack on Kyiv\n",
      "\n",
      "Ukrainian officials said at least one person was killed and nine others were injured in the attack on Kyiv\n",
      "\n",
      "Russia says fiv...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6506, Text: I should have invaded Ukraine earlier, Putin tells Russians in TV marathon\n",
      "\n",
      "Russian President Vladimir Putin has said Russia should have launched a full-scale invasion of Ukraine earlier and been bett...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6509, Text: 43,000 troops killed in war with Russia, Zelensky says\n",
      "\n",
      "Some 43,000 Ukrainian soldiers have been killed since Russia's full-scale invasion began, Volodymyr Zelensky has said in a rare admission of the...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6565, Text: Romania's far right presidential frontrunner vows to end Ukraine aid\n",
      "\n",
      "Calin Georgescu is leading the presidential race in Romania\n",
      "\n",
      "Calin Georgescu, the fringe nationalist politician leading the presid...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6583, Text: US gives $20bn to Ukraine funded by seized Russian assets\n",
      "\n",
      "The US has given $20bn (£15bn) to Ukraine, funded by the profits of seized Russian assets. The economic support forms a significant part of a...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6624, Text: Ukraine's war stamps put humour, patriotism and swearing in the post\n",
      "\n",
      "The head of Ukraine's postal company, Ukrposhta, says they're \"breaking the rules\" with their war stamps\n",
      "\n",
      "Rude gestures are rare o...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6683, Text: How meddling blamed on Russia exploited real grievances in Romania\n",
      "\n",
      "Calin Georgescu said the annulment of the vote was \"an abuse and a crime\"\n",
      "\n",
      "\"Romania dodged a bullet,\" is how a former deputy head of...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6707, Text: Emergency workers have been working to restore the energy plants\n",
      "\n",
      "Russia has launched a huge attack on Ukraine's energy infrastructure, which authorities said was the 12th large-scale attack on energy...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6763, Text: Lt Gen Igor Kirillov, head of the Nuclear, Biological, Chemical Defence Forces (NBC), was killed early on Tuesday\n",
      "\n",
      "Appearance and reality: there is a constant battle in Moscow between the two. Despite...\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.6764, Text: Calin Georgescu cast his vote in the first round of voting last weekend\n",
      "\n",
      "Romania's constitutional court has annulled the result of the first round of voting in the presidential election just days befo...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"What happened with the map shown during the 2026 FIFA World Cup draw regarding Ukraine and Crimea? What was the controversy?\"\n",
    "\n",
    "try:\n",
    "    # Perform the semantic search\n",
    "    start_time = time.time()\n",
    "    search_results = vector_store.similarity_search_with_score(query, k=10)\n",
    "    optimized_time = time.time() - start_time\n",
    "\n",
    "    logging.info(f\"Semantic search completed in {optimized_time:.2f} seconds\")\n",
    "\n",
    "    # Display search results\n",
    "    print(f\"\\nSemantic Search Results (completed in {optimized_time:.2f} seconds):\")\n",
    "    print(\"-\" * 80)  # Add separator line\n",
    "    for doc, score in search_results:\n",
    "        print(f\"Score: {score:.4f}, Text: {doc.page_content[:200]}...\")\n",
    "        print(\"-\" * 80)  # Add separator between results\n",
    "\n",
    "except CouchbaseException as e:\n",
    "    raise RuntimeError(f\"Error performing semantic search: {str(e)}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Composite Index Configuration\n",
    "\n",
    "If your use case requires complex filtering with scalar attributes, you can create a Composite index instead:\n",
    "\n",
    "```python\n",
    "from langchain_couchbase.vectorstores import IndexType\n",
    "vector_store.create_index(\n",
    "    index_type=IndexType.COMPOSITE,  # Instead of IndexType.HYPERSCALE\n",
    "    index_name=\"claude_composite_index\",\n",
    "    index_description=\"IVF,SQ8\"\n",
    ")\n",
    "```\n",
    "\n",
    "Choose based on your specific use case and query patterns. For this tutorial's news search scenario, either index type would work, but Hyperscale is more efficient for pure semantic search across news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VECTOR SEARCH PERFORMANCE OPTIMIZATION SUMMARY\n",
      "================================================================================\n",
      "Phase 1 - Baseline Search (No Hyperscale):     5.6153 seconds\n",
      "Phase 2 - Hyperscale-Optimized Search:         0.2611 seconds\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VECTOR SEARCH OPTIMIZATION IMPACT:\n",
      "--------------------------------------------------------------------------------\n",
      "Hyperscale Index Benefit:      21.51x faster (95.4% improvement)\n",
      "\n",
      "Key Insights for Vector Search Performance:\n",
      "• Hyperscale indexes provide significant performance improvements for vector similarity search\n",
      "• Performance gains are most dramatic for large datasets and complex semantic queries\n",
      "• Hyperscale vector index optimization is particularly effective for high-dimensional embeddings\n",
      "• Combined with proper quantization (SQ8), Hyperscale delivers production-ready performance\n",
      "• Consider Composite indexes when you need to combine vector search with scalar filtering\n"
     ]
    }
   ],
   "source": [
    "# Performance Analysis Summary\n",
    "print(\"=\" * 80)\n",
    "print(\"VECTOR SEARCH PERFORMANCE OPTIMIZATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Phase 1 - Baseline Search (No Hyperscale):     {baseline_time:.4f} seconds\")\n",
    "print(f\"Phase 2 - Hyperscale-Optimized Search:         {optimized_time:.4f} seconds\")\n",
    "\n",
    "print()\n",
    "print(\"-\" * 80)\n",
    "print(\"VECTOR SEARCH OPTIMIZATION IMPACT:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if optimized_time < baseline_time:\n",
    "    speedup = baseline_time / optimized_time\n",
    "    improvement = ((baseline_time - optimized_time) / baseline_time) * 100\n",
    "    print(f\"Hyperscale Index Benefit:      {speedup:.2f}x faster ({improvement:.1f}% improvement)\")\n",
    "else:\n",
    "    print(f\"Note: Hyperscale index did not show improvement in this run.\")\n",
    "    print(f\"This may occur if the index is still training or the dataset is small.\")\n",
    "    print(f\"Re-run Phase 2 after the index is fully built for accurate results.\")\n",
    "\n",
    "print()\n",
    "print(\"Key Insights for Vector Search Performance:\")\n",
    "print(\"• Hyperscale indexes provide significant performance improvements for vector similarity search\")\n",
    "print(\"• Performance gains are most dramatic for large datasets and complex semantic queries\")\n",
    "print(\"• Hyperscale vector index optimization is particularly effective for high-dimensional embeddings\")\n",
    "print(\"• Combined with proper quantization (SQ8), Hyperscale delivers production-ready performance\")\n",
    "print(\"• Consider Composite indexes when you need to combine vector search with scalar filtering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sS0FebHI9U1l"
   },
   "source": [
    "## Retrieval-Augmented Generation (RAG) with Couchbase and LangChain\n",
    "Couchbase and LangChain can be seamlessly integrated to create RAG chains, enhancing the process of generating contextually relevant responses. In this setup, Couchbase serves as the vector store, and LangChain retrieves the most relevant documents and passes them to the language model for response generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZGUXQQmv9ge4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 11:01:49,045 - INFO - Successfully created RAG chain\n"
     ]
    }
   ],
   "source": [
    "system_template = \"You are a helpful assistant that answers questions based on the provided context.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template = \"Context: {context}\\n\\nQuestion: {question}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message_prompt,\n",
    "    human_message_prompt\n",
    "])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": lambda x: format_docs(vector_store.similarity_search(x)), \"question\": RunnablePassthrough()}\n",
    "    | chat_prompt\n",
    "    | llm\n",
    ")\n",
    "logging.info(\"Successfully created RAG chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Mia7XxM9978M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Response: The provided context does not contain any information about the 2026 FIFA World Cup draw or any controversy involving a map related to Ukraine and Crimea at such an event. The context focuses on the Russia-Ukraine war, including missile strikes, casualty figures, Putin's press conference, and Romania's presidential election. I cannot answer your question based on the available information.\n",
      "RAG response generated in 8.25 seconds\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    start_time = time.time()\n",
    "    rag_response = rag_chain.invoke(query)\n",
    "    rag_elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"RAG Response: {rag_response.content}\")\n",
    "    print(f\"RAG response generated in {rag_elapsed_time:.2f} seconds\")\n",
    "except AuthenticationError as e:\n",
    "    print(f\"Authentication error: {str(e)}\")\n",
    "except InternalServerFailureException as e:\n",
    "    if \"query request rejected\" in str(e):\n",
    "        print(\"Error: Search request was rejected due to rate limiting. Please try again later.\")\n",
    "    else:\n",
    "        print(f\"Internal server error occurred: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIdayPzw9glT"
   },
   "source": [
    "## Using Couchbase as a caching mechanism\n",
    "Couchbase can be used as a caching mechanism for RAG responses, storing precomputed results for repeated queries to significantly reduce response times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0xM2G3ef-GS2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 1: What happened when Apple's AI feature generated a false BBC headline about a murder case in New York?\n",
      "Response: ## Apple Intelligence Generates False BBC Headline\n",
      "\n",
      "When Apple's AI notification summarization feature (**Apple Intelligence**) generated a false headline, several significant consequences followed:\n",
      "\n",
      "### The False Claim\n",
      "The AI falsely made it appear that **BBC News had reported that Luigi Mangione** — the man arrested for the murder of healthcare insurance CEO Brian Thompson in New York — **had shot himself**, when in fact he had not.\n",
      "\n",
      "### BBC's Response\n",
      "- The BBC **formally complained to Apple**, contacting them \"to raise this concern and fix the problem\"\n",
      "- The BBC emphasized that it is considered **\"the most trusted news media in the world\"** and stressed the importance of audiences being able to trust information published in their name\n",
      "\n",
      "### Broader Context\n",
      "- This was **not an isolated incident** — Apple Intelligence had also misrepresented a New York Times notification to suggest **\"Netanyahu arrested\"**, when the actual story was about an ICC arrest *warrant*\n",
      "- Experts criticized Apple, with Professor Petros Iosifidis calling it **\"embarrassing\"** and describing the product as **\"demonstrably half-baked\"**, warning of **\"a real danger of spreading disinformation\"**\n",
      "\n",
      "The incident highlighted growing concerns about AI summarization technology being deployed before it is sufficiently reliable, particularly when misrepresenting trusted news sources.\n",
      "Time taken: 11.43 seconds\n",
      "\n",
      "Query 2: What happened with the map shown during the 2026 FIFA World Cup draw regarding Ukraine and Crimea? What was the controversy?\n",
      "Response: The provided context does not contain any information about the 2026 FIFA World Cup draw or any controversy involving a map related to Ukraine and Crimea at such an event. The context focuses on the Russia-Ukraine war, including missile strikes, casualty figures, Putin's press conference, and Romania's presidential election. I cannot answer your question based on the available information.\n",
      "Time taken: 0.30 seconds\n",
      "\n",
      "Query 3: What happened when Apple's AI feature generated a false BBC headline about a murder case in New York?\n",
      "Response: ## Apple Intelligence Generates False BBC Headline\n",
      "\n",
      "When Apple's AI notification summarization feature (**Apple Intelligence**) generated a false headline, several significant consequences followed:\n",
      "\n",
      "### The False Claim\n",
      "The AI falsely made it appear that **BBC News had reported that Luigi Mangione** — the man arrested for the murder of healthcare insurance CEO Brian Thompson in New York — **had shot himself**, when in fact he had not.\n",
      "\n",
      "### BBC's Response\n",
      "- The BBC **formally complained to Apple**, contacting them \"to raise this concern and fix the problem\"\n",
      "- The BBC emphasized that it is considered **\"the most trusted news media in the world\"** and stressed the importance of audiences being able to trust information published in their name\n",
      "\n",
      "### Broader Context\n",
      "- This was **not an isolated incident** — Apple Intelligence had also misrepresented a New York Times notification to suggest **\"Netanyahu arrested\"**, when the actual story was about an ICC arrest *warrant*\n",
      "- Experts criticized Apple, with Professor Petros Iosifidis calling it **\"embarrassing\"** and describing the product as **\"demonstrably half-baked\"**, warning of **\"a real danger of spreading disinformation\"**\n",
      "\n",
      "The incident highlighted growing concerns about AI summarization technology being deployed before it is sufficiently reliable, particularly when misrepresenting trusted news sources.\n",
      "Time taken: 0.28 seconds\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    queries = [\n",
    "        \"What happened when Apple's AI feature generated a false BBC headline about a murder case in New York?\",\n",
    "        \"What happened with the map shown during the 2026 FIFA World Cup draw regarding Ukraine and Crimea? What was the controversy?\", # Repeated query\n",
    "        \"What happened when Apple's AI feature generated a false BBC headline about a murder case in New York?\", # Repeated query\n",
    "    ]\n",
    "\n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(f\"\\nQuery {i}: {query}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        response = rag_chain.invoke(query)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Response: {response.content}\")\n",
    "        print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "except AuthenticationError as e:\n",
    "    print(f\"Authentication error: {str(e)}\")\n",
    "except InternalServerFailureException as e:\n",
    "    if \"query request rejected\" in str(e):\n",
    "        print(\"Error: Search request was rejected due to rate limiting. Please try again later.\")\n",
    "    else:\n",
    "        print(f\"Internal server error occurred: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJQ5P8E29go1"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "You've built a high-performance semantic search engine using Couchbase Hyperscale/Composite indexes with OpenAI embeddings, Anthropic's Claude, and LangChain. For the Search Vector Index alternative, see the [search_based tutorial](https://developer.couchbase.com/tutorial-openai-anthropic-couchbase-rag-with-search-vector-index)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
