{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNdImxzypDlm"
      },
      "source": [
        "# Introduction\n",
        "In this guide, we will walk you through building a powerful semantic search engine using Couchbase as the backend database, [AzureOpenAI](https://azure.microsoft.com/) as the AI-powered embedding and language model provider. Semantic search goes beyond simple keyword matching by understanding the context and meaning behind the words in a query, making it an essential tool for applications that require intelligent information retrieval. This tutorial is designed to be beginner-friendly, with clear, step-by-step instructions that will equip you with the knowledge to create a fully functional semantic search system using GSI( Global Secondary Index) from scratch. Alternatively if you want to perform semantic search using the FTS index, please take a look at [this.](https://developer.couchbase.com/tutorial-azure-openai-couchbase-rag-with-fts/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# How to run this tutorial\n",
        "\n",
        "This tutorial is available as a Jupyter Notebook (`.ipynb` file) that you can run interactively. You can access the original notebook [here](https://github.com/couchbase-examples/vector-search-cookbook/blob/main/azure/RAG_with_Couchbase_and_AzureOpenAI.ipynb).\n",
        "\n",
        "You can either download the notebook file and run it on [Google Colab](https://colab.research.google.com/) or run it on your system by setting up the Python environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Before you start\n",
        "\n",
        "## Get Credentials for Azure OpenAI\n",
        "\n",
        "Please follow the [instructions](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference) to generate the Azure OpenAI credentials.\n",
        "\n",
        "## Create and Deploy Your Free Tier Operational cluster on Capella\n",
        "\n",
        "To get started with Couchbase Capella, create an account and use it to deploy a forever free tier operational cluster. This account provides you with a environment where you can explore and learn about Capella with no time constraint.\n",
        "\n",
        "To know more, please follow the [instructions](https://docs.couchbase.com/cloud/get-started/create-account.html).\n",
        "\n",
        "### Couchbase Capella Configuration\n",
        "\n",
        "When running Couchbase using [Capella](https://cloud.couchbase.com/sign-in), the following prerequisites need to be met.\n",
        "\n",
        "* Create the [database credentials](https://docs.couchbase.com/cloud/clusters/manage-database-users.html) to access the travel-sample bucket (Read and Write) used in the application.\n",
        "* [Allow access](https://docs.couchbase.com/cloud/clusters/allow-ip-address.html) to the Cluster from the IP on which the application is running."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH2o6pqa69oG"
      },
      "source": [
        "# Setting the Stage: Installing Necessary Libraries\n",
        "To build our semantic search engine, we need a robust set of tools. The libraries we install handle everything from connecting to databases to performing complex machine learning tasks. Each library has a specific role: Couchbase libraries manage database operations, LangChain handles AI model integrations, and AzureOpenAI provides advanced AI models for generating embeddings and understanding natural language. By setting up these libraries, we ensure our environment is equipped to handle the data-intensive and computationally complex tasks required for semantic search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYhPj0Ta8l_A",
        "outputId": "9bc5df34-616b-4f0d-ad36-ea578ba140c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets==3.5.0\n",
            "  Using cached datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting langchain-couchbase==0.5.0rc1\n",
            "  Using cached langchain_couchbase-0.5.0rc1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting langchain-openai==0.3.32\n",
            "  Using cached langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting filelock (from datasets==3.5.0)\n",
            "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting numpy>=1.17 (from datasets==3.5.0)\n",
            "  Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Collecting pyarrow>=15.0.0 (from datasets==3.5.0)\n",
            "  Using cached pyarrow-21.0.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.5.0)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets==3.5.0)\n",
            "  Using cached pandas-2.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (91 kB)\n",
            "Collecting requests>=2.32.2 (from datasets==3.5.0)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tqdm>=4.66.3 (from datasets==3.5.0)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting xxhash (from datasets==3.5.0)\n",
            "  Using cached xxhash-3.5.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.5.0)\n",
            "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.5.0)\n",
            "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets==3.5.0)\n",
            "  Using cached aiohttp-3.12.15-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
            "Collecting huggingface-hub>=0.24.0 (from datasets==3.5.0)\n",
            "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: packaging in /Users/prajwal.pai/Documents/Couchbase/vector-search-cookbook/jupyter_env/lib/python3.10/site-packages (from datasets==3.5.0) (25.0)\n",
            "Collecting pyyaml>=5.1 (from datasets==3.5.0)\n",
            "  Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting couchbase<5.0.0,>=4.4.0 (from langchain-couchbase==0.5.0rc1)\n",
            "  Using cached couchbase-4.4.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (23 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain-couchbase==0.5.0rc1)\n",
            "  Using cached langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting openai<2.0.0,>=1.99.9 (from langchain-openai==0.3.32)\n",
            "  Using cached openai-1.105.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.3.32)\n",
            "  Using cached tiktoken-0.11.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->datasets==3.5.0)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp->datasets==3.5.0)\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets==3.5.0)\n",
            "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->datasets==3.5.0)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==3.5.0)\n",
            "  Using cached frozenlist-1.7.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==3.5.0)\n",
            "  Using cached multidict-6.6.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->datasets==3.5.0)\n",
            "  Using cached propcache-0.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets==3.5.0)\n",
            "  Using cached yarl-1.20.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (73 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/prajwal.pai/Documents/Couchbase/vector-search-cookbook/jupyter_env/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets==3.5.0) (4.15.0)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.24.0->datasets==3.5.0)\n",
            "  Using cached hf_xet-1.1.9-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
            "Collecting langsmith>=0.3.45 (from langchain-core<0.4.0,>=0.3.15->langchain-couchbase==0.5.0rc1)\n",
            "  Using cached langsmith-0.4.23-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<0.4.0,>=0.3.15->langchain-couchbase==0.5.0rc1)\n",
            "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.15->langchain-couchbase==0.5.0rc1)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pydantic>=2.7.4 (from langchain-core<0.4.0,>=0.3.15->langchain-couchbase==0.5.0rc1)\n",
            "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.32)\n",
            "  Using cached anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.32)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.32)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.32)\n",
            "  Using cached jiter-0.10.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.32)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets==3.5.0)\n",
            "  Using cached charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets==3.5.0)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets==3.5.0)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets==3.5.0)\n",
            "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai==0.3.32)\n",
            "  Using cached regex-2025.9.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/prajwal.pai/Documents/Couchbase/vector-search-cookbook/jupyter_env/lib/python3.10/site-packages (from pandas->datasets==3.5.0) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets==3.5.0)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets==3.5.0)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/prajwal.pai/Documents/Couchbase/vector-search-cookbook/jupyter_env/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai==0.3.32) (1.3.0)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai==0.3.32)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai==0.3.32)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-couchbase==0.5.0rc1)\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson>=3.9.14 (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.15->langchain-couchbase==0.5.0rc1)\n",
            "  Using cached orjson-3.11.3-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.15->langchain-couchbase==0.5.0rc1)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting zstandard>=0.23.0 (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.15->langchain-couchbase==0.5.0rc1)\n",
            "  Using cached zstandard-0.24.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.1 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain-couchbase==0.5.0rc1)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain-couchbase==0.5.0rc1)\n",
            "  Using cached pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain-couchbase==0.5.0rc1)\n",
            "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/prajwal.pai/Documents/Couchbase/vector-search-cookbook/jupyter_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.5.0) (1.17.0)\n",
            "Using cached datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "Using cached langchain_couchbase-0.5.0rc1-py3-none-any.whl (29 kB)\n",
            "Using cached langchain_openai-0.3.32-py3-none-any.whl (74 kB)\n",
            "Using cached couchbase-4.4.0-cp310-cp310-macosx_11_0_arm64.whl (4.2 MB)\n",
            "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Using cached aiohttp-3.12.15-cp310-cp310-macosx_11_0_arm64.whl (468 kB)\n",
            "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
            "Using cached langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
            "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
            "Using cached openai-1.105.0-py3-none-any.whl (928 kB)\n",
            "Using cached pyarrow-21.0.0-cp310-cp310-macosx_12_0_arm64.whl (31.2 MB)\n",
            "Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached tiktoken-0.11.0-cp310-cp310-macosx_11_0_arm64.whl (999 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Using cached pandas-2.3.2-cp310-cp310-macosx_11_0_arm64.whl (10.8 MB)\n",
            "Using cached xxhash-3.5.0-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Using cached anyio-4.10.0-py3-none-any.whl (107 kB)\n",
            "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Using cached charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl (207 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached frozenlist-1.7.0-cp310-cp310-macosx_11_0_arm64.whl (46 kB)\n",
            "Using cached hf_xet-1.1.9-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached jiter-0.10.0-cp310-cp310-macosx_11_0_arm64.whl (322 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Using cached langsmith-0.4.23-py3-none-any.whl (378 kB)\n",
            "Using cached multidict-6.6.4-cp310-cp310-macosx_11_0_arm64.whl (44 kB)\n",
            "Using cached propcache-0.3.2-cp310-cp310-macosx_11_0_arm64.whl (43 kB)\n",
            "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
            "Using cached pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached regex-2025.9.1-cp310-cp310-macosx_11_0_arm64.whl (286 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached yarl-1.20.1-cp310-cp310-macosx_11_0_arm64.whl (89 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached orjson-3.11.3-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (238 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Using cached zstandard-0.24.0-cp310-cp310-macosx_11_0_arm64.whl (640 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: pytz, zstandard, xxhash, urllib3, tzdata, typing-inspection, tqdm, tenacity, sniffio, regex, pyyaml, pydantic-core, pyarrow, propcache, orjson, numpy, multidict, jsonpointer, jiter, idna, hf-xet, h11, fsspec, frozenlist, filelock, distro, dill, couchbase, charset_normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, requests, pydantic, pandas, multiprocess, jsonpatch, httpcore, anyio, aiosignal, tiktoken, requests-toolbelt, huggingface-hub, httpx, aiohttp, openai, langsmith, langchain-core, datasets, langchain-openai, langchain-couchbase\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.10.0 async-timeout-5.0.1 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 couchbase-4.4.0 datasets-3.5.0 dill-0.3.8 distro-1.9.0 filelock-3.19.1 frozenlist-1.7.0 fsspec-2024.12.0 h11-0.16.0 hf-xet-1.1.9 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.34.4 idna-3.10 jiter-0.10.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.75 langchain-couchbase-0.5.0rc1 langchain-openai-0.3.32 langsmith-0.4.23 multidict-6.6.4 multiprocess-0.70.16 numpy-2.2.6 openai-1.105.0 orjson-3.11.3 pandas-2.3.2 propcache-0.3.2 pyarrow-21.0.0 pydantic-2.11.7 pydantic-core-2.33.2 pytz-2025.2 pyyaml-6.0.2 regex-2025.9.1 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.11.0 tqdm-4.67.1 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0 xxhash-3.5.0 yarl-1.20.1 zstandard-0.24.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets==3.5.0 langchain-couchbase==0.5.0rc1 langchain-openai==0.3.32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pp7GtNg8mB9"
      },
      "source": [
        "# Importing Necessary Libraries\n",
        "The script starts by importing a series of libraries required for various tasks, including handling JSON, logging, time tracking, Couchbase connections, embedding generation, and dataset loading. These libraries provide essential functions for working with data, managing database connections, and processing machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8GzS6tfL8mFP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/prajwal.pai/Documents/Couchbase/vector-search-cookbook/jupyter_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from uuid import uuid4\n",
        "\n",
        "from couchbase.auth import PasswordAuthenticator\n",
        "from couchbase.cluster import Cluster\n",
        "from couchbase.exceptions import (\n",
        "    CouchbaseException,\n",
        "    InternalServerFailureException,\n",
        "    QueryIndexAlreadyExistsException,\n",
        ")\n",
        "from couchbase.options import ClusterOptions\n",
        "from datasets import load_dataset\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.globals import set_llm_cache\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts.chat import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_couchbase.cache import CouchbaseCache\n",
        "from langchain_couchbase.vectorstores import CouchbaseQueryVectorStore\n",
        "from langchain_couchbase.vectorstores import DistanceStrategy\n",
        "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBnMp5vb8mIb"
      },
      "source": [
        "# Setup Logging\n",
        "Logging is configured to track the progress of the script and capture any errors or warnings. This is crucial for debugging and understanding the flow of execution. The logging output includes timestamps, log levels (e.g., INFO, ERROR), and messages that describe what is happening in the script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Yv8kWcuf8mLx"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9G5a0en8mPA"
      },
      "source": [
        "# Loading Sensitive Information\n",
        "In this section, we prompt the user to input essential configuration settings needed. These settings include sensitive information like API keys, database credentials, and specific configuration names. Instead of hardcoding these details into the script, we request the user to provide them at runtime, ensuring flexibility and security.\n",
        "\n",
        "The script also validates that all required inputs are provided, raising an error if any crucial information is missing. This approach ensures that your integration is both secure and correctly configured without hardcoding sensitive information, enhancing the overall security and maintainability of your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFGyHll18mSe",
        "outputId": "50d09055-cf2e-4d8a-d025-cc1a6a2e3193"
      },
      "outputs": [],
      "source": [
        "AZURE_OPENAI_KEY = getpass.getpass('Enter your Azure OpenAI Key: ')\n",
        "AZURE_OPENAI_ENDPOINT = input('Enter your Azure OpenAI Endpoint: ')\n",
        "AZURE_OPENAI_EMBEDDING_DEPLOYMENT = input('Enter your Azure OpenAI Embedding Deployment: ')\n",
        "AZURE_OPENAI_CHAT_DEPLOYMENT = input('Enter your Azure OpenAI Chat Deployment: ')\n",
        "\n",
        "CB_HOST = input('Enter your Couchbase host (default: couchbase://localhost): ') or 'couchbase://localhost'\n",
        "CB_USERNAME = input('Enter your Couchbase username (default: Administrator): ') or 'Administrator'\n",
        "CB_PASSWORD = getpass.getpass('Enter your Couchbase password (default: password): ') or 'password'\n",
        "CB_BUCKET_NAME = input('Enter your Couchbase bucket name (default: query-vector-search-testing): ') or 'query-vector-search-testing'\n",
        "SCOPE_NAME = input('Enter your scope name (default: shared): ') or 'shared'\n",
        "COLLECTION_NAME = input('Enter your collection name (default: azure): ') or 'azure'\n",
        "CACHE_COLLECTION = input('Enter your cache collection name (default: cache): ') or 'cache'\n",
        "\n",
        "# Check if the variables are correctly loaded\n",
        "if not all([AZURE_OPENAI_KEY, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_EMBEDDING_DEPLOYMENT, AZURE_OPENAI_CHAT_DEPLOYMENT]):\n",
        "    raise ValueError(\"Missing required Azure OpenAI variables\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtGrYzUY8mV3"
      },
      "source": [
        "# Connecting to the Couchbase Cluster\n",
        "Connecting to a Couchbase cluster is the foundation of our project. Couchbase will serve as our primary data store, handling all the storage and retrieval operations required for our semantic search engine. By establishing this connection, we enable our application to interact with the database, allowing us to perform operations such as storing embeddings, querying data, and managing collections. This connection is the gateway through which all data will flow, so ensuring it's set up correctly is paramount.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb3kK-7W8mZK",
        "outputId": "a3279e9d-8be9-4cdd-8b04-85630b8b08a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:40:46,389 - INFO - Successfully connected to Couchbase\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    auth = PasswordAuthenticator(CB_USERNAME, CB_PASSWORD)\n",
        "    options = ClusterOptions(auth)\n",
        "    cluster = Cluster(CB_HOST, options)\n",
        "    cluster.wait_until_ready(timedelta(seconds=5))\n",
        "    logging.info(\"Successfully connected to Couchbase\")\n",
        "except Exception as e:\n",
        "    raise ConnectionError(f\"Failed to connect to Couchbase: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_Gpy32N8mcZ"
      },
      "source": [
        "# Setting Up Collections in Couchbase\n",
        "In Couchbase, data is organized in buckets, which can be further divided into scopes and collections. Think of a collection as a table in a traditional SQL database. Before we can store any data, we need to ensure that our collections exist. If they don't, we must create them. This step is important because it prepares the database to handle the specific types of data our application will process. By setting up collections, we define the structure of our data storage, which is essential for efficient data retrieval and management.\n",
        "\n",
        "Moreover, setting up collections allows us to isolate different types of data within the same bucket, providing a more organized and scalable data structure. This is particularly useful when dealing with large datasets, as it ensures that related data is stored together, making it easier to manage and query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACZcwUnG8mf2",
        "outputId": "e6d1b84d-1bd4-4718-a636-1321cb85efa2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:41:48,286 - INFO - Collection 'azure' does not exist. Creating it...\n",
            "2025-09-04 13:41:48,327 - INFO - Collection 'azure' created successfully.\n",
            "2025-09-04 13:41:50,518 - INFO - All documents cleared from the collection.\n",
            "2025-09-04 13:41:50,523 - INFO - Collection 'cache' does not exist. Creating it...\n",
            "2025-09-04 13:41:50,569 - INFO - Collection 'cache' created successfully.\n",
            "2025-09-04 13:41:52,712 - INFO - All documents cleared from the collection.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<couchbase.collection.Collection at 0x127c996c0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def setup_collection(cluster, bucket_name, scope_name, collection_name):\n",
        "    try:\n",
        "        bucket = cluster.bucket(bucket_name)\n",
        "        bucket_manager = bucket.collections()\n",
        "\n",
        "        # Check if collection exists, create if it doesn't\n",
        "        collections = bucket_manager.get_all_scopes()\n",
        "        collection_exists = any(\n",
        "            scope.name == scope_name and collection_name in [col.name for col in scope.collections]\n",
        "            for scope in collections\n",
        "        )\n",
        "\n",
        "        if not collection_exists:\n",
        "            logging.info(f\"Collection '{collection_name}' does not exist. Creating it...\")\n",
        "            bucket_manager.create_collection(scope_name, collection_name)\n",
        "            logging.info(f\"Collection '{collection_name}' created successfully.\")\n",
        "        else:\n",
        "            logging.info(f\"Collection '{collection_name}' already exists.Skipping creation.\")\n",
        "\n",
        "        collection = bucket.scope(scope_name).collection(collection_name)\n",
        "        time.sleep(2)  # Give the collection time to be ready for queries\n",
        "\n",
        "        # Clear all documents in the collection\n",
        "        try:\n",
        "            query = f\"DELETE FROM `{bucket_name}`.`{scope_name}`.`{collection_name}`\"\n",
        "            cluster.query(query).execute()\n",
        "            logging.info(\"All documents cleared from the collection.\")\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"Error while clearing documents: {str(e)}. The collection might be empty.\")\n",
        "\n",
        "        return collection\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error setting up collection: {str(e)}\")\n",
        "\n",
        "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, COLLECTION_NAME)\n",
        "setup_collection(cluster, CB_BUCKET_NAME, SCOPE_NAME, CACHE_COLLECTION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRV4k06L8mwS"
      },
      "source": [
        "# Load the TREC Dataset\n",
        "To build a search engine, we need data to search through. We use the TREC dataset, a well-known benchmark in the field of information retrieval. This dataset contains a wide variety of text data that we'll use to train our search engine. Loading the dataset is a crucial step because it provides the raw material that our search engine will work with. The quality and diversity of the data in the TREC dataset make it an excellent choice for testing and refining our search engine, ensuring that it can handle a wide range of queries effectively.\n",
        "\n",
        "The TREC dataset's rich content allows us to simulate real-world scenarios where users ask complex questions, enabling us to fine-tune our search engine's ability to understand and respond to various types of queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420,
          "referenced_widgets": [
            "8a564229df744b46954b2071c6a6675e",
            "2bcc0c8ac8cf450786af9c143aa0c45e",
            "9c4057c5ed274735b9e2a4a68a75850f",
            "851647814d2144b1a5d45d089b7e550d",
            "4258be805cd640da80eb31d7bcd57224",
            "e44357c05e6340c2a9d62e03dbae75c7",
            "7e9eacd828ad4fc8a91e0e709a6ae894",
            "adf70ce39af24961bf4813b33dfa9a6d",
            "8223fee9a1014359a08574cd33ed9be8",
            "1bb005b776a54fa3b4540c0b0e54f9ad",
            "5a09109b9cca4f51ae6b0f27d6beaff5",
            "e6d34dac7c1347088812a24dd5eaa9b4",
            "d0d85c5e388f4d98bf4ebe41dc735c59",
            "1cfb972e32b94a61b90c1cd6e30c0168",
            "de7b327febff4ce5aeace4cf5e7d8425",
            "5506530162c44ffc8d2fa499bdd898e5",
            "f4a92688a4ac4fbe8cdf0cf0c2adf92e",
            "7f8b7a00ef79456b9c1be68d7c80acbd",
            "846d0a68db8649a4b6a449e33e456557",
            "48c2da481c184d12a1bc7f629f797393",
            "313d80ed87f045da841b18d3ad40aaea",
            "be3342a74451480f9be8660631fd716a",
            "966f78ebd6fe451ba94f225c74822b45",
            "f741064b353e49849872c7cf972de3c3",
            "bb5c9bbe1f734aa28681f84d43fcf11b",
            "fdf561800c7d4080a3f79da7acac0ade",
            "c51ec2e3b7a942818a93aa41ba102d64",
            "5ff28aed5de546f9871d3db0447eb66f",
            "0a72183bcd8f49639ff7e704f1f82d37",
            "42712160f4b44a87aa9e31c9df4a3feb",
            "108bb0c972fa4fee8fca2bd2e632b47e",
            "f862f2cc0ee74a25a41201e1c0d9ee22",
            "ddf1806edafa473182ea94144930221a",
            "3c2eeaa8cf524d0e9b36e97a8b87a2af",
            "e7e7b99a739f4a759dcc5cb1c6c8f506",
            "5004572235214e4db3b9318711cc08b4",
            "570d400cfb394b0898e8b6f09521993e",
            "ad752ded95884bcba2c01eac5ef3fdfe",
            "d69ec185180d448893a6a01c3d64985b",
            "5c83ccc140a84a1db041b7e1969041e2",
            "b6c9ccf11a6b43b89e3f47664899026a",
            "c393cea168ca4ddbb843ea6fc94759a9",
            "3dabbf584cae4640949d1b57567e79ad",
            "eabfed3f083c44f2b925defbb1c32cdc",
            "71d2eeadaf064a9786c99a0c3100ab12",
            "55459ee4f481430a8211e95f80d1ebd2",
            "a070fe396d44404990fd382d14d58e6b",
            "2497fec84589445381608179f088ec2f",
            "2e0d06bf3b2e499b9649f801048b6202",
            "c4d9f620c732417d97167bd97847e75f",
            "da0c03f23da94e4bada122a084255fdc",
            "57b3d95153164e74872d5b68e4c388f4",
            "c911cc70bd394b8abedce89618dfb5b9",
            "be421d34915d453ba49b3939be725cac",
            "40646a88c38c4fca8068165fa5409c79",
            "830bdf8312e64f9694cc9bb2f77da4f7",
            "f1249595418f4481aad0f82f33fd1d96",
            "b831670efec14fd08993cba39d1245bc",
            "cabeb6f338ad4535b88491fd70416e3c",
            "357cbf7417524b1facf5b953fab75c1a",
            "46dc4caa549c48c897519ed4cd781e17",
            "3c30fa950dac4aea9b2e5be54173ddf6",
            "526c22f699ea4ab8afd347b8d5924c47",
            "c46366a97dd6455486a5ab616d1a7dc4",
            "7189e1ec10ab4f2f84daf9b2d5e0af4d",
            "c1e113316431460e8f868a8d914839d9"
          ]
        },
        "id": "TRfRslF_8mzo",
        "outputId": "b2428026-a686-4fb3-bdbf-06c747113280"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:42:13,065 - INFO - Successfully loaded TREC dataset with 1000 samples\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    trec = load_dataset('trec', split='train[:1000]')\n",
        "    logging.info(f\"Successfully loaded TREC dataset with {len(trec)} samples\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Error loading TREC dataset: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FvxRsg38m3G"
      },
      "source": [
        "# Creating AzureOpenAI Embeddings\n",
        "Embeddings are at the heart of semantic search. They are numerical representations of text that capture the semantic meaning of the words and phrases. Unlike traditional keyword-based search, which looks for exact matches, embeddings allow our search engine to understand the context and nuances of language, enabling it to retrieve documents that are semantically similar to the query, even if they don't contain the exact keywords. By creating embeddings using AzureOpenAI, we equip our search engine with the ability to understand and process natural language in a way that's much closer to how humans understand language. This step transforms our raw text data into a format that the search engine can use to find and rank relevant documents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_75ZyCRh8m6m",
        "outputId": "dbbc5248-e107-4652-843f-a60644e7d171"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:42:25,140 - INFO - Successfully created AzureOpenAIEmbeddings\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    embeddings = AzureOpenAIEmbeddings(\n",
        "        deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT,\n",
        "        openai_api_key=AZURE_OPENAI_KEY,\n",
        "        azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
        "    )\n",
        "    logging.info(\"Successfully created AzureOpenAIEmbeddings\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Error creating AzureOpenAIEmbeddings: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IwZMUnF8m-N"
      },
      "source": [
        "#  Setting Up the Couchbase Query Vector Store\n",
        "A vector store is where we'll keep our embeddings. The query vector store is specifically designed to handle embeddings and perform similarity searches. When a user inputs a query, GSI converts the query into an embedding and compares it against the embeddings stored in the vector store. This allows the engine to find documents that are semantically similar to the query, even if they don't contain the exact same words. By setting up the vector store in Couchbase, we create a powerful tool that enables us to understand and retrieve information based on the meaning and context of the query, rather than just the specific words used.\n",
        "\n",
        "The vector store requires a distance metric to determine how similarity between vectors is calculated. This is crucial for accurate semantic search results as different distance metrics can yield different similarity rankings. Some of the supported Distance strategies are dot, l2, euclidean, cosine, l2_squared, euclidean_squared. In our implementation we will use cosine which is particularly effective for text embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwIJQjYT9RV_",
        "outputId": "a302c94d-8cea-43a1-d298-70d6022c7d66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:42:29,043 - INFO - Successfully created vector store\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    vector_store = CouchbaseQueryVectorStore(\n",
        "        cluster=cluster,\n",
        "        bucket_name=CB_BUCKET_NAME,\n",
        "        scope_name=SCOPE_NAME,\n",
        "        collection_name=COLLECTION_NAME,\n",
        "        embedding = embeddings,\n",
        "        distance_metric=DistanceStrategy.COSINE\n",
        "    )\n",
        "    logging.info(\"Successfully created vector store\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Failed to create vector store: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6DJVz7A9RZA"
      },
      "source": [
        "# Saving Data to the Vector Store\n",
        "With the vector store set up, the next step is to populate it with data. We save the TREC dataset to the vector store in batches. This method is efficient and ensures that our search engine can handle large datasets without running into performance issues. By saving the data in this way, we prepare our search engine to quickly and accurately respond to user queries. This step is essential for making the dataset searchable, transforming raw data into a format that can be easily queried by our search engine.\n",
        "\n",
        "Batch processing is particularly important when dealing with large datasets, as it prevents memory overload and ensures that the data is stored in a structured and retrievable manner. This approach not only optimizes performance but also ensures the scalability of our system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6opqqvx9Rb_",
        "outputId": "1443b364-8f39-4978-a6de-832fa425e676"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:42:34,294 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:35,766 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:36,756 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:37,707 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:38,521 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:39,360 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:40,184 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:41,005 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:41,890 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:42,852 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:43,772 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:44,604 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:45,453 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:46,271 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:47,244 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:48,201 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:49,834 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:50,684 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:51,648 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:52,609 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:42:53,102 - INFO - Document ingestion completed successfully.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 50\n",
        "articles = trec['text'] \n",
        "\n",
        "try:\n",
        "    vector_store.add_texts(\n",
        "        texts=articles,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    logging.info(\"Document ingestion completed successfully.\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Failed to save documents to vector store: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pn8-dQw9RfQ"
      },
      "source": [
        "# Setting Up a Couchbase Cache\n",
        "To further optimize our system, we set up a Couchbase-based cache. A cache is a temporary storage layer that holds data that is frequently accessed, speeding up operations by reducing the need to repeatedly retrieve the same information from the database. In our setup, the cache will help us accelerate repetitive tasks, such as looking up similar documents. By implementing a cache, we enhance the overall performance of our search engine, ensuring that it can handle high query volumes and deliver results quickly.\n",
        "\n",
        "Caching is particularly valuable in scenarios where users may submit similar queries multiple times or where certain pieces of information are frequently requested. By storing these in a cache, we can significantly reduce the time it takes to respond to these queries, improving the user experience.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2y7dyjf9Rid",
        "outputId": "7930391d-4ed5-443b-a6ec-ac8091230966"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:42:56,788 - INFO - Successfully created cache\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    cache = CouchbaseCache(\n",
        "        cluster=cluster,\n",
        "        bucket_name=CB_BUCKET_NAME,\n",
        "        scope_name=SCOPE_NAME,\n",
        "        collection_name=CACHE_COLLECTION,\n",
        "    )\n",
        "    logging.info(\"Successfully created cache\")\n",
        "    set_llm_cache(cache)\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Failed to create cache: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uehAx36o9Rlm"
      },
      "source": [
        "# Using the AzureChatOpenAI Language Model (LLM)\n",
        "Language models are AI systems that are trained to understand and generate human language. We'll be using `AzureChatOpenAI` language model to process user queries and generate meaningful responses. This model is a key component of our semantic search engine, allowing it to go beyond simple keyword matching and truly understand the intent behind a query. By creating this language model, we equip our search engine with the ability to interpret complex queries, understand the nuances of language, and provide more accurate and contextually relevant responses.\n",
        "\n",
        "The language model's ability to understand context and generate coherent responses is what makes our search engine truly intelligent. It can not only find the right information but also present it in a way that is useful and understandable to the user.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRAfBRLH9RpO",
        "outputId": "fb7cb642-12c1-4122-c1fc-e9d7429fb91c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:42:59,368 - INFO - Successfully created Azure OpenAI Chat model\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    llm = AzureChatOpenAI(\n",
        "        deployment_name=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
        "        openai_api_key=AZURE_OPENAI_KEY,\n",
        "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "        openai_api_version=\"2024-10-21\"\n",
        "    )\n",
        "    logging.info(\"Successfully created Azure OpenAI Chat model\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Error creating Azure OpenAI Chat model: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_XDfCx19UvG"
      },
      "source": [
        "# Perform Semantic Search\n",
        "Semantic search in Couchbase involves converting queries and documents into vector representations using an embeddings model. These vectors capture the semantic meaning of the text and are stored directly in Couchbase. When a query is made, Couchbase performs a similarity search by comparing the query vector against the stored document vectors. The similarity metric used for this comparison is configurable, allowing flexibility in how the relevance of documents is determined. Common metrics include cosine similarity, Euclidean distance, or dot product, but other metrics can be implemented based on specific use cases. Different embedding models like BERT, Word2Vec, or GloVe can also be used depending on the application's needs, with the vectors generated by these models stored and searched within Couchbase itself.\n",
        "\n",
        "In the provided code, the search process begins by recording the start time, followed by executing the `similarity_search_with_score` method of the `CouchbaseQueryVectorStore`. This method searches Couchbase for the most relevant documents based on the vector similarity to the query. The search results include the document content and the distance that reflects how closely each document aligns with the query in the defined semantic space. The time taken to perform this search is then calculated and logged, and the results are displayed, showing the most relevant documents along with their similarity scores. This approach leverages Couchbase as both a storage and retrieval engine for vector data, enabling efficient and scalable semantic searches. The integration of vector storage and search capabilities within Couchbase allows for sophisticated semantic search operations without relying on external services for vector storage or comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk-oFbnC9Uym",
        "outputId": "2f0cf55f-6032-49cb-e91b-c7b56026067d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:43:03,875 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:43:04,835 - INFO - Semantic search completed in 1.92 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Semantic Search Results (completed in 1.92 seconds):\n",
            "Distance: 0.0556, Text: Name the Ranger who was always after Yogi Bear .\n",
            "Distance: 0.5872, Text: Who is Snoopy 's arch-enemy ?\n",
            "Distance: 0.5972, Text: What was the name of the `` Little Rascals '' dog ?\n",
            "Distance: 0.5986, Text: What was the name of the cook on Rawhide ?\n",
            "Distance: 0.6097, Text: What was American folk hero John Chapman 's nickname ?\n",
            "Distance: 0.6148, Text: Which Doonesbury character was likely to turn into a werewolf ?\n",
            "Distance: 0.6155, Text: What other name were the `` Little Rascals '' known as ?\n",
            "Distance: 0.6225, Text: What video game hero do some of his fans call Chomper ?\n",
            "Distance: 0.6237, Text: What relative of the racoon is sometimes known as the cat-bear ?\n",
            "Distance: 0.6243, Text: What Indian tribe is F Troop perpetually doing battle with ?\n"
          ]
        }
      ],
      "source": [
        "query = \"Who was the Ranger who was always after Yogi Bear?\"\n",
        "\n",
        "try:\n",
        "    # Perform the semantic search\n",
        "    start_time = time.time()\n",
        "    search_results = vector_store.similarity_search_with_score(query, k=10)\n",
        "    search_elapsed_time = time.time() - start_time\n",
        "\n",
        "    logging.info(f\"Semantic search completed in {search_elapsed_time:.2f} seconds\")\n",
        "\n",
        "    # Display search results\n",
        "    print(f\"\\nSemantic Search Results (completed in {search_elapsed_time:.2f} seconds):\")\n",
        "    for doc, score in search_results:\n",
        "        print(f\"Distance: {score:.4f}, Text: {doc.page_content}\")\n",
        "\n",
        "except CouchbaseException as e:\n",
        "    raise RuntimeError(f\"Error performing semantic search: {str(e)}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Unexpected error: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimizing Vector Search with Global Secondary Index (GSI)\n",
        "\n",
        "While the above semantic search using similarity_search_with_score works effectively, we can significantly improve query performance by leveraging Global Secondary Index (GSI) in Couchbase.\n",
        "\n",
        "Couchbase offers three types of vector indexes, but for GSI-based vector search we focus on two main types:\n",
        "\n",
        "Hyperscale Vector Indexes (BHIVE)\n",
        "- Best for pure vector searches - content discovery, recommendations, semantic search\n",
        "- High performance with low memory footprint - designed to scale to billions of vectors\n",
        "- Optimized for concurrent operations - supports simultaneous searches and inserts\n",
        "- Use when: You primarily perform vector-only queries without complex scalar filtering\n",
        "- Ideal for: Large-scale semantic search, recommendation systems, content discovery\n",
        "\n",
        "Composite Vector Indexes \n",
        "- Best for filtered vector searches - combines vector search with scalar value filtering\n",
        "- Efficient pre-filtering - scalar attributes reduce the vector comparison scope\n",
        "- Use when: Your queries combine vector similarity with scalar filters that eliminate large portions of data\n",
        "- Ideal for: Compliance-based filtering, user-specific searches, time-bounded queries\n",
        "\n",
        "Choosing the Right Index Type\n",
        "- Start with Hyperscale Vector Index for pure vector searches and large datasets\n",
        "- Use Composite Vector Index when scalar filters significantly reduce your search space\n",
        "- Consider your dataset size: Hyperscale scales to billions, Composite works well for tens of millions to billions\n",
        "\n",
        "For more details, see the [Couchbase Vector Index documentation](https://preview.docs-test.couchbase.com/docs-server-DOC-12565_vector_search_concepts/server/current/vector-index/use-vector-indexes.html).\n",
        "\n",
        "\n",
        "## Understanding Index Configuration (Couchbase 8.0 Feature)\n",
        "\n",
        "The index_description parameter controls how Couchbase optimizes vector storage and search performance through centroids and quantization:\n",
        "\n",
        "Format: `'IVF[<centroids>],{PQ|SQ}<settings>'`\n",
        "\n",
        "Centroids (IVF - Inverted File):\n",
        "- Controls how the dataset is subdivided for faster searches\n",
        "- More centroids = faster search, slower training  \n",
        "- Fewer centroids = slower search, faster training\n",
        "- If omitted (like IVF,SQ8), Couchbase auto-selects based on dataset size\n",
        "\n",
        "Quantization Options:\n",
        "- SQ (Scalar Quantization): SQ4, SQ6, SQ8 (4, 6, or 8 bits per dimension)\n",
        "- PQ (Product Quantization): PQ<subquantizers>x<bits> (e.g., PQ32x8)\n",
        "- Higher values = better accuracy, larger index size\n",
        "\n",
        "Common Examples:\n",
        "- IVF,SQ8 - Auto centroids, 8-bit scalar quantization (good default)\n",
        "- IVF1000,SQ6 - 1000 centroids, 6-bit scalar quantization  \n",
        "- IVF,PQ32x8 - Auto centroids, 32 subquantizers with 8 bits\n",
        "\n",
        "For detailed configuration options, see the [Quantization & Centroid Settings](https://preview.docs-test.couchbase.com/docs-server-DOC-12565_vector_search_concepts/server/current/vector-index/hyperscale-vector-index.html#algo_settings).\n",
        "\n",
        "In the code below, we demonstrate creating a BHIVE index. This method takes an index type (BHIVE or COMPOSITE) and description parameter for optimization settings. Alternatively, GSI indexes can be created manually from the Couchbase UI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:43:10,257 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "from langchain_couchbase.vectorstores import IndexType\n",
        "vector_store.create_index(index_type=IndexType.BHIVE, index_name=\"azure_bhive_index\",index_description=\"IVF,SQ8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The example below shows running the same similarity search, but now using the BHIVE GSI index we created above. You'll notice improved performance as the index efficiently retrieves data.\n",
        "\n",
        "**Important**: When using Composite indexes, scalar filters take precedence over vector similarity, which can improve performance for filtered searches but may miss some semantically relevant results that don't match the scalar criteria.\n",
        "\n",
        "Note: In GSI vector search, the distance represents the vector distance between the query and document embeddings. Lower distance indicate higher similarity, while higher distance indicate lower similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:43:34,079 - INFO - HTTP Request: POST https://vector-search-demos-instance.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 13:43:34,144 - INFO - Semantic search completed in 1.00 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Semantic Search Results (completed in 1.00 seconds):\n",
            "Distance: 0.0556, Text: Name the Ranger who was always after Yogi Bear .\n",
            "Distance: 0.5872, Text: Who is Snoopy 's arch-enemy ?\n",
            "Distance: 0.5972, Text: What was the name of the `` Little Rascals '' dog ?\n",
            "Distance: 0.5986, Text: What was the name of the cook on Rawhide ?\n",
            "Distance: 0.6097, Text: What was American folk hero John Chapman 's nickname ?\n",
            "Distance: 0.6148, Text: Which Doonesbury character was likely to turn into a werewolf ?\n",
            "Distance: 0.6155, Text: What other name were the `` Little Rascals '' known as ?\n",
            "Distance: 0.6225, Text: What video game hero do some of his fans call Chomper ?\n",
            "Distance: 0.6237, Text: What relative of the racoon is sometimes known as the cat-bear ?\n",
            "Distance: 0.6243, Text: What Indian tribe is F Troop perpetually doing battle with ?\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Perform the semantic search\n",
        "    start_time = time.time()\n",
        "    search_results = vector_store.similarity_search_with_score(query, k=10)\n",
        "    search_elapsed_time = time.time() - start_time\n",
        "\n",
        "    logging.info(f\"Semantic search completed in {search_elapsed_time:.2f} seconds\")\n",
        "\n",
        "    # Display search results\n",
        "    print(f\"\\nSemantic Search Results (completed in {search_elapsed_time:.2f} seconds):\")\n",
        "    for doc, score in search_results:\n",
        "        print(f\"Distance: {score:.4f}, Text: {doc.page_content}\")\n",
        "\n",
        "except CouchbaseException as e:\n",
        "    raise RuntimeError(f\"Error performing semantic search: {str(e)}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Unexpected error: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: To create a COMPOSITE index, the below code can be used.\n",
        "Choose based on your specific use case and query patterns. For this tutorial's question-answering scenario using the TREC dataset, either index type would work, but BHIVE might be more efficient for pure semantic search across questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_couchbase.vectorstores import IndexType\n",
        "vector_store.create_index(index_type=IndexType.COMPOSITE, index_name=\"azure_composite_index\", index_description=\"IVF,SQ8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS0FebHI9U1l"
      },
      "source": [
        "# Retrieval-Augmented Generation (RAG) with Couchbase and Langchain\n",
        "Couchbase and LangChain can be seamlessly integrated to create RAG (Retrieval-Augmented Generation) chains, enhancing the process of generating contextually relevant responses. In this setup, Couchbase serves as the vector store, where embeddings of documents are stored. When a query is made, LangChain retrieves the most relevant documents from Couchbase by comparing the query’s embedding with the stored document embeddings. These documents, which provide contextual information, are then passed to a generative language model within LangChain.\n",
        "\n",
        "The language model, equipped with the context from the retrieved documents, generates a response that is both informed and contextually accurate. This integration allows the RAG chain to leverage Couchbase’s efficient storage and retrieval capabilities, while LangChain handles the generation of responses based on the context provided by the retrieved documents. Together, they create a powerful system that can deliver highly relevant and accurate answers by combining the strengths of both retrieval and generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGUXQQmv9ge4",
        "outputId": "d0c619c1-c34e-4084-d31f-ca6671c23e5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 13:44:08,118 - INFO - Successfully created RAG chain\n"
          ]
        }
      ],
      "source": [
        "rag_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that answers questions based on the provided context.\"),\n",
        "    (\"human\", \"Context: {context}\\n\\nQuestion: {question}\")\n",
        "])\n",
        "rag_chain = (\n",
        "    {\"context\": vector_store.as_retriever(), \"question\": RunnablePassthrough()}\n",
        "    | rag_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "logging.info(\"Successfully created RAG chain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mia7XxM9978M",
        "outputId": "79e3506d-8c04-4374-b594-2c836310277d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAG Response: The Ranger who was always after Yogi Bear was Ranger Smith.\n",
            "RAG response generated in 2.37 seconds\n"
          ]
        }
      ],
      "source": [
        "# Get responses\n",
        "logging.disable(sys.maxsize) # Disable logging to prevent tqdm outputs\n",
        "start_time = time.time()\n",
        "rag_response = rag_chain.invoke(query)\n",
        "rag_elapsed_time = time.time() - start_time\n",
        "\n",
        "print(f\"RAG Response: {rag_response}\")\n",
        "print(f\"RAG response generated in {rag_elapsed_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIdayPzw9glT"
      },
      "source": [
        "# Using Couchbase as a caching mechanism\n",
        "Couchbase can be effectively used as a caching mechanism for RAG (Retrieval-Augmented Generation) responses by storing and retrieving precomputed results for specific queries. This approach enhances the system's efficiency and speed, particularly when dealing with repeated or similar queries. When a query is first processed, the RAG chain retrieves relevant documents, generates a response using the language model, and then stores this response in Couchbase, with the query serving as the key.\n",
        "\n",
        "For subsequent requests with the same query, the system checks Couchbase first. If a cached response is found, it is retrieved directly from Couchbase, bypassing the need to re-run the entire RAG process. This significantly reduces response time because the computationally expensive steps of document retrieval and response generation are skipped. Couchbase's role in this setup is to provide a fast and scalable storage solution for caching these responses, ensuring that frequently asked queries can be answered more quickly and efficiently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xM2G3ef-GS2",
        "outputId": "4452839f-50ab-4513-c581-b07221e0dee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query 1: When did the Vietnam War end ?\n",
            "Response: The Vietnam War ended in **1975**.\n",
            "Time taken: 2.50 seconds\n",
            "\n",
            "Query 2: Which is the slowest Olympic swimming stroke ?\n",
            "Response: The slowest Olympic swimming stroke is the **breaststroke**.\n",
            "Time taken: 1.01 seconds\n",
            "\n",
            "Query 3: When did the Vietnam War end ?\n",
            "Response: The Vietnam War ended in **1975**.\n",
            "Time taken: 0.39 seconds\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    queries = [\n",
        "        \"When did the Vietnam War end ?\",\n",
        "        \"Which is the slowest Olympic swimming stroke ?\",\n",
        "        \"When did the Vietnam War end ?\",  # Repeated query\n",
        "    ]\n",
        "\n",
        "    for i, query in enumerate(queries, 1):\n",
        "        print(f\"\\nQuery {i}: {query}\")\n",
        "        start_time = time.time()\n",
        "        response = rag_chain.invoke(query)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"Response: {response}\")\n",
        "        print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Error generating RAG response: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJQ5P8E29go1"
      },
      "source": [
        "By following these steps, you'll have a fully functional semantic search engine that leverages the strengths of Couchbase and AzureOpenAI. This guide is designed not just to show you how to build the system, but also to explain why each step is necessary, giving you a deeper understanding of the principles behind semantic search and how it improves querying data more efficiently using GSI which can significantly improve your RAG performance. Whether you're a newcomer to software development or an experienced developer looking to expand your skills, this guide will provide you with the knowledge and tools you need to create a powerful, AI-driven search engine."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "jupyter_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a72183bcd8f49639ff7e704f1f82d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "108bb0c972fa4fee8fca2bd2e632b47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bb005b776a54fa3b4540c0b0e54f9ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cfb972e32b94a61b90c1cd6e30c0168": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_846d0a68db8649a4b6a449e33e456557",
            "max": 10630,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48c2da481c184d12a1bc7f629f797393",
            "value": 10630
          }
        },
        "2497fec84589445381608179f088ec2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be421d34915d453ba49b3939be725cac",
            "placeholder": "​",
            "style": "IPY_MODEL_40646a88c38c4fca8068165fa5409c79",
            "value": " 5452/5452 [00:00&lt;00:00, 5272.67 examples/s]"
          }
        },
        "2bcc0c8ac8cf450786af9c143aa0c45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e44357c05e6340c2a9d62e03dbae75c7",
            "placeholder": "​",
            "style": "IPY_MODEL_7e9eacd828ad4fc8a91e0e709a6ae894",
            "value": "Downloading builder script: 100%"
          }
        },
        "2e0d06bf3b2e499b9649f801048b6202": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "313d80ed87f045da841b18d3ad40aaea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357cbf7417524b1facf5b953fab75c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c2eeaa8cf524d0e9b36e97a8b87a2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7e7b99a739f4a759dcc5cb1c6c8f506",
              "IPY_MODEL_5004572235214e4db3b9318711cc08b4",
              "IPY_MODEL_570d400cfb394b0898e8b6f09521993e"
            ],
            "layout": "IPY_MODEL_ad752ded95884bcba2c01eac5ef3fdfe"
          }
        },
        "3c30fa950dac4aea9b2e5be54173ddf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dabbf584cae4640949d1b57567e79ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40646a88c38c4fca8068165fa5409c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4258be805cd640da80eb31d7bcd57224": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42712160f4b44a87aa9e31c9df4a3feb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46dc4caa549c48c897519ed4cd781e17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48c2da481c184d12a1bc7f629f797393": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5004572235214e4db3b9318711cc08b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6c9ccf11a6b43b89e3f47664899026a",
            "max": 23354,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c393cea168ca4ddbb843ea6fc94759a9",
            "value": 23354
          }
        },
        "526c22f699ea4ab8afd347b8d5924c47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5506530162c44ffc8d2fa499bdd898e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55459ee4f481430a8211e95f80d1ebd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d9f620c732417d97167bd97847e75f",
            "placeholder": "​",
            "style": "IPY_MODEL_da0c03f23da94e4bada122a084255fdc",
            "value": "Generating train split: 100%"
          }
        },
        "570d400cfb394b0898e8b6f09521993e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dabbf584cae4640949d1b57567e79ad",
            "placeholder": "​",
            "style": "IPY_MODEL_eabfed3f083c44f2b925defbb1c32cdc",
            "value": " 23.4k/23.4k [00:00&lt;00:00, 313kB/s]"
          }
        },
        "57b3d95153164e74872d5b68e4c388f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a09109b9cca4f51ae6b0f27d6beaff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c83ccc140a84a1db041b7e1969041e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ff28aed5de546f9871d3db0447eb66f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7189e1ec10ab4f2f84daf9b2d5e0af4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d2eeadaf064a9786c99a0c3100ab12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55459ee4f481430a8211e95f80d1ebd2",
              "IPY_MODEL_a070fe396d44404990fd382d14d58e6b",
              "IPY_MODEL_2497fec84589445381608179f088ec2f"
            ],
            "layout": "IPY_MODEL_2e0d06bf3b2e499b9649f801048b6202"
          }
        },
        "7e9eacd828ad4fc8a91e0e709a6ae894": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f8b7a00ef79456b9c1be68d7c80acbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8223fee9a1014359a08574cd33ed9be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "830bdf8312e64f9694cc9bb2f77da4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1249595418f4481aad0f82f33fd1d96",
              "IPY_MODEL_b831670efec14fd08993cba39d1245bc",
              "IPY_MODEL_cabeb6f338ad4535b88491fd70416e3c"
            ],
            "layout": "IPY_MODEL_357cbf7417524b1facf5b953fab75c1a"
          }
        },
        "846d0a68db8649a4b6a449e33e456557": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851647814d2144b1a5d45d089b7e550d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bb005b776a54fa3b4540c0b0e54f9ad",
            "placeholder": "​",
            "style": "IPY_MODEL_5a09109b9cca4f51ae6b0f27d6beaff5",
            "value": " 5.09k/5.09k [00:00&lt;00:00, 21.6kB/s]"
          }
        },
        "8a564229df744b46954b2071c6a6675e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bcc0c8ac8cf450786af9c143aa0c45e",
              "IPY_MODEL_9c4057c5ed274735b9e2a4a68a75850f",
              "IPY_MODEL_851647814d2144b1a5d45d089b7e550d"
            ],
            "layout": "IPY_MODEL_4258be805cd640da80eb31d7bcd57224"
          }
        },
        "966f78ebd6fe451ba94f225c74822b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f741064b353e49849872c7cf972de3c3",
              "IPY_MODEL_bb5c9bbe1f734aa28681f84d43fcf11b",
              "IPY_MODEL_fdf561800c7d4080a3f79da7acac0ade"
            ],
            "layout": "IPY_MODEL_c51ec2e3b7a942818a93aa41ba102d64"
          }
        },
        "9c4057c5ed274735b9e2a4a68a75850f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adf70ce39af24961bf4813b33dfa9a6d",
            "max": 5090,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8223fee9a1014359a08574cd33ed9be8",
            "value": 5090
          }
        },
        "a070fe396d44404990fd382d14d58e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57b3d95153164e74872d5b68e4c388f4",
            "max": 5452,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c911cc70bd394b8abedce89618dfb5b9",
            "value": 5452
          }
        },
        "ad752ded95884bcba2c01eac5ef3fdfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf70ce39af24961bf4813b33dfa9a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6c9ccf11a6b43b89e3f47664899026a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b831670efec14fd08993cba39d1245bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_526c22f699ea4ab8afd347b8d5924c47",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c46366a97dd6455486a5ab616d1a7dc4",
            "value": 500
          }
        },
        "bb5c9bbe1f734aa28681f84d43fcf11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42712160f4b44a87aa9e31c9df4a3feb",
            "max": 335858,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_108bb0c972fa4fee8fca2bd2e632b47e",
            "value": 335858
          }
        },
        "be3342a74451480f9be8660631fd716a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be421d34915d453ba49b3939be725cac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1e113316431460e8f868a8d914839d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c393cea168ca4ddbb843ea6fc94759a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c46366a97dd6455486a5ab616d1a7dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4d9f620c732417d97167bd97847e75f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c51ec2e3b7a942818a93aa41ba102d64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c911cc70bd394b8abedce89618dfb5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cabeb6f338ad4535b88491fd70416e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7189e1ec10ab4f2f84daf9b2d5e0af4d",
            "placeholder": "​",
            "style": "IPY_MODEL_c1e113316431460e8f868a8d914839d9",
            "value": " 500/500 [00:00&lt;00:00, 2186.41 examples/s]"
          }
        },
        "d0d85c5e388f4d98bf4ebe41dc735c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a92688a4ac4fbe8cdf0cf0c2adf92e",
            "placeholder": "​",
            "style": "IPY_MODEL_7f8b7a00ef79456b9c1be68d7c80acbd",
            "value": "Downloading readme: 100%"
          }
        },
        "d69ec185180d448893a6a01c3d64985b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da0c03f23da94e4bada122a084255fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddf1806edafa473182ea94144930221a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de7b327febff4ce5aeace4cf5e7d8425": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_313d80ed87f045da841b18d3ad40aaea",
            "placeholder": "​",
            "style": "IPY_MODEL_be3342a74451480f9be8660631fd716a",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 52.3kB/s]"
          }
        },
        "e44357c05e6340c2a9d62e03dbae75c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d34dac7c1347088812a24dd5eaa9b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0d85c5e388f4d98bf4ebe41dc735c59",
              "IPY_MODEL_1cfb972e32b94a61b90c1cd6e30c0168",
              "IPY_MODEL_de7b327febff4ce5aeace4cf5e7d8425"
            ],
            "layout": "IPY_MODEL_5506530162c44ffc8d2fa499bdd898e5"
          }
        },
        "e7e7b99a739f4a759dcc5cb1c6c8f506": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d69ec185180d448893a6a01c3d64985b",
            "placeholder": "​",
            "style": "IPY_MODEL_5c83ccc140a84a1db041b7e1969041e2",
            "value": "Downloading data: 100%"
          }
        },
        "eabfed3f083c44f2b925defbb1c32cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1249595418f4481aad0f82f33fd1d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46dc4caa549c48c897519ed4cd781e17",
            "placeholder": "​",
            "style": "IPY_MODEL_3c30fa950dac4aea9b2e5be54173ddf6",
            "value": "Generating test split: 100%"
          }
        },
        "f4a92688a4ac4fbe8cdf0cf0c2adf92e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f741064b353e49849872c7cf972de3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ff28aed5de546f9871d3db0447eb66f",
            "placeholder": "​",
            "style": "IPY_MODEL_0a72183bcd8f49639ff7e704f1f82d37",
            "value": "Downloading data: 100%"
          }
        },
        "f862f2cc0ee74a25a41201e1c0d9ee22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdf561800c7d4080a3f79da7acac0ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f862f2cc0ee74a25a41201e1c0d9ee22",
            "placeholder": "​",
            "style": "IPY_MODEL_ddf1806edafa473182ea94144930221a",
            "value": " 336k/336k [00:00&lt;00:00, 605kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
